Instruction,Input,Output,materi,question_id,Template,correct_answer
Write a python program to successfully insert a row into a table named 'students' with the given values.,"student_name = ""John Doe""
student_age = 20","import sqlite3

conn = sqlite3.connect(""example.db"")
c = conn.cursor()
c.execute(""INSERT INTO students VALUES ('John Doe', 20)"")
conn.commit()
conn.close()",Lainnya,12,"import ___

conn = sqlite3.connect(""example.db"")
c = conn.cursor()
c.execute(""INSERT INTO students VALUES ('John Doe', 20)"")
conn.commit()
conn.close()",sqlite3
Create a web server in Python.,<no input>,"import http.server
import socketserver

PORT = 8080

Handler = http.server.SimpleHTTPRequestHandler

with socketserver.TCPServer(("""", PORT), Handler) as httpd:
    print(""Server running at http://localhost:{}/"".format(PORT))
    httpd.serve_forever()",Lainnya,20,"import ___.server
import socketserver

PORT = 8080

Handler = http.server.SimpleHTTPRequestHandler

with socketserver.TCPServer(("""", PORT), Handler) as httpd:
    print(""Server running at http://localhost:{}/"".format(PORT))
    httpd.serve_forever()",http
Write a Python program that takes a sentence as an argument and removes all punctuations from it.,"String: ""This, is a?! test* sentence.""","import string

def removePunctuations(sentence):
    return sentence.translate(str.maketrans('', '', string.punctuation))

print(removePunctuations(""This, is a?! test* sentence.""))",Lainnya,57,"import ___

def removePunctuations(sentence):
    return sentence.translate(str.maketrans('', '', string.punctuation))

print(removePunctuations(""This, is a?! test* sentence.""))",string
Write a Python program to solve a quadratic equation.,"a = 1
b = -5
c = 6","import math

# Solve the quadratic equation ax**2 + bx + c = 0 
# ax**2 + bx + c = 0 
# find x

a = 1
b = - 5
c = 6

d = (b**2) - (4*a*c)
 
# find two solutions
sol1 = (-b-math.sqrt(d))/(2*a)
sol2 = (-b+math.sqrt(d))/(2*a)
 
print('The solution are {0} and {1}'.format(sol1,sol2))",Lainnya,93,"import ___

# Solve the quadratic equation ax**2 + bx + c = 0 
# ax**2 + bx + c = 0 
# find x

a = 1
b = - 5
c = 6

d = (b**2) - (4*a*c)
 
# find two solutions
sol1 = (-b-math.sqrt(d))/(2*a)
sol2 = (-b+math.sqrt(d))/(2*a)
 
print('The solution are {0} and {1}'.format(sol1,sol2))",math
Write a Python code to tokenize the given sentence.,This is a sample sentence,"import nltk

sentence = ""This is a sample sentence""

tokenized_words = nltk.word_tokenize(sentence)

print(tokenized_words)",Lainnya,99,"import ___

sentence = ""This is a sample sentence""

tokenized_words = nltk.word_tokenize(sentence)

print(tokenized_words)",nltk
Edit the given Python code to make it asynchronous.,"""""""
def find_files(files, pattern):
    result = []
    for f in files:
        if re.search(pattern, f):
            result.append(f)
    return result
""""""","""""""
import asyncio
import re

async def find_files(files, pattern):
    result = []
    for f in files:
        if re.search(pattern,f):
            result.append(f)
    return result
""""""",Lainnya,103,"""""""
import ___
import re

async def find_files(files, pattern):
    result = []
    for f in files:
        if re.search(pattern,f):
            result.append(f)
    return result
""""""",asyncio
Train a machine learning model in Python using a given dataset and generate a confusion matrix.,// Dataset of 1000 samples and 30 features,"from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) 
model.fit(X_train, y_train)
predictions = model.predict(X_test)
confusion_matrix(y_test, predictions)",Lainnya,109,"from sklearn.model_selection import ___
from sklearn.metrics import confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) 
model.fit(X_train, y_train)
predictions = model.predict(X_test)
confusion_matrix(y_test, predictions)",train_test_split
Create a translation model in python which takes a sentence as input and returns its translation in Khmer.,"""Hello world""","import googletrans 
from googletrans import Translator 
 
def translate_sentence(sentence): 
    translator = Translator()
    translated_sentence = translator.translate(sentence, dest='km')
    return translated_sentence.text

result = translate_sentence(""Hello world"")
print(result)",Lainnya,147,"import ___ 
from googletrans import Translator 
 
def translate_sentence(sentence): 
    translator = Translator()
    translated_sentence = translator.translate(sentence, dest='km')
    return translated_sentence.text

result = translate_sentence(""Hello world"")
print(result)",googletrans
Create a ‘Find and Replace’ Script in Python.,"String: 'This is a sentence with words'
Find: 'words'
Replace: 'letters'","import re

text = 'This is a sentence with words'
find = 'words'
replace = 'letters'

new_text = re.sub(find, replace, text)
print(new_text)
# Output: This is a sentence with letters",Lainnya,148,"import ___

text = 'This is a sentence with words'
find = 'words'
replace = 'letters'

new_text = re.sub(find, replace, text)
print(new_text)
# Output: This is a sentence with letters",re
Formulate a python program to calculate the roots of a quadratic equation with given coefficients.,"coefficients: 2, -5, -3","import math
 
def quadratic_roots(a, b, c):
 
  # calculate the discriminant
  d = (b**2) - (4*a*c)
  
  # calculate the two roots
  root1 = (-b + math.sqrt(d)) / (2*a)
  root2 = (-b - math.sqrt(d)) / (2*a)
   
  print(""The roots of x^2 - 5x - 6 are"",root1,""and"",root2)
  
# Driver Code
a = 2
b = -5
c = -3
quadratic_roots(a, b, c)",Lainnya,151,"import ___
 
def quadratic_roots(a, b, c):
 
  # calculate the discriminant
  d = (b**2) - (4*a*c)
  
  # calculate the two roots
  root1 = (-b + math.sqrt(d)) / (2*a)
  root2 = (-b - math.sqrt(d)) / (2*a)
   
  print(""The roots of x^2 - 5x - 6 are"",root1,""and"",root2)
  
# Driver Code
a = 2
b = -5
c = -3
quadratic_roots(a, b, c)",math
Find the most common word in a sentence using Python.,"""this is a sentence with several words in it""","from collections import Counter
 
def most_frequent(sentence):
    words = sentence.split()
    counter = Counter(words)
    return counter.most_common(1)[0][0]

sentence = ""this is a sentence with several words in it""
print(most_frequent(sentence))
// Outputs: ""a""",Lainnya,155,"from collections import ___
 
def most_frequent(sentence):
    words = sentence.split()
    counter = Counter(words)
    return counter.most_common(1)[0][0]

sentence = ""this is a sentence with several words in it""
print(most_frequent(sentence))
// Outputs: ""a""",Counter
Write a Python program that displays the current status of a given stock quote.,The stock symbol is AAPL,"import requests 

AAPL_url = ""https://api.iextrading.com/1.0/stock/AAPL/quote?filter=symbol,latestPrice,latestSource,latestTime""

res = requests.get(AAPL_url)
data = res.json()

print(""Symbol: "" + data['symbol']) 
print(""Price: "" + str(data['latestPrice'])) 
print(""Source: "" + data['latestSource']) 
print(""Time: "" + data['latestTime'])",Lainnya,157,"import ___ 

AAPL_url = ""https://api.iextrading.com/1.0/stock/AAPL/quote?filter=symbol,latestPrice,latestSource,latestTime""

res = requests.get(AAPL_url)
data = res.json()

print(""Symbol: "" + data['symbol']) 
print(""Price: "" + str(data['latestPrice'])) 
print(""Source: "" + data['latestSource']) 
print(""Time: "" + data['latestTime'])",requests
Create a web scraper in Python that extracts the titles and summary from the reviews on a certain web page.,https://www.example.com/reviews,"import requests
from bs4 import BeautifulSoup

url = “https://www.example.com/reviews”
response = requests.get(url)
soup = BeautifulSoup(response.text, “html.parser”)

titles = []
summaries = []

for review in soup.find_all(‘div’, {‘class’: ‘review’}):
 titles.append(review.find(‘h3’).text)
 summaries.append(review.find(‘p’).text)",Lainnya,185,"import ___
from bs4 import BeautifulSoup

url = “https://www.example.com/reviews”
response = requests.get(url)
soup = BeautifulSoup(response.text, “html.parser”)

titles = []
summaries = []

for review in soup.find_all(‘div’, {‘class’: ‘review’}):
 titles.append(review.find(‘h3’).text)
 summaries.append(review.find(‘p’).text)",requests
Optimize a Python program containing a matrix addition operation.,"X = [[2, 3], 
     [1, 4]] 

Y = [[5, 6], 
     [7, 8]]","import numpy as np 

X = np.array([[2, 3], 
     [1, 4]]) 

Y = np.array([[5, 6], 
     [7, 8]])

Z = X + Y 

print(""Matrix addition result:"") 
print(Z)",Lainnya,224,"import ___ as np 

X = np.array([[2, 3], 
     [1, 4]]) 

Y = np.array([[5, 6], 
     [7, 8]])

Z = X + Y 

print(""Matrix addition result:"") 
print(Z)",numpy
Create a command line tool in Python that takes a numerical input (e.g. from user input) and prints out all prime numbers up to that number.,50,"import sys

def main():
 try:
 number = int(sys.argv[1])
 except (IndexError, ValueError):
 number = int(input('Please enter a number: '))

 prime_list = []
 for num in range(2, number + 1):
 for i in prime_list:
 if num % i == 0:
 break
 else:
 prime_list.append(num)

print(prime_list)

if __name__ == '__main__':
 main()",Lainnya,248,"import ___

def main():
 try:
 number = int(sys.argv[1])
 except (IndexError, ValueError):
 number = int(input('Please enter a number: '))

 prime_list = []
 for num in range(2, number + 1):
 for i in prime_list:
 if num % i == 0:
 break
 else:
 prime_list.append(num)

print(prime_list)

if __name__ == '__main__':
 main()",sys
Generate a Python program to extract the domain name from a given URL.,"url = ""https://www.google.com""","import re

def extract_domain_name(url):
    pattern = r""([a-z0-9][a-z0-9\-]*?\.(com|org|net|edu|co))(\/|$)""
    result = re.search(pattern, url)
    return result[1]

print(extract_domain_name(url))",Lainnya,256,"import ___

def extract_domain_name(url):
    pattern = r""([a-z0-9][a-z0-9\-]*?\.(com|org|net|edu|co))(\/|$)""
    result = re.search(pattern, url)
    return result[1]

print(extract_domain_name(url))",re
"Use pandas in Python to aggregate a given dataset with 4 columns (A, B, C, D) into a single column.","| A | B  | C | D |
|---|----|---|---|
| 0 | 34 | 2 | 6 |
| 1 | 21 | 9 | 0 |","import pandas as pd

data = [[0, 34, 2, 6], [1, 21, 9, 0]]
df = pd.DataFrame(data, columns = ['A', 'B', 'C', 'D'])

df['Aggregate'] = df.apply(lambda row: row.A + row.B + row.C + row.D, axis=1)

print(df)",Lainnya,263,"import ___ as pd

data = [[0, 34, 2, 6], [1, 21, 9, 0]]
df = pd.DataFrame(data, columns = ['A', 'B', 'C', 'D'])

df['Aggregate'] = df.apply(lambda row: row.A + row.B + row.C + row.D, axis=1)

print(df)",pandas
Modify the following Python code to generate more random numbers.,"import random

x = random.randint(1, 10)","import random

x = random.randint(1, 10)
y = random.randint(1, 10)
z = random.randint(1, 10)",Lainnya,295,"import ___

x = random.randint(1, 10)
y = random.randint(1, 10)
z = random.randint(1, 10)",random
Edit the following Python program to make a correct API request and parse the response.,"import requests

url = 'https://api.example.com/users'

response = requests.get(url)

print(response.json())","import requests

url = 'https://api.example.com/users'

headers = {
 'Authorization': 'Bearer YOUR_API_TOKEN',
 'Content-Type': 'application/json',
}

response = requests.get(url, headers=headers).json()

for user in response['data']:
 print(user)",Lainnya,304,"import ___

url = 'https://api.example.com/users'

headers = {
 'Authorization': 'Bearer YOUR_API_TOKEN',
 'Content-Type': 'application/json',
}

response = requests.get(url, headers=headers).json()

for user in response['data']:
 print(user)",requests
Write a Python program to encrypt a plaintext using Advanced Encryption Standard (AES).,"Plaintext: ""This is a secret message""","from Crypto.Cipher import AES 

plaintext = ""This is a secret message""
key = b""Sixteen Byte Key""

cipher = AES.new(key, AES.MODE_ECB) 
encrypted_text = cipher.encrypt(plaintext.encode('utf-8')) 

print(encrypted_text.hex())

# Output
c3a40f3dce503efa1f00561d60e579b9",Lainnya,322,"from Crypto.Cipher import ___ 

plaintext = ""This is a secret message""
key = b""Sixteen Byte Key""

cipher = AES.new(key, AES.MODE_ECB) 
encrypted_text = cipher.encrypt(plaintext.encode('utf-8')) 

print(encrypted_text.hex())

# Output
c3a40f3dce503efa1f00561d60e579b9",AES
Automate this Excel task using Python.,"abc,1
def,2
ghi,3
jkl,4","import pandas as pd

# Read data
df = pd.read_csv(""data.csv"")

# Perform tasks
df['result'] = df['column2'] + df['column2']

# Write the result
df.to_csv(""result.csv"", index=False)",Lainnya,363,"import ___ as pd

# Read data
df = pd.read_csv(""data.csv"")

# Perform tasks
df['result'] = df['column2'] + df['column2']

# Write the result
df.to_csv(""result.csv"", index=False)",pandas
Create a web scraper in Python to scrape the content from a website,Website URL: https://www.example.com,"import requests
from bs4 import BeautifulSoup

def scraper(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    for article in soup.find_all('article'):
        print(article.text)

if __name__ == ""__main__"":
    scraper(""https://www.example.com"")",Lainnya,376,"import ___
from bs4 import BeautifulSoup

def scraper(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    for article in soup.find_all('article'):
        print(article.text)

if __name__ == ""__main__"":
    scraper(""https://www.example.com"")",requests
Create a Python program to multiply a matrix by its inverse.,"[[3, 4],
[2, 16]]","import numpy as np

def inverse_multiplication(matrix):
    inverseM = np.linalg.inv(matrix) 
    result = np.matmul(matrix, inverseM) 
    return result

matrix = [[3, 4],
          [2, 16]]

result = inverse_multiplication(matrix)
print(result)",Lainnya,397,"import ___ as np

def inverse_multiplication(matrix):
    inverseM = np.linalg.inv(matrix) 
    result = np.matmul(matrix, inverseM) 
    return result

matrix = [[3, 4],
          [2, 16]]

result = inverse_multiplication(matrix)
print(result)",numpy
Develop a program in Python to extract the substring between two given strings,"input_string = ""This is an example string""
start_string = ""an""
end_string = ""string""","import re

input_string = ""This is an example string""
start_string = ""an""
end_string = ""string""

 regex = re.compile(start_string + '(.*?)' + end_string)
result = re.search(regex, input_string) 
if result: 
    print(result.group(1))",Lainnya,428,"import ___

input_string = ""This is an example string""
start_string = ""an""
end_string = ""string""

 regex = re.compile(start_string + '(.*?)' + end_string)
result = re.search(regex, input_string) 
if result: 
    print(result.group(1))",re
"Write a Python code snippet to create a shallow copy of the following dictionary: {‘a’: 1, ‘b’: 2}.","{'a': 1, 'b': 2}","import copy

original_dict = {'a': 1, 'b': 2}

shallow_copy_dict = copy.copy(original_dict)",Lainnya,462,"import ___

original_dict = {'a': 1, 'b': 2}

shallow_copy_dict = copy.copy(original_dict)",copy
Create a Python script that prints the top three words from a given sentence.,"sentence= ""This is a really long sentence with many words.""","import collections

sentence = ""This is a really long sentence with many words.""

# Split the given sentence into a list of words
words = sentence.split("" "")

# Count the occurrence of each word
word_freq = collections.Counter(words)

# Print out the top three words
for word, count in word_freq.most_common(3):
    print(f'{word}: {count}')",Lainnya,487,"import ___

sentence = ""This is a really long sentence with many words.""

# Split the given sentence into a list of words
words = sentence.split("" "")

# Count the occurrence of each word
word_freq = collections.Counter(words)

# Print out the top three words
for word, count in word_freq.most_common(3):
    print(f'{word}: {count}')",collections
Build a web scraper in Python to extract data from a given webpage.,"""https://www.example.com""","import requests
from bs4 import BeautifulSoup

# Make a request to the website and get the HTML
url = ""https://www.example.com""
response = requests.get(url)
html = response.content

# Parse the HTML using BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')

# Extract data from tags which contain specific class names
data = soup.find_all('div', {""class"": ""example-class""})",Lainnya,500,"import ___
from bs4 import BeautifulSoup

# Make a request to the website and get the HTML
url = ""https://www.example.com""
response = requests.get(url)
html = response.content

# Parse the HTML using BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')

# Extract data from tags which contain specific class names
data = soup.find_all('div', {""class"": ""example-class""})",requests
Write a Python program optimize the following code using functional programming.,"i = 5
while i >= 0:
 print(i)
 i -= 1","from functools import reduce

# initialize the loop
num = 5

# call reduce()
solution = reduce(lambda i, _: i - 1, range(num + 1))

# print the result
print(solution)",Lainnya,508,"from functools import ___

# initialize the loop
num = 5

# call reduce()
solution = reduce(lambda i, _: i - 1, range(num + 1))

# print the result
print(solution)",reduce
Modify the following Python program to generate random numbers between 1 and 10 instead of 1 and 100.,"import random

for i in range(10):
 num = random.randint(1,100)
 print(num)","import random

for i in range(10):
 num = random.randint(1,10)
 print(num)",Lainnya,514,"import ___

for i in range(10):
 num = random.randint(1,10)
 print(num)",random
Convert the following JSON to a python dictionary.,"{
    ""name"": ""John"",
    ""age"": 30,
    ""hobbies"": [
        ""soccer"",
        ""playing guitar""
    ]
}","""""""
Convert the following JSON to a python dictionary.
""""""
import json

json_data = {
    ""name"": ""John"",
    ""age"": 30,
    ""hobbies"": [
        ""soccer"",
        ""playing guitar""
    ]
}

python_dict =  json.loads(json.dumps(json_data))
print(python_dict)",Lainnya,528,"""""""
Convert the following JSON to a python dictionary.
""""""
import ___

json_data = {
    ""name"": ""John"",
    ""age"": 30,
    ""hobbies"": [
        ""soccer"",
        ""playing guitar""
    ]
}

python_dict =  json.loads(json.dumps(json_data))
print(python_dict)",json
Develop a Python script to calculate the cosine similarity between two word vectors.,"[0.5, 0.2, 0.7, 0.8]
[0.9, 0.6, 0.1, 0.2]","import numpy as np 
  
a = np.array([0.5, 0.2, 0.7, 0.8]) 
b = np.array([0.9, 0.6, 0.1, 0.2]) 
  
def cos_sim(a, b): 
    dot_product = np.dot(a, b) 
    norm_a = np.linalg.norm(a) 
    norm_b = np.linalg.norm(b) 
    return dot_product / (norm_a * norm_b) 
  
result = cos_sim(a, b) 
print(result)",Lainnya,535,"import ___ as np 
  
a = np.array([0.5, 0.2, 0.7, 0.8]) 
b = np.array([0.9, 0.6, 0.1, 0.2]) 
  
def cos_sim(a, b): 
    dot_product = np.dot(a, b) 
    norm_a = np.linalg.norm(a) 
    norm_b = np.linalg.norm(b) 
    return dot_product / (norm_a * norm_b) 
  
result = cos_sim(a, b) 
print(result)",numpy
Generate 3 random numbers within the specified range using Python.,"[0, 10]","import random

random_numbers = random.sample(range(0, 10), 3) 
print(random_numbers)",Lainnya,571,"import ___

random_numbers = random.sample(range(0, 10), 3) 
print(random_numbers)",random
Generate a Python program that takes a sentence as input and prints out only the verbs.,The cat jumped over the moon.,"import nltk

def extract_verbs(sentence):
    tokens = nltk.word_tokenize(sentence)
    tags = nltk.pos_tag(tokens)
    verbs = [word for word, pos in tags if pos.startswith('V')]
    return verbs

sentence = ""The cat jumped over the moon.""
verbs = extract_verbs(sentence)
print(verbs)",Lainnya,586,"import ___

def extract_verbs(sentence):
    tokens = nltk.word_tokenize(sentence)
    tags = nltk.pos_tag(tokens)
    verbs = [word for word, pos in tags if pos.startswith('V')]
    return verbs

sentence = ""The cat jumped over the moon.""
verbs = extract_verbs(sentence)
print(verbs)",nltk
Convert a given SQL statement into a Python Pandas DataFrame.,SELECT * FROM book;,"import pandas as pd

df = pd.read_sql_query(""SELECT * FROM book;"", conn)",Lainnya,612,"import ___ as pd

df = pd.read_sql_query(""SELECT * FROM book;"", conn)",pandas
Construct a Python program that computes the area of a circle with the given radius.,radius = 5,"import math

def area_circle(radius):
 return math.pi * (radius ** 2)

area = area_circle(radius)
print('The area of the circle is %.2f' % area)",Lainnya,616,"import ___

def area_circle(radius):
 return math.pi * (radius ** 2)

area = area_circle(radius)
print('The area of the circle is %.2f' % area)",math
Improve the following Python script to load the data in the absence or presence of the header.,"import pandas as pd
data = pd.read_csv('mydata.csv')","import pandas as pd

#Variable to indicate presence of Header
has_header = False

#Read CSV
data = pd.read_csv('mydata.csv',header=None) 

#Check for presence of Header
if data.iloc[0,0] != 'Column1':
  has_header = True

#Read again with header
if has_header:
  data = pd.read_csv('mydata.csv')",Lainnya,617,"import ___ as pd

#Variable to indicate presence of Header
has_header = False

#Read CSV
data = pd.read_csv('mydata.csv',header=None) 

#Check for presence of Header
if data.iloc[0,0] != 'Column1':
  has_header = True

#Read again with header
if has_header:
  data = pd.read_csv('mydata.csv')",pandas
"Using Regular Expressions, create a Python program that finds all the words in a given sentence that end with 'ing'.",This is a sentence containing a lot of words ending in 'ing'.,"import re
 
sentence = ""This is a sentence containing a lot of words ending in 'ing'.""
pattern = r""\w+ing\b""
 
words = re.findall(pattern, sentence)
 
print(words)
 
# Output: ['containing', 'ending']",Lainnya,694,"import ___
 
sentence = ""This is a sentence containing a lot of words ending in 'ing'.""
pattern = r""\w+ing\b""
 
words = re.findall(pattern, sentence)
 
print(words)
 
# Output: ['containing', 'ending']",re
Generate a syntax to input random numbers into a python program,N = 10,"import random

# Generates N random numbers
numbers = [random.randint(0, N) for i in range(N)]",Lainnya,707,"import ___

# Generates N random numbers
numbers = [random.randint(0, N) for i in range(N)]",random
Modify the given Python program so that it checks the spelling of the given word using an external library.,"word = ""Hello""","import spellchecker

word = ""Hello""

correct_word = spellchecker.correction(word)
if word != correct_word:
 print(""Did you mean"", correct_word, ""?"")",Lainnya,716,"import ___

word = ""Hello""

correct_word = spellchecker.correction(word)
if word != correct_word:
 print(""Did you mean"", correct_word, ""?"")",spellchecker
Write a Python program to calculate the standard deviation of given data.,"[20, 10, 15, 25]","import statistics
def calculate_std_dev(arr):
	return statistics.stdev(arr)",Lainnya,728,"import ___
def calculate_std_dev(arr):
	return statistics.stdev(arr)",statistics
Create a Python script to detect when a song has ended.,Sample song length in seconds: 300,"import time
 
# Define a song length
song_length = 300

# Start the progress bar
progress_bar = 0
for x in range(0, song_length):
    # Update the progress bar
    progress_bar += 1
    # Sleep a second
    time.sleep(1)
    print(""Progress Bar: {}%"".format(progress_bar/song_length * 100))

# Song has ended
print(""Song Ended!"")",Lainnya,747,"import ___
 
# Define a song length
song_length = 300

# Start the progress bar
progress_bar = 0
for x in range(0, song_length):
    # Update the progress bar
    progress_bar += 1
    # Sleep a second
    time.sleep(1)
    print(""Progress Bar: {}%"".format(progress_bar/song_length * 100))

# Song has ended
print(""Song Ended!"")",time
Develop a web scraper in Python that visits a website and retrieves the contents of the web page.,The URL of the website:  https://www.example.com,"import requests

url = ""https://www.example.com""

response = requests.get(url)
if response.status_code == 200:
 html = response.content
 print(html)",Lainnya,762,"import ___

url = ""https://www.example.com""

response = requests.get(url)
if response.status_code == 200:
 html = response.content
 print(html)",requests
Develop a python script that extracts the titles of all articles from a given website.,www.example.com,"import requests
from bs4 import BeautifulSoup

# specify url
url = 'www.example.com'

# fetch the page
response = requests.get(url)
html = response.content

# parse page content
soup = BeautifulSoup(html)

# extract titles
titles = []
for title in soup.find_all('title'):
 titles.append(title.text)

# print titles
print(titles)",Lainnya,796,"import ___
from bs4 import BeautifulSoup

# specify url
url = 'www.example.com'

# fetch the page
response = requests.get(url)
html = response.content

# parse page content
soup = BeautifulSoup(html)

# extract titles
titles = []
for title in soup.find_all('title'):
 titles.append(title.text)

# print titles
print(titles)",requests
Create a Python program to tokenize a sentence and calculate the frequency of each word in the sentence.,The quick brown fox jumps over the lazy dog,"import nltk

sentence = ""The quick brown fox jumps over the lazy dog""

words = nltk.word_tokenize(sentence)

word_freq = {}

for word in words:
 if word in word_freq:
  word_freq[word] += 1
 else:
  word_freq[word] = 1

print(word_freq)",Lainnya,797,"import ___

sentence = ""The quick brown fox jumps over the lazy dog""

words = nltk.word_tokenize(sentence)

word_freq = {}

for word in words:
 if word in word_freq:
  word_freq[word] += 1
 else:
  word_freq[word] = 1

print(word_freq)",nltk
Create a Python program to remove punctuation from a block of text.,"Text: Wel,come to the wo,rld of 'programming'.","import string

def remove_punctuation(text):
    return text.translate(str.maketrans("""","""", string.punctuation))

text = ""Wel,come to the wo,rld of 'programming'.""
print(remove_punctuation(text))
Output:
Welcome to the world of programming",Lainnya,811,"import ___

def remove_punctuation(text):
    return text.translate(str.maketrans("""","""", string.punctuation))

text = ""Wel,come to the wo,rld of 'programming'.""
print(remove_punctuation(text))
Output:
Welcome to the world of programming",string
Create a program that makes an HTTP request using Python and parses the response.,Request URL: https://www.example.com/userdata?query=example,"import requests

# make HTTP request
r = requests.get(""https://www.example.com/userdata?query=example"")
if r.status_code == 200:
    # parse response
    data = r.json()
    # do something with the data
    # ...",Lainnya,823,"import ___

# make HTTP request
r = requests.get(""https://www.example.com/userdata?query=example"")
if r.status_code == 200:
    # parse response
    data = r.json()
    # do something with the data
    # ...",requests
Write a Python program to calculate the roots of a quadratic equation.,"-2, 5, -3","import math

def quadratic_roots(a, b, c):
    d = (b ** 2) - (4 * a * c) 
    if d < 0:
        return None  # No real roots
    elif d == 0:
        return -b / (2 * a)  # One root 
    else:
        x1 = (-b + math.sqrt(d)) / (2 * a) 
        x2 = (-b - math.sqrt(d)) / (2 * a) 
        return (x1, x2)  # Two roots

print(quadratic_roots(-2, 5, -3))",Lainnya,843,"import ___

def quadratic_roots(a, b, c):
    d = (b ** 2) - (4 * a * c) 
    if d < 0:
        return None  # No real roots
    elif d == 0:
        return -b / (2 * a)  # One root 
    else:
        x1 = (-b + math.sqrt(d)) / (2 * a) 
        x2 = (-b - math.sqrt(d)) / (2 * a) 
        return (x1, x2)  # Two roots

print(quadratic_roots(-2, 5, -3))",math
Generate a Python program to generate random passwords of length n.,Length: 8,"import string
import random
 
def random_password(length):
 chars = string.ascii_uppercase + string.ascii_lowercase + string.digits
 random_password = ''.join(random.choice(chars) for i in range(length))
 return random_password
  
length = 8
print(random_password(length))",Lainnya,851,"import ___
import random
 
def random_password(length):
 chars = string.ascii_uppercase + string.ascii_lowercase + string.digits
 random_password = ''.join(random.choice(chars) for i in range(length))
 return random_password
  
length = 8
print(random_password(length))",string
Design an API in Python to compare two strings and provide an output/ match score.,"String1 = ""Hello World""
String2 = ""Hello Everyone""","import difflib

def compare_strings(string1, string2):
    # Convert strings to lowercase
    string1 = string1.lower()
    string2 = string2.lower()

    # Compute match score
    score = difflib.SequenceMatcher(None, string1, string2).ratio()

    # Return the match score
    return score",Lainnya,895,"import ___

def compare_strings(string1, string2):
    # Convert strings to lowercase
    string1 = string1.lower()
    string2 = string2.lower()

    # Compute match score
    score = difflib.SequenceMatcher(None, string1, string2).ratio()

    # Return the match score
    return score",difflib
Write some Python code to detect bias in text using the Gender Bias Detection software?,The software requires a text string to query.,"from gender_bias_detection import detect_bias

text = ""The software requires a text string to query.""

bias_signal = detect_bias(text)

# Checking is the detected bias is positive
if bias_signal > 0:
  print(""The text contains gender bias."")
else:
  print(""The text does not contain gender bias."")",Lainnya,924,"from gender_bias_detection import ___

text = ""The software requires a text string to query.""

bias_signal = detect_bias(text)

# Checking is the detected bias is positive
if bias_signal > 0:
  print(""The text contains gender bias."")
else:
  print(""The text does not contain gender bias."")",detect_bias
Utilize ajax to send a request to a given web page and write a Python script to parse the response.,"url = ""www.example.com""","import requests

url = ""www.example.com""

try:
    request = requests.get(url)  # Send ajax request
    response = request.json()  # Get response in JSON
    for data in response['data']:
        # Do something with data  # Parse JSON response
except Exception as e:
    print(e)",Lainnya,929,"import ___

url = ""www.example.com""

try:
    request = requests.get(url)  # Send ajax request
    response = request.json()  # Get response in JSON
    for data in response['data']:
        # Do something with data  # Parse JSON response
except Exception as e:
    print(e)",requests
Generate a graphical representation of a network using Python and matplotlib.,Number of nodes = 10,"import matplotlib.pyplot as plt

node_list = []
for i in range(10):
    node_list.append(i)

G = nx.Graph()
G.add_nodes_from(node_list)

nx.draw(G, with_labels=True)
plt.show()",Lainnya,955,"import ___.pyplot as plt

node_list = []
for i in range(10):
    node_list.append(i)

G = nx.Graph()
G.add_nodes_from(node_list)

nx.draw(G, with_labels=True)
plt.show()",matplotlib
Create an algorithm in Python to generate random numbers between 1 and 10 without repetition.,Number of random numbers needed is 5,"import random

def generate_random_numbers(n):
 result = random.sample(range(1, 11), n)
 return result

random_numbers = generate_random_numbers(5)
print(random_numbers) # Example output: [4, 9, 2, 6, 8]",Lainnya,967,"import ___

def generate_random_numbers(n):
 result = random.sample(range(1, 11), n)
 return result

random_numbers = generate_random_numbers(5)
print(random_numbers) # Example output: [4, 9, 2, 6, 8]",random
Implement a Python module that converts a given date to ISO format,25-Dec-24,"import datetime

def convertToISO(dateString):
 date = datetime.datetime.strptime(dateString, ""%d %B %Y"").isoformat()
 return date

# test
dateString = '25 December 2024'
print(convertToISO(dateString))

# Output: 2024-12-25T00:00:00",Lainnya,986,"import ___

def convertToISO(dateString):
 date = datetime.datetime.strptime(dateString, ""%d %B %Y"").isoformat()
 return date

# test
dateString = '25 December 2024'
print(convertToISO(dateString))

# Output: 2024-12-25T00:00:00",datetime
Write a Python script to perform linear regression on a given dataset.,"[[5, 6], [3, 4], [7, 9], [4, 5]]","import numpy as np
from sklearn.linear_model import LinearRegression

x = np.array([[5, 6], [3, 4], [7, 9], [4, 5]])
y = np.array([7, 5, 11, 7])

model = LinearRegression().fit(x, y)

print(model.coef_)
print(model.intercept_)",Lainnya,1040,"import ___ as np
from sklearn.linear_model import LinearRegression

x = np.array([[5, 6], [3, 4], [7, 9], [4, 5]])
y = np.array([7, 5, 11, 7])

model = LinearRegression().fit(x, y)

print(model.coef_)
print(model.intercept_)",numpy
Create a web service in Python that takes in a temperature value as input in Celsius and returns the equivalent value in Fahrenheit.,celsius = 21,"import flask

app = flask.Flask(__name__)

@app.route('/celsius-to-fahrenheit/<int:celsius>', methods=['GET'])
def celsius_to_fahrenheit(celsius):
 fahrenheit = celsius * 9/5 + 32
 return flask.jsonify({'celsius': celsius, 'fahrenheit': fahrenheit})
 
if __name__ == '__main__':
 app.run()",Lainnya,1052,"import ___

app = flask.Flask(__name__)

@app.route('/celsius-to-fahrenheit/<int:celsius>', methods=['GET'])
def celsius_to_fahrenheit(celsius):
 fahrenheit = celsius * 9/5 + 32
 return flask.jsonify({'celsius': celsius, 'fahrenheit': fahrenheit})
 
if __name__ == '__main__':
 app.run()",flask
Produce a Python script to convert a given Unix timestamp into human readable date format.,1545732721,"import time

# Unix timestamp in seconds
unix_timestamp = 1545732721

# Convert to readable date format
timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(unix_timestamp))

print('Human readable date format:', timestamp)",Lainnya,1072,"import ___

# Unix timestamp in seconds
unix_timestamp = 1545732721

# Convert to readable date format
timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(unix_timestamp))

print('Human readable date format:', timestamp)",time
Find the 5 most frequent words in the given text.,Text: Python is a high-level programming language.,"from collections import Counter

text = "" Python is a high-level programming language.""
words = text.split()

frequencies = Counter(words)

# printing five most frequent words 
frequent_words = frequencies.most_common(5)

print(frequent_words)",Lainnya,1090,"from collections import ___

text = "" Python is a high-level programming language.""
words = text.split()

frequencies = Counter(words)

# printing five most frequent words 
frequent_words = frequencies.most_common(5)

print(frequent_words)",Counter
Develop a Python script which extracts data from a given website.,URL: https://www.example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://www.example.com""
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')

# Extract all Anchor Tags
links = soup.find_all('a')

# Extract all the contents of Anchors
for link in links:
    print(link.text, link.get('href'))",Lainnya,1099,"import ___
from bs4 import BeautifulSoup

url = ""https://www.example.com""
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')

# Extract all Anchor Tags
links = soup.find_all('a')

# Extract all the contents of Anchors
for link in links:
    print(link.text, link.get('href'))",requests
Write code to establish a connection between a Python backend and a MySQL database.,"Host = 'localhost'
Username = 'root'
Password = '123456'
Database = 'sample_database'","import mysql.connector 
  
#Create MySQL Connection 
connection = mysql.connector.connect(host = Host, database = Database, user = Username, password = Password) 

#Check whether connection is established or not
if connection.is_connected(): 
    print(""Connection established successfully"")",Lainnya,1109,"import ___.connector 
  
#Create MySQL Connection 
connection = mysql.connector.connect(host = Host, database = Database, user = Username, password = Password) 

#Check whether connection is established or not
if connection.is_connected(): 
    print(""Connection established successfully"")",mysql
Replace the given SQL query with a Python program to calculate the sum of all the column values.,SELECT SUM(column) FROM table;,"import pandas as pd

data = pd.read_sql

  query = ""SELECT * FROM table""

df = pd.read_sql(query, conn)

sum_column = df['column'].sum()

print(sum_column)",Lainnya,1112,"import ___ as pd

data = pd.read_sql

  query = ""SELECT * FROM table""

df = pd.read_sql(query, conn)

sum_column = df['column'].sum()

print(sum_column)",pandas
Write a Python program to generate N random numbers.,5,"import random

random_numbers = []

for _ in range(5):
  random_numbers.append(random.random()) 

print(random_numbers)",Lainnya,1114,"import ___

random_numbers = []

for _ in range(5):
  random_numbers.append(random.random()) 

print(random_numbers)",random
Develop a Python solution to identify parts of speech of a given sentence.,"Sentence: ""I like apples.""","import nltk

sentence = ""I like apples.""
words = nltk.word_tokenize(sentence)
tagged_words = nltk.pos_tag(words)

parts_of_speech = dict()
for word, tag in tagged_words:
  parts_of_speech[word] = tag

print(parts_of_speech)
# Output: {'I': 'PRP', 'like': 'VBP', 'apples': 'NNS'}",Lainnya,1182,"import ___

sentence = ""I like apples.""
words = nltk.word_tokenize(sentence)
tagged_words = nltk.pos_tag(words)

parts_of_speech = dict()
for word, tag in tagged_words:
  parts_of_speech[word] = tag

print(parts_of_speech)
# Output: {'I': 'PRP', 'like': 'VBP', 'apples': 'NNS'}",nltk
Create a python program to convert a date from one format to another.,"""May 14, 2020"" -> ""14-05-2020""","import datetime

def convert_date_format(date_str, old_format, new_format): 
  dt_obj = datetime.datetime.strptime(date_str, old_format) 
  return dt_obj.strftime(new_format) 

print(convert_date_format(""May 14, 2020"", ""%b %d, %Y"", "" %d-%m-%Y""))",Lainnya,1211,"import ___

def convert_date_format(date_str, old_format, new_format): 
  dt_obj = datetime.datetime.strptime(date_str, old_format) 
  return dt_obj.strftime(new_format) 

print(convert_date_format(""May 14, 2020"", ""%b %d, %Y"", "" %d-%m-%Y""))",datetime
Develop a Python script to scrape all HTML elements from a given website.,Input URL: https://www.example.com/,"import requests
from bs4 import BeautifulSoup

# Request the HTML page
url = 'https://www.example.com/'
page = requests.get(url)

# Create the Beautiful Soup object
soup = BeautifulSoup(page.content, 'html.parser')

# Fetch all HTML elements
elements = soup.find_all()

# Output elements
for element in elements:
    print(element)",Lainnya,1226,"import ___
from bs4 import BeautifulSoup

# Request the HTML page
url = 'https://www.example.com/'
page = requests.get(url)

# Create the Beautiful Soup object
soup = BeautifulSoup(page.content, 'html.parser')

# Fetch all HTML elements
elements = soup.find_all()

# Output elements
for element in elements:
    print(element)",requests
Write a Python program to generate a password with a given length and characters.,"length = 10
characters = alphanumeric","import random

def generate_password(length, characters):
    password = ''
    for i in range(length):
        password += random.choice(characters)
    return password

print(generate_password(10, 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'))",Lainnya,1227,"import ___

def generate_password(length, characters):
    password = ''
    for i in range(length):
        password += random.choice(characters)
    return password

print(generate_password(10, 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'))",random
Implement a decision tree model in Python to classify given data.,"[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]","#importing necessary libraries
from sklearn import tree
import numpy as np

#data
X = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]])
y = np.array([0, 1])

#model
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X, y)

#predicting
x_test = np.array([[1, 0, 0, 0, 1]])
prediction = clf.predict(x_test)

#result
print(prediction)",Lainnya,1238,"#importing necessary libraries
from sklearn import ___
import numpy as np

#data
X = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]])
y = np.array([0, 1])

#model
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X, y)

#predicting
x_test = np.array([[1, 0, 0, 0, 1]])
prediction = clf.predict(x_test)

#result
print(prediction)",tree
"Given the following data, adjust the Python code so that it outputs a JSON representation of the data.","data = [
  {
    ""id"": 5,
    ""name"": ""John""
  },
  {
    ""id"": 7,
    ""name"": ""Jack""
  },
  {
    ""id"": 9,
    ""name"": ""James""
  }
]","import json

data = [
  {
    ""id"": 5,
    ""name"": ""John""
  },
  {
    ""id"": 7,
    ""name"": ""Jack""
  },
  {
    ""id"": 9,
    ""name"": ""James""
  }
]

data_json = json.dumps(data, indent=4)
print(data_json)",Lainnya,1240,"import ___

data = [
  {
    ""id"": 5,
    ""name"": ""John""
  },
  {
    ""id"": 7,
    ""name"": ""Jack""
  },
  {
    ""id"": 9,
    ""name"": ""James""
  }
]

data_json = json.dumps(data, indent=4)
print(data_json)",json
Understand the meaning of the given data and create a classification model in Python.,"x1 = [1 ,2 ,3, 4, 5]
y = [1, 2, 1, 2, 1]","# Import necessary library 
from sklearn import svm

# Create a feature and label array 
X = [[1], [2], [3], [4], [5]] 
Y = [1,2,1,2,1]

# Set up the svm model 
clf = svm.SVC(kernel='linear')

# Train the model 
clf.fit(X, Y)

# Test the model 
predictions = clf.predict([[3]])
print(predictions)",Lainnya,1292,"# Import necessary library 
from sklearn import ___

# Create a feature and label array 
X = [[1], [2], [3], [4], [5]] 
Y = [1,2,1,2,1]

# Set up the svm model 
clf = svm.SVC(kernel='linear')

# Train the model 
clf.fit(X, Y)

# Test the model 
predictions = clf.predict([[3]])
print(predictions)",svm
Convert the following SQL query into a python pandas dataframe.,SELECT * from books WHERE author LIKE '%Rowling%';,"import pandas as pd

# read the books table
df = pd.read_sql(""SELECT * from books"", connection)

# filter for rows with matching author
df_filtered = df[df['author'].str.contains(""Rowling"")]

# print the results
print(df_filtered)",Lainnya,1297,"import ___ as pd

# read the books table
df = pd.read_sql(""SELECT * from books"", connection)

# filter for rows with matching author
df_filtered = df[df['author'].str.contains(""Rowling"")]

# print the results
print(df_filtered)",pandas
Generate a voltage signal with random noise using a Python script.,A signal of frequency 250 Hz and amplitude 1 V.,"import numpy as np 

freq = 250 
amplitude = 1 

t= np.linspace(0, 1, 1000) 
voltage_signal = np.sin(2*np.pi*freq*t) + np.random.normal(0, 0.1, 1000)",Lainnya,1300,"import ___ as np 

freq = 250 
amplitude = 1 

t= np.linspace(0, 1, 1000) 
voltage_signal = np.sin(2*np.pi*freq*t) + np.random.normal(0, 0.1, 1000)",numpy
Write a Python script to download the source code of a website.,URL: example.com,"import requests

# send the request 
response = requests.get(""http://example.com"")

# get the source code of the website
data = response.text 

# write the source code into a file
with open('example_source.txt', 'w') as file:
 file.write(data)",Lainnya,1327,"import ___

# send the request 
response = requests.get(""http://example.com"")

# get the source code of the website
data = response.text 

# write the source code into a file
with open('example_source.txt', 'w') as file:
 file.write(data)",requests
Create a Python program that uses regular expression to find and extract certain information from a text.,"Text: ""The customer's address is 123 Main Street, Anytown, USA.""","import re

text = ""The customer's address is 123 Main Street, Anytown, USA.""

address_pattern = re.compile(r'(\d+\s*(?:[A-Za-z]+\s*)+),\s*([A-Za-z\s]+),\s*([A-Z]{2})')

match = address_pattern.search(text)

if match:
 street = match[1]
 city = match[2]
 state = match[3]

print(f'{street}, {city}, {state}')",Lainnya,1351,"import ___

text = ""The customer's address is 123 Main Street, Anytown, USA.""

address_pattern = re.compile(r'(\d+\s*(?:[A-Za-z]+\s*)+),\s*([A-Za-z\s]+),\s*([A-Z]{2})')

match = address_pattern.search(text)

if match:
 street = match[1]
 city = match[2]
 state = match[3]

print(f'{street}, {city}, {state}')",re
"Using Python, make a program which will generate a random password of a given length.",7,"import string
import random

def get_password(length):
    alphabet = string.ascii_letters + string.digits
    password = ''.join(random.choice(alphabet) for i in range(length))
    print (password)

get_password(7)",Lainnya,1357,"import ___
import random

def get_password(length):
    alphabet = string.ascii_letters + string.digits
    password = ''.join(random.choice(alphabet) for i in range(length))
    print (password)

get_password(7)",string
Translate the following SQL query into Python code.,"SELECT Customer_Name, COUNT(Order_Id) AS Number_of_Orders 
FROM Orders 
GROUP BY Customer_Name","import pandas as pd

df = pd.read_sql_query(""SELECT Customer_Name, COUNT(Order_Id) AS Number_of_Orders FROM Orders GROUP BY Customer_Name"", con)
result = df.to_dict('records')",Lainnya,1360,"import ___ as pd

df = pd.read_sql_query(""SELECT Customer_Name, COUNT(Order_Id) AS Number_of_Orders FROM Orders GROUP BY Customer_Name"", con)
result = df.to_dict('records')",pandas
"Generate a Python program to calculate the amount of time the user has been working on a specific task, given the start time and the current time.","start time=4:30pm, current time= 5:07pm","import datetime

def get_time_difference(start_time, current_time):
    start_time = datetime.datetime.strptime(start_time, ""%H:%M%p"")
    current_time = datetime.datetime.strptime(current_time, ""%H:%M%p"")
    return current_time - start_time",Lainnya,1361,"import ___

def get_time_difference(start_time, current_time):
    start_time = datetime.datetime.strptime(start_time, ""%H:%M%p"")
    current_time = datetime.datetime.strptime(current_time, ""%H:%M%p"")
    return current_time - start_time",datetime
Complete this Python code to to generate a random password using a given length.,length = 10,"import string
import random

def generate_password(length):
    password_characters = string.ascii_letters + string.digits + string.punctuation 
    password = ''.join(random.choice(password_characters) for i in range(length))
    return password

print(generate_password(length))",Lainnya,1367,"import ___
import random

def generate_password(length):
    password_characters = string.ascii_letters + string.digits + string.punctuation 
    password = ''.join(random.choice(password_characters) for i in range(length))
    return password

print(generate_password(length))",string
Edit the given Python code to format the output as a table using tabulate.,"fruits = [""apple"", ""orange"", ""pineapple"", ""melon""]
for fruit in fruits:
    print(fruit)","import tabulate

fruits = [""apple"", ""orange"", ""pineapple"", ""melon""] 
table = [(fruit,) for fruit in fruits] 
print(tabulate.tabulate(table, headers=[""Fruits""])) 
# Output: 
# Fruits
# apple
# orange
# pineapple
# melon",Lainnya,1372,"import ___

fruits = [""apple"", ""orange"", ""pineapple"", ""melon""] 
table = [(fruit,) for fruit in fruits] 
print(tabulate.tabulate(table, headers=[""Fruits""])) 
# Output: 
# Fruits
# apple
# orange
# pineapple
# melon",tabulate
Create a model in Python using Linear Regression that can predict the housing prices given the living area and number of rooms.,"data = [[2000, 3], [1600, 2.5], [2400, 3.5], [1400, 2], [3000, 4]]","import numpy as np
from sklearn import linear_model

X = np.array([[2000, 3], [1600, 2.5], [2400, 3.5], [1400, 2], [3000, 4]])
y = np.array([75000, 43000, 59000, 32000, 85000])

model = linear_model.LinearRegression()
model.fit(X, y)

prediction = model.predict([[2200, 3]])",Lainnya,1382,"import ___ as np
from sklearn import linear_model

X = np.array([[2000, 3], [1600, 2.5], [2400, 3.5], [1400, 2], [3000, 4]])
y = np.array([75000, 43000, 59000, 32000, 85000])

model = linear_model.LinearRegression()
model.fit(X, y)

prediction = model.predict([[2200, 3]])",numpy
Complete the Python program to automatically add 3 months to a date.,"import datetime
date_str = '2020-01-31'
def add_three_months","import datetime
date_str = '2020-01-31'

def add_three_months(date_str):
    d = datetime.datetime.strptime(date_str, '%Y-%m-%d')
    d = d + datetime.timedelta(days=90)
    date_str = d.strftime('%Y-%m-%d')
    return date_str",Lainnya,1388,"import ___
date_str = '2020-01-31'

def add_three_months(date_str):
    d = datetime.datetime.strptime(date_str, '%Y-%m-%d')
    d = d + datetime.timedelta(days=90)
    date_str = d.strftime('%Y-%m-%d')
    return date_str",datetime
Write a machine learning algorithm in Python to find the nearest neighbors of a given point.,"point = [3, 4]","from sklearn.neighbors import NearestNeighbors

def nearest_neighbors(point):
    neighbors = NearestNeighbors(n_neighbors=1).fit(point) 
    return neighbors.kneighbors([point], return_distance=False)[0]",Lainnya,1390,"from sklearn.neighbors import ___

def nearest_neighbors(point):
    neighbors = NearestNeighbors(n_neighbors=1).fit(point) 
    return neighbors.kneighbors([point], return_distance=False)[0]",NearestNeighbors
Write a Python program to create a bar chart from a given dataset.,"dataset = [5, 8, 10, 12, 3, 6]","import matplotlib.pyplot as plt 

# Data to plot 
data = [5, 8, 10, 12, 3, 6] 

# Plot the data 
plt.bar(data, data) 

# Set labels 
plt.xlabel('Data') 
plt.ylabel('Values') 

# Title 
plt.title('Bar Chart of Data Set') 

# Show the plot 
plt.show()",Lainnya,1408,"import ___.pyplot as plt 

# Data to plot 
data = [5, 8, 10, 12, 3, 6] 

# Plot the data 
plt.bar(data, data) 

# Set labels 
plt.xlabel('Data') 
plt.ylabel('Values') 

# Title 
plt.title('Bar Chart of Data Set') 

# Show the plot 
plt.show()",matplotlib
Create a web scraper in Python to scrape product prices from a given URL.,URL: https://example.com/product-list,"import requests
from bs4 import BeautifulSoup

# make the request
URL = ""https://example.com/product-list""
response = requests.get(URL)

# parse the HTML
soup = BeautifulSoup(response.content, 'html.parser')

# find all product prices on the page
prices = soup.find_all('span', class_=""price"")

# print out all the prices
for price in prices:
 print(price.text)",Lainnya,1433,"import ___
from bs4 import BeautifulSoup

# make the request
URL = ""https://example.com/product-list""
response = requests.get(URL)

# parse the HTML
soup = BeautifulSoup(response.content, 'html.parser')

# find all product prices on the page
prices = soup.find_all('span', class_=""price"")

# print out all the prices
for price in prices:
 print(price.text)",requests
Modify the following Python program to explore and retrieve data from a dataset using Pandas.,"import pandas as pd

df = pd.read_csv('data.csv')

print(df)","import pandas as pd

df = pd.read_csv('data.csv')

print(df.head())
print(df.info())
print(""Average age of passengers:"", df['Age'].mean())
print(""Number of female passengers:"", df[df['Sex'] == 'female'].shape[0])
print(""Oldest passenger:"", df.loc[df['Age'].idxmax()])",Lainnya,1445,"import ___ as pd

df = pd.read_csv('data.csv')

print(df.head())
print(df.info())
print(""Average age of passengers:"", df['Age'].mean())
print(""Number of female passengers:"", df[df['Sex'] == 'female'].shape[0])
print(""Oldest passenger:"", df.loc[df['Age'].idxmax()])",pandas
Create a WebScraper in Python that extracts the titles and links from a given URL.,The web page https://www.example.com,"from bs4 import BeautifulSoup
import requests

url = 'https://www.example.com'
r = requests.get(url)

soup = BeautifulSoup(r.content, 'html.parser')

# Extract titles and links
titles = []
links = []
for link in soup.find_all('a'):
 titles.append(link.get('title'))
 links.append(link.get('href'))

print(titles, links)",Lainnya,1457,"from bs4 import ___
import requests

url = 'https://www.example.com'
r = requests.get(url)

soup = BeautifulSoup(r.content, 'html.parser')

# Extract titles and links
titles = []
links = []
for link in soup.find_all('a'):
 titles.append(link.get('title'))
 links.append(link.get('href'))

print(titles, links)",BeautifulSoup
Propose a solution to fetch an online catalog of products and display them in a tabular format using Python.,Catalog consisting of 1000 products,"import requests
import pandas as pd

# Set the request URL
url = ""http://example.com/products""

# Send the request and retrieve the data
data = requests.get(url).json()

# Convert the data into a pandas DataFrame
df = pd.DataFrame(data)

# Print the resulting table
print(df)",Lainnya,1471,"import ___
import pandas as pd

# Set the request URL
url = ""http://example.com/products""

# Send the request and retrieve the data
data = requests.get(url).json()

# Convert the data into a pandas DataFrame
df = pd.DataFrame(data)

# Print the resulting table
print(df)",requests
Generate a python script that plans a route from point A to point B.,"Point A = (1.2, -2.6)
Point B = (7.9, 5.3)","# import modules
import math

# function to calculate the distance
def route_distance(A, B):
    dX = B[0] - A[0]
    dY = B[1] - A[1]
    return math.sqrt(dX * dX + dY * dY)

# Driver code 
A = (1.2, -2.6) 
B = (7.9, 5.3)

dist = route_distance(A, B)

print(""Distance from A to B is:"", dist)",Lainnya,1486,"# import ___
import math

# function to calculate the distance
def route_distance(A, B):
    dX = B[0] - A[0]
    dY = B[1] - A[1]
    return math.sqrt(dX * dX + dY * dY)

# Driver code 
A = (1.2, -2.6) 
B = (7.9, 5.3)

dist = route_distance(A, B)

print(""Distance from A to B is:"", dist)",modules
Develop a Python script to extract the specific keyword from the given URL.,"URL: https://www.test.com/where-is-the-key
Keyword: key","import re

url = ""https://www.test.com/where-is-the-key""
keyword = ""key""

match = re.search(f'{keyword}', url)
if match:
    print(f'{keyword} found at starting index: {match.start()}')
else:
    print(f'{keyword} not found')",Lainnya,1496,"import ___

url = ""https://www.test.com/where-is-the-key""
keyword = ""key""

match = re.search(f'{keyword}', url)
if match:
    print(f'{keyword} found at starting index: {match.start()}')
else:
    print(f'{keyword} not found')",re
Develop a Python program to fetch the website users of an online store.,Website URL: www.example.com,"import requests

url = 'https://www.example.com/users'
response = requests.get(url)
data = response.json()

for user in data:
    print(user['name'])",Lainnya,1505,"import ___

url = 'https://www.example.com/users'
response = requests.get(url)
data = response.json()

for user in data:
    print(user['name'])",requests
Construct a parser in Python to identify the parts of speech in a given sentence.,This is a great day.,"import spacy

nlp = spacy.load('en_core_web_sm')

# Define the sentence to be parsed
sentence = 'This is a great day.'

# Create a Doc object
doc = nlp(sentence)

# Print the parts of speech
for token in doc:
    print(token.text, token.pos_)

# Output:
# This DET
# is VERB
# a DET
# great ADJ
# day NOUN
# . PUNCT",Lainnya,1541,"import ___

nlp = spacy.load('en_core_web_sm')

# Define the sentence to be parsed
sentence = 'This is a great day.'

# Create a Doc object
doc = nlp(sentence)

# Print the parts of speech
for token in doc:
    print(token.text, token.pos_)

# Output:
# This DET
# is VERB
# a DET
# great ADJ
# day NOUN
# . PUNCT",spacy
Write a Python program to retrieve binary data from a given URL.,"url = ""https://example.com/sample.txt""","import requests 
  
def getFileData(url):
  # Get binary data
  r = requests.get(url)
  return r.content

url = ""https://example.com/sample.txt""
data = getFileData(url)

print(data)",Lainnya,1546,"import ___ 
  
def getFileData(url):
  # Get binary data
  r = requests.get(url)
  return r.content

url = ""https://example.com/sample.txt""
data = getFileData(url)

print(data)",requests
Write a Python program to parse an XML document.,"<?xml version=""1.0"" encoding="" UTF-8""?>
<note>
    <to>John Doe</to>
    <from>Jane Doe</from>
    <heading>Greeting</heading>
    <body>Hello World!</body>
</note>","""""""
Parse an XML document
""""""

import xml.etree.ElementTree as ET

# Parse the XML file
root = ET.parse('note.xml').getroot()

# Print out the XML elements
for item in root:
    print(f""{item.tag}: {item.text}"")",Lainnya,1568,"""""""
Parse an XML document
""""""

import ___.etree.ElementTree as ET

# Parse the XML file
root = ET.parse('note.xml').getroot()

# Print out the XML elements
for item in root:
    print(f""{item.tag}: {item.text}"")",xml
Create a program in Python to calculate the Euclidean distance between two points.,"x1 = 2
y1 = 3
x2 = 6
y2 = 8","import math

x1 = 2
y1 = 3
x2 = 6
y2 = 8
distance = math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 )

print(distance)",Lainnya,1592,"import ___

x1 = 2
y1 = 3
x2 = 6
y2 = 8
distance = math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 )

print(distance)",math
"Change the following Pythoncode to display ""Hello, World!"" on the web page:","print(""Hello, World!"")","from flask import Flask
app = Flask(__name__)

@app.route(""/"")
def hello():
	return ""Hello, World!""

if __name__ == ""__main__"":
	app.run()",Lainnya,1596,"from flask import ___
app = Flask(__name__)

@app.route(""/"")
def hello():
	return ""Hello, World!""

if __name__ == ""__main__"":
	app.run()",Flask
Create a Python script to read data from a database.,Table Name: 'customers',"import psycopg2

connection = psycopg2.connect(database='dbname', user='user', password='password', host='localhost', port='5432')

cursor = connection.cursor()

cursor.execute('SELECT * FROM customers')

rows = cursor.fetchall()

for row in rows:
    print(row)
    
cursor.close()",Lainnya,1606,"import ___

connection = psycopg2.connect(database='dbname', user='user', password='password', host='localhost', port='5432')

cursor = connection.cursor()

cursor.execute('SELECT * FROM customers')

rows = cursor.fetchall()

for row in rows:
    print(row)
    
cursor.close()",psycopg2
Create a Python script to extract the title of a web page.,<url>,"import requests
from bs4 import BeautifulSoup

# Function to extract the title of a web page
def extract_title(url):
    response = requests.get(url)
    html = response.text

    soup = BeautifulSoup(html, 'html.parser')
    return soup.title.string

url = 'https://www.example.com'
title = extract_title(url)
print(title)  # Output 'Example Domain'",Lainnya,1616,"import ___
from bs4 import BeautifulSoup

# Function to extract the title of a web page
def extract_title(url):
    response = requests.get(url)
    html = response.text

    soup = BeautifulSoup(html, 'html.parser')
    return soup.title.string

url = 'https://www.example.com'
title = extract_title(url)
print(title)  # Output 'Example Domain'",requests
Create a program to convert a text document to an HTML webpage using Python.,"Text document with contents ""This is a sample document"".","from bs4 import BeautifulSoup

# Read and parse the document
with open('sample.txt', 'r') as file:
  content = file.read()

# Create the HTML
soup = BeautifulSoup(content, 'html.parser')
html_content = soup.prettify()

# Write to the file
with open('sample.html', 'w') as file:
  file.write(html_content)",Lainnya,1621,"from bs4 import ___

# Read and parse the document
with open('sample.txt', 'r') as file:
  content = file.read()

# Create the HTML
soup = BeautifulSoup(content, 'html.parser')
html_content = soup.prettify()

# Write to the file
with open('sample.html', 'w') as file:
  file.write(html_content)",BeautifulSoup
Write a Python program that will calculate the correlation between two different datasets.,"Dataset 1:[1,2,3,4,5]
Dataset 2:[2,4,6,8,10]","import numpy as np

data1 = [1,2,3,4,5]
data2 = [2,4,6,8,10]

correlation = np.corrcoef(data1, data2)[0][1]
print(correlation)

# Output
0.98198050606",Lainnya,1626,"import ___ as np

data1 = [1,2,3,4,5]
data2 = [2,4,6,8,10]

correlation = np.corrcoef(data1, data2)[0][1]
print(correlation)

# Output
0.98198050606",numpy
Generate a Python program that requests a movie title and prints the synopsis of the movie.,Toy Story,"import requests

# Get the movie title from user input
title = input(""Enter a movie title: "")

# Make a request to the OMDb API
url = ""http://www.omdbapi.com/?t="" + title + ""&plot=full&apikey=<YOUR_API_KEY>

response = requests.get(url)
data = response.json()

# Print the synopsis
print(""Synopsis: "" + data[""Plot""])",Lainnya,1643,"import ___

# Get the movie title from user input
title = input(""Enter a movie title: "")

# Make a request to the OMDb API
url = ""http://www.omdbapi.com/?t="" + title + ""&plot=full&apikey=<YOUR_API_KEY>

response = requests.get(url)
data = response.json()

# Print the synopsis
print(""Synopsis: "" + data[""Plot""])",requests
Create a script in Python to find the square root of a number.,float x = 81.0,"import math
x = 81.0
# calculate the square root
print('The square root of %0.1f is %0.1f'%(x, math.sqrt(x)))",Lainnya,1644,"import ___
x = 81.0
# calculate the square root
print('The square root of %0.1f is %0.1f'%(x, math.sqrt(x)))",math
Generate a Python script that will extract all URLs from the given text.,The websites I like to visit are https://www.google.com and https://www.facebook.com,"import re

text = ""The websites I like to visit are https://www.google.com and https://www.facebook.com""

url_list = re.findall(r'(https?://\S+)', text)

print(url_list)",Lainnya,1650,"import ___

text = ""The websites I like to visit are https://www.google.com and https://www.facebook.com""

url_list = re.findall(r'(https?://\S+)', text)

print(url_list)",re
Create a script in Python that checks that a given URL is active and responding.,"url = ""http://www.example.com""","import requests

url = ""http://www.example.com""

try:
 request = requests.get(url)
 if request.status_code == 200:
 print(""URL is active and responding"")
except Exception as e:
 print(f""Error: {e}"")",Lainnya,1668,"import ___

url = ""http://www.example.com""

try:
 request = requests.get(url)
 if request.status_code == 200:
 print(""URL is active and responding"")
except Exception as e:
 print(f""Error: {e}"")",requests
Convert the given JSON data into python dictionary.,"{""key"": ""value""}","import json 

json_data = '{""key"": ""value""}'

pydict = json.loads(json_data) 
print (""Python dictionary:"", pydict)",Lainnya,1670,"import ___ 

json_data = '{""key"": ""value""}'

pydict = json.loads(json_data) 
print (""Python dictionary:"", pydict)",json
Construct a Python program to perform principal component analysis,A dataset of 10 rows and 3 columns,"from sklearn.decomposition import PCA

def pca_transformation(X):
    pca = PCA()
    X_pca = pca.fit_transform(X)
    return X_pca",Lainnya,1672,"from sklearn.decomposition import ___

def pca_transformation(X):
    pca = PCA()
    X_pca = pca.fit_transform(X)
    return X_pca",PCA
Create a python program to remove the python comments from a text,"# This is a python comment
print(""Hello world"") # This is another comment","import re

def remove_comments(text):
    regex = r""(\"".*?\""|\'.*?\')|(/\*.*?\*/|\#[^\r\n]*$)""
    clean_text = re.sub(regex, """", text, 0, re.MULTILINE).strip()
    return clean_text

remove_comments(""# This is a python comment\nprint(\""Hello world\"") # This is another comment"")
#output:
print(""Hello world"")",Lainnya,1681,"import ___

def remove_comments(text):
    regex = r""(\"".*?\""|\'.*?\')|(/\*.*?\*/|\#[^\r\n]*$)""
    clean_text = re.sub(regex, """", text, 0, re.MULTILINE).strip()
    return clean_text

remove_comments(""# This is a python comment\nprint(\""Hello world\"") # This is another comment"")
#output:
print(""Hello world"")",re
Compute a matrix multiplication of two given matrices A and B in Python.,"The matrices are A=[1, 2, 3; 4, 5, 6] and B=[1, 2; 3, 4; 5, 6].","import numpy as np 

A = np.array([[1,2,3], [4,5,6]])
B = np.array([[1,2], [3,4], [5,6]])

C = np.matmul(A, B)

print(C)
# Output 
# [[22 28], 
#  [49 64]]",Lainnya,1717,"import ___ as np 

A = np.array([[1,2,3], [4,5,6]])
B = np.array([[1,2], [3,4], [5,6]])

C = np.matmul(A, B)

print(C)
# Output 
# [[22 28], 
#  [49 64]]",numpy
Write a Python program to create a random password of length 10.,<noimport>,"import string 
import random

def generate_password(length): 
    password = """" 
    for i in range(length): 
        character = random.choice(
            string.ascii_letters + 
            string.digits + 
            string.punctuation)
        password += character
    return password

password = generate_password(10) 
print(password)",Lainnya,1737,"import ___ 
import random

def generate_password(length): 
    password = """" 
    for i in range(length): 
        character = random.choice(
            string.ascii_letters + 
            string.digits + 
            string.punctuation)
        password += character
    return password

password = generate_password(10) 
print(password)",string
Create a visualization using the Python library matplotlib that compares the sales of two products.,"Product1: [10, 15, 12, 18, 20]
Product2: [5, 8, 9, 10, 15]","import matplotlib.pyplot as plt

product1 = [10, 15, 12, 18, 20]
product2 = [5, 8, 9, 10, 15]

plt.plot(product1, marker='o', label='Product 1')
plt.plot(product2, marker='o', label='Product 2')

plt.title('Comparing sales of two products')
plt.xlabel('Products')
plt.ylabel('Sales')
plt.legend()
plt.show()",Lainnya,1766,"import ___.pyplot as plt

product1 = [10, 15, 12, 18, 20]
product2 = [5, 8, 9, 10, 15]

plt.plot(product1, marker='o', label='Product 1')
plt.plot(product2, marker='o', label='Product 2')

plt.title('Comparing sales of two products')
plt.xlabel('Products')
plt.ylabel('Sales')
plt.legend()
plt.show()",matplotlib
Develop a Python program to output the most common elements in a given collection,"collection = [1, 4, 5, 3, 4, 6, 5, 3, 4]","from collections import Counter 

def most_common (collection): 
	data = Counter(collection) 
	return data.most_common(1)[0] 

collection = [1, 4, 5, 3, 4, 6, 5, 3, 4]
assert most_common(collection) == (4, 3) 
print (""Most Common element is: "",most_common(collection))",Lainnya,1773,"from collections import ___ 

def most_common (collection): 
	data = Counter(collection) 
	return data.most_common(1)[0] 

collection = [1, 4, 5, 3, 4, 6, 5, 3, 4]
assert most_common(collection) == (4, 3) 
print (""Most Common element is: "",most_common(collection))",Counter
Write a Python program to parse a web page and extract text from its HTML tags.,"<html>
<head>
 <title>Example Web Page</title>
</head>
<body>
 <h1>This is an example web page</h1>
 <p>Welcome to our web page!</p>
</body>
</html>","from bs4 import BeautifulSoup
def parse_web_html(html):
 soup = BeautifulSoup(html, 'html.parser')
 text = soup.get_text()
 return text",Lainnya,1805,"from bs4 import ___
def parse_web_html(html):
 soup = BeautifulSoup(html, 'html.parser')
 text = soup.get_text()
 return text",BeautifulSoup
"Given the following data points, generate a polynomial equation using Python.","x = [-2, 0, 2]
y = [1, 4, 9]","import numpy as np

x = np.array([-2, 0, 2])
y = np.array([1, 4, 9])

z = np.polyfit(x, y, 2)
equation = np.poly1d(z)

print(equation)

# Output: 
#       2
# -6.66 x + 5.0 x + 1.0",Lainnya,1815,"import ___ as np

x = np.array([-2, 0, 2])
y = np.array([1, 4, 9])

z = np.polyfit(x, y, 2)
equation = np.poly1d(z)

print(equation)

# Output: 
#       2
# -6.66 x + 5.0 x + 1.0",numpy
Create a Python script to identify the frequency of words in a sentence.,"Sentence = ""This is a test sentence""","from collections import Counter

sentence = ""This is a test sentence""

#split the sentence into words
words = sentence.split()

#count the frequency of each word
word_frequency = Counter(words)

#print the results
print(word_frequency)",Lainnya,1825,"from collections import ___

sentence = ""This is a test sentence""

#split the sentence into words
words = sentence.split()

#count the frequency of each word
word_frequency = Counter(words)

#print the results
print(word_frequency)",Counter
Write a Python program to display a histogram of the frequencies of words in a given sentence.,"Sentence: ""My name is John""","import matplotlib.pyplot as plt 
  
# Data to plot 
labels = 'My', 'name', 'is', 'John'
sizes = [1, 1, 1, 1]

# Plot
plt.pie(sizes, labels=labels, 
        autopct='%1.1f%%', shadow=True, startangle=90) 

plt.axis('equal') 

plt.show()",Lainnya,1829,"import ___.pyplot as plt 
  
# Data to plot 
labels = 'My', 'name', 'is', 'John'
sizes = [1, 1, 1, 1]

# Plot
plt.pie(sizes, labels=labels, 
        autopct='%1.1f%%', shadow=True, startangle=90) 

plt.axis('equal') 

plt.show()",matplotlib
Automate the following UNIX command using  python.,echo password | sudo -S apt-get install vim,"import os

password = 'password'
os.system('echo ' + password + ' | sudo -S apt-get install vim')",Lainnya,1835,"import ___

password = 'password'
os.system('echo ' + password + ' | sudo -S apt-get install vim')",os
Transform the following shell script into a python program.,"#!/usr/bin/env bash
for i in *.txt; do
    echo ""Processing $i file...""
    cat $i
done","import sys
import os

for filename in os.listdir('.'):
    if filename.endswith('.txt'):
        print('Processing ' + filename + ' file...')
        with open(filename, 'r') as f:
            print(f.read())",Lainnya,1862,"import ___
import os

for filename in os.listdir('.'):
    if filename.endswith('.txt'):
        print('Processing ' + filename + ' file...')
        with open(filename, 'r') as f:
            print(f.read())",sys
Can you provide a machine learning algorithm in Python that performs sentiment analysis on a given text?,"Text: ""This product is simply incredible!""","from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentences = [""This product is simply incredible!""]

analyzer = SentimentIntensityAnalyzer()

for sentence in sentences:
    scores = analyzer.polarity_scores(sentence)
    print(""{:-<40} {}"".format(sentence, str(scores)))",Lainnya,1866,"from nltk.sentiment.vader import ___

sentences = [""This product is simply incredible!""]

analyzer = SentimentIntensityAnalyzer()

for sentence in sentences:
    scores = analyzer.polarity_scores(sentence)
    print(""{:-<40} {}"".format(sentence, str(scores)))",SentimentIntensityAnalyzer
Create a Python NLTK program to tokenize a given English text.,"Example text: ""This is a sample sentence for tokenizing.""","import nltk

# Input text
text = ""This is a sample sentence for tokenizing.""

# Tokenize sentences
tokens = nltk.word_tokenize(text)

# Print tokens
print(tokens)

# Output
['This', 'is', 'a', 'sample', 'sentence', 'for', 'tokenizing', '.']",Lainnya,1872,"import ___

# Input text
text = ""This is a sample sentence for tokenizing.""

# Tokenize sentences
tokens = nltk.word_tokenize(text)

# Print tokens
print(tokens)

# Output
['This', 'is', 'a', 'sample', 'sentence', 'for', 'tokenizing', '.']",nltk
Develop a program to remove all the comments from a Python code.,"import sys
# This code prints hello world
def main():
    print(""Hello World!"")","import sys

def main():
    print(""Hello World!"")",Lainnya,1882,"import ___

def main():
    print(""Hello World!"")",sys
Create a command line Python script to generate random numbers within a given range.,Minimum Number: 10 and Maximum Number: 25,"import random

min_num = 10
max_num = 25
 
# Generate a random number
rand_num = random.randint(min_num, max_num)
 
# Print the random number
print(rand_num)",Lainnya,1912,"import ___

min_num = 10
max_num = 25
 
# Generate a random number
rand_num = random.randint(min_num, max_num)
 
# Print the random number
print(rand_num)",random
"Create a DataFrame in Python Pandas using given dates, numbers, and strings.","dates = ['2013-01-01', '2013-01-02', '2013-01-03'] 
numbers = [1, 2, 3] 
strings = ['a', 'b', 'c']","import pandas as pd

# Create the dataframe
df = pd.DataFrame({'date': dates, 'number': numbers, 'string': strings})

df
   date  number string
0  2013-01-01       1      a
1  2013-01-02       2      b
2  2013-01-03       3      c",Lainnya,1970,"import ___ as pd

# Create the dataframe
df = pd.DataFrame({'date': dates, 'number': numbers, 'string': strings})

df
   date  number string
0  2013-01-01       1      a
1  2013-01-02       2      b
2  2013-01-03       3      c",pandas
Optimize a Python program using multiprocessing.,A program to find all prime numbers up to a given number n.,"from multiprocessing import Pool
import math

def is_prime(n):
    if n <= 1:
        return False
    for i in range(2, int(math.sqrt(n)) + 1):
        if n % i == 0:
            return False
    return True

def find_prime_numbers(n):
    primes = []
    with Pool(processes=4) as pool:
        primes = list(pool.map(is_prime, range(2, n)))
    return primes",Lainnya,1975,"from multiprocessing import ___
import math

def is_prime(n):
    if n <= 1:
        return False
    for i in range(2, int(math.sqrt(n)) + 1):
        if n % i == 0:
            return False
    return True

def find_prime_numbers(n):
    primes = []
    with Pool(processes=4) as pool:
        primes = list(pool.map(is_prime, range(2, n)))
    return primes",Pool
Create a Python program to parse a domain name and extract important information.,example.com,"import tldextract

def parse_domain_name(name):
    """"""Parses a domain name and extracts information such as the subdomain and the root domain.""""""
    extract = tldextract.extract(name)
    subdomain = extract.subdomain
    root_domain = extract.domain + '.' + extract.suffix
 
    return subdomain, root_domain",Lainnya,1988,"import ___

def parse_domain_name(name):
    """"""Parses a domain name and extracts information such as the subdomain and the root domain.""""""
    extract = tldextract.extract(name)
    subdomain = extract.subdomain
    root_domain = extract.domain + '.' + extract.suffix
 
    return subdomain, root_domain",tldextract
Create a Python code to decode an URL.,"""http://www.example.com/?param1=hello&param2=world""","import urllib.parse

def decode_url(url):
 parsed_url = urllib.parse.urlparse(url)
 return urllib.parse.parse_qs(parsed_url.query)

decode_url(""http://www.example.com/?param1=hello&param2=world"")",Lainnya,1989,"import ___.parse

def decode_url(url):
 parsed_url = urllib.parse.urlparse(url)
 return urllib.parse.parse_qs(parsed_url.query)

decode_url(""http://www.example.com/?param1=hello&param2=world"")",urllib
Construct a python visualization to display a bar chart of the results of some data.,"Array of word strings and the associated frequency 
[
  [""word1"", 5], 
  [""word2"", 8], 
  [""word3"", 3],
  [""word4"", 2],
]","import matplotlib.pyplot as plt

words = [""word1"", ""word2"", ""word3"", ""word4""]
frequencies = [5, 8, 3, 2]

plt.bar(words, frequencies)
plt.title(""Word Frequency Chart"")
plt.xlabel(""Words"")
plt.ylabel(""Frequency"")
plt.show()",Lainnya,1995,"import ___.pyplot as plt

words = [""word1"", ""word2"", ""word3"", ""word4""]
frequencies = [5, 8, 3, 2]

plt.bar(words, frequencies)
plt.title(""Word Frequency Chart"")
plt.xlabel(""Words"")
plt.ylabel(""Frequency"")
plt.show()",matplotlib
Write a Python program to classify a given sentence based on its sentiment.,"Input sentence: ""I hate Mondays"".","from textblob import TextBlob

input_sentence = ""I hate Mondays""
sentiment = TextBlob(input_sentence).sentiment.polarity

if sentiment > 0:
    print(""The sentiment is 'positive'"")
elif sentiment == 0:
    print(""The sentiment is 'neutral'"")
else:
    print(""The sentiment is 'negative'"")",Lainnya,2007,"from textblob import ___

input_sentence = ""I hate Mondays""
sentiment = TextBlob(input_sentence).sentiment.polarity

if sentiment > 0:
    print(""The sentiment is 'positive'"")
elif sentiment == 0:
    print(""The sentiment is 'neutral'"")
else:
    print(""The sentiment is 'negative'"")",TextBlob
Write a Python program to implement a decision tree using a given dataset.,"The dataset contains 10,000 examples and 5 features.","import numpy as np
from sklearn import tree

# Load the data
X = np.loadtxt('data.txt', delimiter=',')

# Create a decision tree model
clf = tree.DecisionTreeClassifier()
clf.fit(X, y)

# print the model tree 
tree.export_graphviz(clf, out_file=""model.dot"")",Lainnya,2015,"import ___ as np
from sklearn import tree

# Load the data
X = np.loadtxt('data.txt', delimiter=',')

# Create a decision tree model
clf = tree.DecisionTreeClassifier()
clf.fit(X, y)

# print the model tree 
tree.export_graphviz(clf, out_file=""model.dot"")",numpy
Implement webscraping with Python to extract content from a given website.,A website URL,"import requests
from bs4 import BeautifulSoup

# Fetch the website content
link = ""https://example.com""
data = requests.get(link)

# Parse the HTML content
soup = BeautifulSoup(data.text, 'html.parser')

# Extract all the <p> tags
content = soup.find_all('p')

# Print the content
for item in content:
    print(item.text)",Lainnya,2018,"import ___
from bs4 import BeautifulSoup

# Fetch the website content
link = ""https://example.com""
data = requests.get(link)

# Parse the HTML content
soup = BeautifulSoup(data.text, 'html.parser')

# Extract all the <p> tags
content = soup.find_all('p')

# Print the content
for item in content:
    print(item.text)",requests
Convert the given JSON data into Python dictionary.,"{""name"": ""John"", ""age"": 30, ""hobby"": ""running""}","import json

data = '{""name"": ""John"", ""age"": 30, ""hobby"": ""running""}'
dict_data = json.loads(data)

print(dict_data)",Lainnya,2062,"import ___

data = '{""name"": ""John"", ""age"": 30, ""hobby"": ""running""}'
dict_data = json.loads(data)

print(dict_data)",json
Can you create a web scraper in Python to extract the titles of articles from a newspaper website?,http://example.com/newspaper,"import requests
from bs4 import BeautifulSoup

url = ""http://example.com/newspaper""

# fetch data from the given URL
r = requests.get(url)

# create a BeautifulSoup object
soup = BeautifulSoup(r.content, ""lxml"")

# extract the title of all articles
for article_title in soup.find_all('h3', class_='title'):
    print(article_title.text)",Lainnya,2093,"import ___
from bs4 import BeautifulSoup

url = ""http://example.com/newspaper""

# fetch data from the given URL
r = requests.get(url)

# create a BeautifulSoup object
soup = BeautifulSoup(r.content, ""lxml"")

# extract the title of all articles
for article_title in soup.find_all('h3', class_='title'):
    print(article_title.text)",requests
Create a web scraper with Python that collects all the titles of posts from a website.,https://example.com,"import requests
from bs4 import BeautifulSoup

url = 'https://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

post_titles = [title.text for title in soup.find_all('h2', class_='post-title')]

for post_title in post_titles:
 print(post_title)",Lainnya,2111,"import ___
from bs4 import BeautifulSoup

url = 'https://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

post_titles = [title.text for title in soup.find_all('h2', class_='post-title')]

for post_title in post_titles:
 print(post_title)",requests
Generate a Python program that creates a word cloud from a given text.,Text: The quick brown fox jumps over the lazy dog.,"import matplotlib.pyplot as plt
from wordcloud import WordCloud
 
# Read the whole text.
text = 'The quick brown fox jumps over the lazy dog.'
 
# Generate a word cloud image
wordcloud = WordCloud().generate(text)
 
# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis(""off"")
plt.show()",Lainnya,2117,"import ___.pyplot as plt
from wordcloud import WordCloud
 
# Read the whole text.
text = 'The quick brown fox jumps over the lazy dog.'
 
# Generate a word cloud image
wordcloud = WordCloud().generate(text)
 
# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis(""off"")
plt.show()",matplotlib
Generate a python program to create a Pandas DataFrame using the following input data.,"Input:
data = {'Country':[""United States"", ""France"", ""China""], 
'Population': [330, 67, 13]}","import pandas as pd

# Create the data frame
data_frame = pd.DataFrame(data)
  
# Print the data frame
print(data_frame)",Lainnya,2124,"import ___ as pd

# Create the data frame
data_frame = pd.DataFrame(data)
  
# Print the data frame
print(data_frame)",pandas
Generate Python code to tokenize the given text.,Text: This is a sentence containing words,"import re

def tokenize_text(text):
    #Split the string into words on whitespace
    words = re.split(r'\s', text)
    #Punctuation patterns
    punctuation = re.compile(r'[.,!?;:]')
    #Create tokens
    tokens = [word.strip(punctuation.pattern) for word in words]
    #Return the list of tokens
    return tokens",Lainnya,2136,"import ___

def tokenize_text(text):
    #Split the string into words on whitespace
    words = re.split(r'\s', text)
    #Punctuation patterns
    punctuation = re.compile(r'[.,!?;:]')
    #Create tokens
    tokens = [word.strip(punctuation.pattern) for word in words]
    #Return the list of tokens
    return tokens",re
Create a Python script to scrape the HTML of a given web page and extract all of its headings and paragraphs.,URL of a web page,"import requests
from bs4 import BeautifulSoup


url = 'url'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')

headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
for heading in headings:
 print(heading.text)

paragraphs = soup.find_all('p')
for paragraph in paragraphs:
 print(paragraph.text)",Lainnya,2151,"import ___
from bs4 import BeautifulSoup


url = 'url'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')

headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
for heading in headings:
 print(heading.text)

paragraphs = soup.find_all('p')
for paragraph in paragraphs:
 print(paragraph.text)",requests
Create a Python program to extract the top 10 words from a text.,My name is John and I work as a software engineer.,"import re
from collections import Counter

def get_top_words(txt):
    words = re.findall(r'\w+', txt.lower())
    return Counter(words).most_common(10)

print(get_top_words('My name is John and I work as a software engineer.'))
# Output: [('i', 2), ('a', 1), ('as', 1), ('engineer', 1), ('john', 1), ('name', 1), ('software', 1), ('work', 1)]",Lainnya,2155,"import ___
from collections import Counter

def get_top_words(txt):
    words = re.findall(r'\w+', txt.lower())
    return Counter(words).most_common(10)

print(get_top_words('My name is John and I work as a software engineer.'))
# Output: [('i', 2), ('a', 1), ('as', 1), ('engineer', 1), ('john', 1), ('name', 1), ('software', 1), ('work', 1)]",re
Design a Python script to generate a report containing summaries of the data in a table.,Table name: orders,"import pandas as pd 

# Load data from the orders table 
orders = pd.read_csv('orders.csv')

# Generate summary statistics for the orders table 
summary_stats = orders.describe()

# Generate a report containing summary statistics 
report = open('report.html', 'w') 
report.write(summary_stats.to_html()) 
report.close()",Lainnya,2161,"import ___ as pd 

# Load data from the orders table 
orders = pd.read_csv('orders.csv')

# Generate summary statistics for the orders table 
summary_stats = orders.describe()

# Generate a report containing summary statistics 
report = open('report.html', 'w') 
report.write(summary_stats.to_html()) 
report.close()",pandas
Write a python script to get the filename from the given path,/Users/john/Documents/Github/myproject/myfile.py,"import os

def get_filename_from_path(path):
    return os.path.basename(path)

filename = get_filename_from_path('/Users/john/Documents/Github/myproject/myfile.py')
print(filename)",Lainnya,2170,"import ___

def get_filename_from_path(path):
    return os.path.basename(path)

filename = get_filename_from_path('/Users/john/Documents/Github/myproject/myfile.py')
print(filename)",os
Update the following Python program to validate a phone number.,"import re

phone = ""404-999-9999""

pattern = r""^[0-9]{3}-[0-9]{3}-[0-9]{4}$""

result = re.match(pattern, phone)

if result:
 print(""Valid phone number"")
else:
 print(""Invalid phone number"")","import re

phone = ""404-999-9999""

pattern = r""^[0-9]{3}-[0-9]{3}-[0-9]{4}$""

result = re.match(pattern, phone)

if result and len(phone) == 12:
 print(""Valid phone number"")
else:
 print(""Invalid phone number"")",Lainnya,2172,"import ___

phone = ""404-999-9999""

pattern = r""^[0-9]{3}-[0-9]{3}-[0-9]{4}$""

result = re.match(pattern, phone)

if result and len(phone) == 12:
 print(""Valid phone number"")
else:
 print(""Invalid phone number"")",re
Optimize an existing Python script by improving its runtime performance.,"import time

start = time.time()

def foo(): 
 for _ in range(1000): 
  print('Hello World')

foo()

end = time.time()

print('Time Taken:', end - start)","import time 

start = time.time()

def foo(): 
 for i in range(1000): 
  print('Hello World', i)

foo()

end = time.time()

print('Time Taken:', end - start)",Lainnya,2177,"import ___ 

start = time.time()

def foo(): 
 for i in range(1000): 
  print('Hello World', i)

foo()

end = time.time()

print('Time Taken:', end - start)",time
Write a python program to create a connection to a given database.,"Database Name: test
Username: admin
Password: admin123","import pymysql

# Create connection to database
conn = pymysql.connect(host=""localhost"",
                       user=""admin"",
                       passwd=""admin123"",
                       db=""test"")

# Create a cursor and execute a query
cur = conn.cursor()",Lainnya,2179,"import ___

# Create connection to database
conn = pymysql.connect(host=""localhost"",
                       user=""admin"",
                       passwd=""admin123"",
                       db=""test"")

# Create a cursor and execute a query
cur = conn.cursor()",pymysql
Write a Python script to download the html content of a given webpage,https://www.example.com/,"import requests

url = 'https://www.example.com/'
resp = requests.get(url)
html = resp.content",Lainnya,2204,"import ___

url = 'https://www.example.com/'
resp = requests.get(url)
html = resp.content",requests
Write a command line script to calculate the total number of people who attended a concert.,"Table: attendance

| name | age | arrival_time |
|------|-----|--------------|
| Jack | 20  | 9:00         |
| Jane | 21  | 8:45         |","#!/usr/bin/env python

import csv

total_attendees = 0
with open('attendance.csv', 'r') as csv_file:
    csv_reader = csv.reader(csv_file)
    for row in csv_reader:
        total_attendees += 1

print(f'Total Attendees: {total_attendees}')",Lainnya,2229,"#!/usr/bin/env python

import ___

total_attendees = 0
with open('attendance.csv', 'r') as csv_file:
    csv_reader = csv.reader(csv_file)
    for row in csv_reader:
        total_attendees += 1

print(f'Total Attendees: {total_attendees}')",csv
Write a Python program to generate a dataframe from a given JSON response.,"{""name"": ""John"", ""age"": 30, ""job"": ""Engineer"", ""salary"": 5000}","import pandas as pd

json_data = {""name"": ""John"", ""age"": 30, ""job"": ""Engineer"", ""salary"": 5000}

# Convert the data into a dataframe
df = pd.DataFrame(json_data, index=[0])

print(df)",Lainnya,2234,"import ___ as pd

json_data = {""name"": ""John"", ""age"": 30, ""job"": ""Engineer"", ""salary"": 5000}

# Convert the data into a dataframe
df = pd.DataFrame(json_data, index=[0])

print(df)",pandas
Write a Python code that gives the output of all possible combinations of given elements.,"[1, 2, 3]","from itertools import combinations

input_list = [1, 2, 3]
result = list(combinations(input_list, 3))

for combination in result:
    print(combination)",Lainnya,2288,"from itertools import ___

input_list = [1, 2, 3]
result = list(combinations(input_list, 3))

for combination in result:
    print(combination)",combinations
Create a machine learning algorithm in Python to classify a given dataset.,Dataset for classification,"from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100)
clf.fit(x_train, y_train)
predictions = clf.predict(x_test)",Lainnya,2308,"from sklearn.model_selection import ___
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100)
clf.fit(x_train, y_train)
predictions = clf.predict(x_test)",train_test_split
Write a Python script to fetch the sale price of a product from an online store.,"Website = www.productstore.com
ProductID = 12345","import requests
url = f'https://www.productstore.com/ProductID={ProductID}&format=json'

resp = requests.get(url)
data = resp.json()
sales_price = data['salesPrice']
print('The sale price of the product is {}'.format(sales_price))",Lainnya,2334,"import ___
url = f'https://www.productstore.com/ProductID={ProductID}&format=json'

resp = requests.get(url)
data = resp.json()
sales_price = data['salesPrice']
print('The sale price of the product is {}'.format(sales_price))",requests
Create a histogram of the following data using Python.,"data = [2, 3, 4, 6, 7, 8, 9, 10]","import matplotlib.pyplot as plt

data = [2, 3, 4, 6, 7, 8, 9, 10]

plt.hist(data)
plt.title('Histogram of Wind Direction')
plt.xlabel('Direction (degrees)')
plt.ylabel('Frequency')
plt.show()",Lainnya,2343,"import ___.pyplot as plt

data = [2, 3, 4, 6, 7, 8, 9, 10]

plt.hist(data)
plt.title('Histogram of Wind Direction')
plt.xlabel('Direction (degrees)')
plt.ylabel('Frequency')
plt.show()",matplotlib
Write a Python program to classify a dataset with 6 classes.,List of sample data,"import pandas as pd

# Load the dataset 
df = pd.read_csv('dataset.csv')

# Split the dataset into features and labels
X = df.drop('label', axis=1).values
y = df['label'].values

# Train the model
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X, y)

# Make predictions on the dataset
predictions = model.predict(X)",Lainnya,2358,"import ___ as pd

# Load the dataset 
df = pd.read_csv('dataset.csv')

# Split the dataset into features and labels
X = df.drop('label', axis=1).values
y = df['label'].values

# Train the model
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X, y)

# Make predictions on the dataset
predictions = model.predict(X)",pandas
Develop a biopython program which counts the number of occurrences of a given DNA sequence.,ATGGGCTAG,"from Bio.Seq import Seq
from Bio import SeqIO

seq = Seq(""ATGGGCTAG"")

# Count the occurrence of the DNA sequence
count = seq.count_overlap(seq)

print(count)",Lainnya,2373,"from Bio.Seq import ___
from Bio import SeqIO

seq = Seq(""ATGGGCTAG"")

# Count the occurrence of the DNA sequence
count = seq.count_overlap(seq)

print(count)",Seq
Design a python program to extract URLs from a website.,url = 'http://example.com',"from bs4 import BeautifulSoup
import requests

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
links = soup.select('a[href]')
for link in links:
    print(link['href'])",Lainnya,2378,"from bs4 import ___
import requests

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
links = soup.select('a[href]')
for link in links:
    print(link['href'])",BeautifulSoup
Modify a Python program to generate output in JSON format.,"dictionary = {
   ""name"": ""John"",
   ""age"": 30,
   ""car"": [""Ford"", ""BMW"", ""Fiat""]
}","import json

dictionary = {
   ""name"": ""John"",
   ""age"": 30,
   ""car"": [""Ford"", ""BMW"", ""Fiat""]
}

json_data = json.dumps(dictionary)
print(json_data) // Output: {""name"": ""John"", ""age"": 30, ""car"": [""Ford"", ""BMW"", ""Fiat""]}",Lainnya,2379,"import ___

dictionary = {
   ""name"": ""John"",
   ""age"": 30,
   ""car"": [""Ford"", ""BMW"", ""Fiat""]
}

json_data = json.dumps(dictionary)
print(json_data) // Output: {""name"": ""John"", ""age"": 30, ""car"": [""Ford"", ""BMW"", ""Fiat""]}",json
Add Python logging capabilities to a given Flask application.,"Example existing application:
from flask import Flask
app = Flask(name)

@app.route('/')
def index():
 return 'Hello World!'","import logging
import sys
from flask import Flask

app = Flask(name)

# Set up logging
app.logger.addHandler(logging.StreamHandler(sys.stdout))
app.logger.setLevel(logging.DEBUG)

@app.route('/')
def index():
 app.logger.info('Processing request to index')
 return 'Hello World!'",Lainnya,2387,"import ___
import sys
from flask import Flask

app = Flask(name)

# Set up logging
app.logger.addHandler(logging.StreamHandler(sys.stdout))
app.logger.setLevel(logging.DEBUG)

@app.route('/')
def index():
 app.logger.info('Processing request to index')
 return 'Hello World!'",logging
Write a Python program to collect data from an API and store the data in a SQL database.,"import requests

url = 'http://some_api.com/resource1/?format=json'","import sqlite3
import requests

# Connect to the database
db = sqlite3.connect('api_data.db')

# Create the statement
stmt = 'INSERT INTO api_data (data) VALUES (?)'

# Collect and save the data
data = requests.get(url).json()
db.execute(stmt, (data,))
db.commit()
db.close()",Lainnya,2392,"import ___
import requests

# Connect to the database
db = sqlite3.connect('api_data.db')

# Create the statement
stmt = 'INSERT INTO api_data (data) VALUES (?)'

# Collect and save the data
data = requests.get(url).json()
db.execute(stmt, (data,))
db.commit()
db.close()",sqlite3
Create an alternate version of a given program that produces the same output.,"import math
myString = ""Python Rocks!""
numRounds = math.ceil(len(myString) / 2)
for i in range(1, numRounds+1):
    print(myString[0:i])","import math
myString = ""Python Rocks!""
numRounds = math.floor(len(myString) / 2)
for i in reversed(range(1, numRounds+1)):
    print(myString[i-1::-1] + myString[i::])",Lainnya,2394,"import ___
myString = ""Python Rocks!""
numRounds = math.floor(len(myString) / 2)
for i in reversed(range(1, numRounds+1)):
    print(myString[i-1::-1] + myString[i::])",math
Create a program in Python to generate a random 2D matrix of size NxN containing integers between 1 and 10.,N = 10,"import random

n = 10

matrix = [[random.randint(1, 10) for _ in range(n)] for _ in range(n)]

print(matrix)",Lainnya,2414,"import ___

n = 10

matrix = [[random.randint(1, 10) for _ in range(n)] for _ in range(n)]

print(matrix)",random
Update the below Python code to run in multiprocess mode.,"import time

def add(a, b):
 return a + b

if __name__ == '__main__':
 start = time.time()
 result = add(2, 3)
 end = time.time()
 print(end-start)","import multiprocessing
import time

def add(a, b):
 return a + b

if __name__ == '__main__':
 pool = multiprocessing.Pool()
 start = time.time()
 result = pool.apply_async(add, (2, 3))
 pool.close()
 pool.join()
 end = time.time()
 print(result.get())
 print(end-start)",Lainnya,2427,"import ___
import time

def add(a, b):
 return a + b

if __name__ == '__main__':
 pool = multiprocessing.Pool()
 start = time.time()
 result = pool.apply_async(add, (2, 3))
 pool.close()
 pool.join()
 end = time.time()
 print(result.get())
 print(end-start)",multiprocessing
Automate the process of pulling data from a website using Python.,Website URL: http://www.example.com,"import requests
from bs4 import BeautifulSoup

url = 'http://www.example.com'

# Use requests to get website HTML
resp = requests.get(url)

# Parse the HTML using BeautifulSoup
soup = BeautifulSoup(resp.text, 'lxml')

# Extract data from HTML
data = []
for item in soup.find_all('div'):
 data.append(item.text)

# Print the data
for d in data:
 print(d)",Lainnya,2430,"import ___
from bs4 import BeautifulSoup

url = 'http://www.example.com'

# Use requests to get website HTML
resp = requests.get(url)

# Parse the HTML using BeautifulSoup
soup = BeautifulSoup(resp.text, 'lxml')

# Extract data from HTML
data = []
for item in soup.find_all('div'):
 data.append(item.text)

# Print the data
for d in data:
 print(d)",requests
Write a Python script to identify the words that contain more than one vowel in a given sentence.,Sentence: The quick brown fox jumped over the lazy dog.,"import re

sentence = ""The quick brown fox jumped over the lazy dog.""
pattern = r""\b(\w*[aeiou]\w*){2,}\b""

match = re.findall(pattern, sentence)
print(match)

# Output: ['quick', 'brown', 'jumped', 'over', 'lazy']",Lainnya,2437,"import ___

sentence = ""The quick brown fox jumped over the lazy dog.""
pattern = r""\b(\w*[aeiou]\w*){2,}\b""

match = re.findall(pattern, sentence)
print(match)

# Output: ['quick', 'brown', 'jumped', 'over', 'lazy']",re
"You need to optimise a given Python code, which takes a  3x3 matrix as input and outputs the inverse.","import numpy as np

def inverse_matrix(matrix):
    return np.linalg.inv(matrix)","import numpy as np

def inverse_matrix(matrix):
    det = np.linalg.det(matrix)
    if det == 0:
        return None 
    return np.dot(np.linalg.inv(matrix), 1/det)",Lainnya,2460,"import ___ as np

def inverse_matrix(matrix):
    det = np.linalg.det(matrix)
    if det == 0:
        return None 
    return np.dot(np.linalg.inv(matrix), 1/det)",numpy
Write a Python code to find the RMSE (root mean squared error) of two given lists.,"list1 = [1, 2, 3]
list2 = [2, 3, 4]","import math 

def rmse(list1, list2): 
    mean_square = 0
    for i in range(len(list1)):
        mean_square += math.pow((list1[i] - list2[i]), 2)
    return math.sqrt(mean_square/len(list1))

rmse_value = rmse(list1, list2)
print(""Root Mean Square Error is:"", rmse_value)",Lainnya,2492,"import ___ 

def rmse(list1, list2): 
    mean_square = 0
    for i in range(len(list1)):
        mean_square += math.pow((list1[i] - list2[i]), 2)
    return math.sqrt(mean_square/len(list1))

rmse_value = rmse(list1, list2)
print(""Root Mean Square Error is:"", rmse_value)",math
Design a Python program that analyses the sentiment of a given text.,"""I love programming""","import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""I love programming""

sid = SentimentIntensityAnalyzer()
scores = sid.polarity_scores(text)

if scores['compound'] > 0.0:
 print(""Positive sentiment"")
elif scores['compound'] == 0.0:
 print(""Neutral sentiment"")
else:
 print(""Negative sentiment"")

# Output: Positive sentiment",Lainnya,2510,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""I love programming""

sid = SentimentIntensityAnalyzer()
scores = sid.polarity_scores(text)

if scores['compound'] > 0.0:
 print(""Positive sentiment"")
elif scores['compound'] == 0.0:
 print(""Neutral sentiment"")
else:
 print(""Negative sentiment"")

# Output: Positive sentiment",nltk
Create a Python script that processes a sentence and classifies it as positive or negative.,The food was really bad.,"import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentence = ""The food was really bad.""

sentiment_analyzer = SentimentIntensityAnalyzer()
score = sentiment_analyzer.polarity_scores(sentence)

if score['compound'] > 0:
 sentiment = 'positive'
elif score['compound'] < 0:
 sentiment = 'negative'

print(f'The sentence is {sentiment}.')",Lainnya,2530,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentence = ""The food was really bad.""

sentiment_analyzer = SentimentIntensityAnalyzer()
score = sentiment_analyzer.polarity_scores(sentence)

if score['compound'] > 0:
 sentiment = 'positive'
elif score['compound'] < 0:
 sentiment = 'negative'

print(f'The sentence is {sentiment}.')",nltk
Create a web API in Python Flask that returns the factorial of the provided number.,5,"from flask import Flask, request

app = Flask(__name__)

@app.route('/factorial', methods=['POST'])
def factorial():
 num = request.json['num']
 result = 1
 for i in range(2, num + 1):
  result *= i
 return { 'factorial': result }

if __name__ == '__main__':
 app.run(debug=True)",Lainnya,2536,"from flask import ___, request

app = Flask(__name__)

@app.route('/factorial', methods=['POST'])
def factorial():
 num = request.json['num']
 result = 1
 for i in range(2, num + 1):
  result *= i
 return { 'factorial': result }

if __name__ == '__main__':
 app.run(debug=True)",Flask
"Design a Python program to find the difference between two provided times. The two times should be provided as strings in the format ""[HH:mm:ss]"".","time1 = ""08:30:15""
time2 = ""10:20:20""","from datetime import datetime

def time_diff(time1, time2):
 t1 = datetime.strptime(time1, ""%H:%M:%S"")
 t2 = datetime.strptime(time2, ""%H:%M:%S"")
 return (t2 - t1).total_seconds()

print(time_diff('08:30:15', '10:20:20')) // 7200.0",Lainnya,2545,"from datetime import ___

def time_diff(time1, time2):
 t1 = datetime.strptime(time1, ""%H:%M:%S"")
 t2 = datetime.strptime(time2, ""%H:%M:%S"")
 return (t2 - t1).total_seconds()

print(time_diff('08:30:15', '10:20:20')) // 7200.0",datetime
Write a Python program to get all the information associated with an IPv4 address.,"IPv4 address = ""8.8.8.8""","import socket
ip =  ""8.8.8.8""
address_info = socket.getaddrinfo(ip, None)

for info in address_info:
    print(""IP version :"", info[0])
    print(""IP address as string:"", info[4][0])
    print(""IP address as tuple:"", info[4])
    print(""IP protocol:"", info[6])",Lainnya,2549,"import ___
ip =  ""8.8.8.8""
address_info = socket.getaddrinfo(ip, None)

for info in address_info:
    print(""IP version :"", info[0])
    print(""IP address as string:"", info[4][0])
    print(""IP address as tuple:"", info[4])
    print(""IP protocol:"", info[6])",socket
Generate a python program that create a pandas dataframe from a dictionary column.,"data_dict = {'name': ['Bob', 'Alice', 'John'],
             'age': [18, 20, 19]}","import pandas as pd

df = pd.DataFrame(data_dict)",Lainnya,2562,"import ___ as pd

df = pd.DataFrame(data_dict)",pandas
Generate a random number in Python between 2 inclusive numbers.,"int min = 1;
int max = 6;","import random

num = random.randint(min, max)
print(num)",Lainnya,2597,"import ___

num = random.randint(min, max)
print(num)",random
Write a Python program to generate a bar chart visualizing a dataset.,"data = [3, 5, 2, 8, 9, 10]","import matplotlib.pyplot as plt

#create data
data = [3, 5, 2, 8, 9, 10]

#set plot size
plt.figure(figsize=(5, 2))

#generate the bar chart
plt.bar([str(i) for i in range(1, len(data)+1)], data)
plt.show()",Lainnya,2599,"import ___.pyplot as plt

#create data
data = [3, 5, 2, 8, 9, 10]

#set plot size
plt.figure(figsize=(5, 2))

#generate the bar chart
plt.bar([str(i) for i in range(1, len(data)+1)], data)
plt.show()",matplotlib
Create a hierarchical clustering algorithm in Python to group data points into clusters.,"data_points=[1,2,3,4,5]","import numpy as np
from scipy.cluster.hierarchy import dendrogram, linkage

# define the data points
data_points = np.array([1,2,3,4,5])

# create the linkage matrix
linkage_matrix = linkage(data_points, 'ward')

# generate the dendrogram
dendrogram(linkage_matrix)",Lainnya,2602,"import ___ as np
from scipy.cluster.hierarchy import dendrogram, linkage

# define the data points
data_points = np.array([1,2,3,4,5])

# create the linkage matrix
linkage_matrix = linkage(data_points, 'ward')

# generate the dendrogram
dendrogram(linkage_matrix)",numpy
Update a given MongoDB document using Python.,"db.collection.updateOne(
    { ""name"": ""John Doe"" },
    {
        $set:{
            ""age"": 28
        }
    }
)","import pymongo

# Open connection
client = pymongo.MongoClient(""mongodb://localhost:27017/"")
db = client[""mydatabase""]

# Update document
db.collection.update_one(
    {""name"": ""John Doe""},
    {""$set"": {""age"": 28}}
)

# Close connection
client.close()",Lainnya,2616,"import ___

# Open connection
client = pymongo.MongoClient(""mongodb://localhost:27017/"")
db = client[""mydatabase""]

# Update document
db.collection.update_one(
    {""name"": ""John Doe""},
    {""$set"": {""age"": 28}}
)

# Close connection
client.close()",pymongo
Create a web scraper using Python that collects data from the given URL - http://example.com/,http://example.com/,"import requests
from lxml import html

# Get the response
resp = requests.get('http://example.com/')

# Parse the response
doc = html.fromstring(resp.text)

# Extract the data
data = doc.xpath('//div/span/text()')

# Print out the data
print(data)",Lainnya,2632,"import ___
from lxml import html

# Get the response
resp = requests.get('http://example.com/')

# Parse the response
doc = html.fromstring(resp.text)

# Extract the data
data = doc.xpath('//div/span/text()')

# Print out the data
print(data)",requests
Write a Python code to handle this data loading task.,Problem: Load a CSV file that contains data from multiple sources and store it in a DataFrame.,"import pandas as pd

def load_data(csv_file):
    '''This function will load the CSV file and store the data in a DataFrame'''
    
    data = pd.read_csv(csv_file, sep=',', encoding='utf-8')
    return pd.DataFrame(data)",Lainnya,2637,"import ___ as pd

def load_data(csv_file):
    '''This function will load the CSV file and store the data in a DataFrame'''
    
    data = pd.read_csv(csv_file, sep=',', encoding='utf-8')
    return pd.DataFrame(data)",pandas
Create a python script that extracts the first ten words from a given text.,The quick brown fox jumps over the lazy dog,"import re

text = ""The quick brown fox jumps over the lazy dog""

# Extract words using a regular expression
words_list = re.findall(r""[\w']+"", text)

# Print the first ten words
print(words_list[:10])",Lainnya,2645,"import ___

text = ""The quick brown fox jumps over the lazy dog""

# Extract words using a regular expression
words_list = re.findall(r""[\w']+"", text)

# Print the first ten words
print(words_list[:10])",re
Rewrite the code in Python to improve its readability.,"import math
def area(r):
 return math.pi*r**2","import math

def calculate_area(radius):
    return math.pi * (radius ** 2)",Lainnya,2653,"import ___

def calculate_area(radius):
    return math.pi * (radius ** 2)",math
Convert the following Regular Expression matching code to a Regular Expression replacement code in Python.,"re_match = ""\w+@\w+\.\w+""","import re

re_match = ""\w+@\w+\.\w+""
re_replace = ""<valid email>""

print(re.sub(re_match, re_replace, ""my_email@example.com""))",Lainnya,2663,"import ___

re_match = ""\w+@\w+\.\w+""
re_replace = ""<valid email>""

print(re.sub(re_match, re_replace, ""my_email@example.com""))",re
Create a program in Python that prints out the first 10 prime numbers.,"""<noinput>""","import math

def is_prime(n):
    if n == 1:
        return False
    
    for i in range(2, int(math.sqrt(n)) + 1):
        if n % i == 0:
            return False
    return True

prime_nums = []

for i in range(2, 1000):  
    if is_prime(i):
        prime_nums.append(i)
        if len(prime_nums) == 10:
            break

for item in prime_nums:
    print(item)",Lainnya,2670,"import ___

def is_prime(n):
    if n == 1:
        return False
    
    for i in range(2, int(math.sqrt(n)) + 1):
        if n % i == 0:
            return False
    return True

prime_nums = []

for i in range(2, 1000):  
    if is_prime(i):
        prime_nums.append(i)
        if len(prime_nums) == 10:
            break

for item in prime_nums:
    print(item)",math
Create a Python program to find all the solutions to a given equation.,ax^2 + bx + c = 0,"import cmath

a = int(input(""Enter a: ""))
b = int(input(""Enter b: ""))
c = int(input(""Enter c: ""))

#calculate the discriminant
d = (b**2) - (4*a*c)

# find two solutions
sol1 = (-b-cmath.sqrt(d))/(2*a)
sol2 = (-b+cmath.sqrt(d))/(2*a)

print('The solutions are {0} and {1}'.format(sol1,sol2))",Lainnya,2689,"import ___

a = int(input(""Enter a: ""))
b = int(input(""Enter b: ""))
c = int(input(""Enter c: ""))

#calculate the discriminant
d = (b**2) - (4*a*c)

# find two solutions
sol1 = (-b-cmath.sqrt(d))/(2*a)
sol2 = (-b+cmath.sqrt(d))/(2*a)

print('The solutions are {0} and {1}'.format(sol1,sol2))",cmath
Can you create a Python script to extract email addresses from a raw text?,"""John Doe john@example.com, Jane Doe jane@example.com, Kevin Smith kevin@example.com""","import re

text = ""John Doe john@example.com, Jane Doe jane@example.com, Kevin Smith kevin@example.com""

emails = re.findall(r""[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+"",
                    text)

print(emails) # ['john@example.com', 'jane@example.com', 'kevin@example.com']",Lainnya,2692,"import ___

text = ""John Doe john@example.com, Jane Doe jane@example.com, Kevin Smith kevin@example.com""

emails = re.findall(r""[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+"",
                    text)

print(emails) # ['john@example.com', 'jane@example.com', 'kevin@example.com']",re
Design a Python program to generate a random password containing both lowercase and uppercase characters.,<no input>,"import random
import string

def generate_random_password():
  charset = string.ascii_letters + string.digits
  return ''.join(random.sample(charset, 8))

print(generate_random_password())",Lainnya,2700,"import ___
import string

def generate_random_password():
  charset = string.ascii_letters + string.digits
  return ''.join(random.sample(charset, 8))

print(generate_random_password())",random
Create a Python program that takes an email message as input and prints the sender's email address.,"Email Message:
From: ""John Doe"" <john.doe@example.com>
To: ""Jane Doe"" <jane.doe@example.com>
Subject: Example Email","import re

email_message = """""" 
From: ""John Doe"" <john.doe@example.com>
To: ""Jane Doe"" <jane.doe@example.com>
Subject: Example Email
""""""

sender_email = re.findall(r'From: .+?<(.+?)>', email_message)

print('Sender\'s email address:', sender_email[0])",Lainnya,2704,"import ___

email_message = """""" 
From: ""John Doe"" <john.doe@example.com>
To: ""Jane Doe"" <jane.doe@example.com>
Subject: Example Email
""""""

sender_email = re.findall(r'From: .+?<(.+?)>', email_message)

print('Sender\'s email address:', sender_email[0])",re
Create a Python script to scrape a website and extract the main content of any webpage.,URL: www.example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://www.example.com""
html = requests.get(url).content
soup = BeautifulSoup(html, 'html.parser')

content = soup.find(""div"", {""class"": ""main-content""}).text

print(content)",Lainnya,2720,"import ___
from bs4 import BeautifulSoup

url = ""https://www.example.com""
html = requests.get(url).content
soup = BeautifulSoup(html, 'html.parser')

content = soup.find(""div"", {""class"": ""main-content""}).text

print(content)",requests
Write a Python program to convert a unix timestamp to UTC time.,1594842400,"import time

timestamp = 1594842400
utc_time = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(timestamp))

print(utc_time) # Output: 2020-07-17 02:00:00",Lainnya,2737,"import ___

timestamp = 1594842400
utc_time = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(timestamp))

print(utc_time) # Output: 2020-07-17 02:00:00",time
Create a Python script to create a data visualisation of the data provided.,"[5, 10, 15, 20, 25, 30, 35, 40, 45]","import matplotlib.pyplot as plt 
data = [5, 10, 15, 20, 25, 30, 35, 40, 45]
plt.plot(data) 

# formatting the text
plt.title('Data Visualisation') 
plt.xlabel('Data Points') 
plt.ylabel('Value') 

# function to show the plot 
plt.show()",Lainnya,2768,"import ___.pyplot as plt 
data = [5, 10, 15, 20, 25, 30, 35, 40, 45]
plt.plot(data) 

# formatting the text
plt.title('Data Visualisation') 
plt.xlabel('Data Points') 
plt.ylabel('Value') 

# function to show the plot 
plt.show()",matplotlib
Write a Python program to generate a random permutation of a given sequence.,"sequence = [1, 2, 3]","from random import shuffle

sequence = [1, 2, 3]
shuffle(sequence)
print(sequence)",Lainnya,2778,"from random import ___

sequence = [1, 2, 3]
shuffle(sequence)
print(sequence)",shuffle
Create a Python program to log the current time (in the given timezone) every 20 minutes.,Timezone: America/Los_Angeles,"import time
import datetime
from pytz import timezone

def logtime(tz):
 while True:
 currtime = datetime.datetime.now(tz)
 print(""The current time is"", currtime.strftime(""%H:%M:%S""))
 time.sleep(60 * 20)

logtime(timezone('America/Los_Angeles'))",Lainnya,2793,"import ___
import datetime
from pytz import timezone

def logtime(tz):
 while True:
 currtime = datetime.datetime.now(tz)
 print(""The current time is"", currtime.strftime(""%H:%M:%S""))
 time.sleep(60 * 20)

logtime(timezone('America/Los_Angeles'))",time
Perform sentiment analysis on a given text using Python.,This movie was an amazing experience!,"from textblob import TextBlob

text = ""This movie was an amazing experience!""
blob = TextBlob(text)
print(""Sentiment score: "", blob.sentiment.polarity)",Lainnya,2799,"from textblob import ___

text = ""This movie was an amazing experience!""
blob = TextBlob(text)
print(""Sentiment score: "", blob.sentiment.polarity)",TextBlob
Write a Python program to scrape the text from a web page and remove all the html tags.,<p>This is a sample web page.<br>This text has <b>some</b> <i>html</i> tags.</p>,"import re

text = ""<p>This is a sample web page.<br>This text has <b>some</b> <i>html</i> tags.</p>""

cleaned_text = re.sub(r'<.*?>', '', text)

print(cleaned_text)
# Output: This is a sample web page.This text has some html tags.",Lainnya,2802,"import ___

text = ""<p>This is a sample web page.<br>This text has <b>some</b> <i>html</i> tags.</p>""

cleaned_text = re.sub(r'<.*?>', '', text)

print(cleaned_text)
# Output: This is a sample web page.This text has some html tags.",re
Create a vectorized implementation in Python to solve the given problem.,"def add(a, b):
    c = []
    for i in range(len(a)):
        c.append(a[i] + b[i])
    return c","import numpy as np
def add_vector(a, b):
    return np.add(a,b)",Lainnya,2808,"import ___ as np
def add_vector(a, b):
    return np.add(a,b)",numpy
Construct a Python program that shuffles a deck of cards.,A standard deck of cards with 52 cards,"import random

# A standard deck of cards with 52 cards
deck = [2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A', 
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A',
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A',
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A']

# Shuffle the deck
random.shuffle(deck)
print(deck)",Lainnya,2814,"import ___

# A standard deck of cards with 52 cards
deck = [2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A', 
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A',
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A',
        2, 3, 4, 5, 6, 7, 8, 9, 10, 
        'J', 'Q', 'K', 'A']

# Shuffle the deck
random.shuffle(deck)
print(deck)",random
Create a Python program to analyze the sentiment of a given sentence.,sentence = 'I am very happy to be here',"from textblob import TextBlob

sentence = 'I am very happy to be here'
sentiment = TextBlob(sentence).polarity

if sentiment > 0:
    print(""Sentiment: Positive"")
elif sentiment == 0:
    print(""Sentiment: Neutral"")
else:
    print(""Sentiment: Negative"")",Lainnya,2817,"from textblob import ___

sentence = 'I am very happy to be here'
sentiment = TextBlob(sentence).polarity

if sentiment > 0:
    print(""Sentiment: Positive"")
elif sentiment == 0:
    print(""Sentiment: Neutral"")
else:
    print(""Sentiment: Negative"")",TextBlob
Write a python script to extract the text from a HTML page and count the number of words.,"<html>
<head>
    <title>My Page</title>
</head>
<body>
    <p>This is a test page</p>
</body>
</html>","from bs4 import BeautifulSoup
import re

html_doc = <input>
soup = BeautifulSoup(html_doc, 'html.parser')
text = soup.get_text()
words = re.findall(r'\w+', text)
print (len(words))",Lainnya,2818,"from bs4 import ___
import re

html_doc = <input>
soup = BeautifulSoup(html_doc, 'html.parser')
text = soup.get_text()
words = re.findall(r'\w+', text)
print (len(words))",BeautifulSoup
Create a Python program to classify the digits in a dataset,"Features: [0.25, 0.33, 0.46, 0.83, 0.14]
Labels: [0, 0, 1, 1, 0]","import numpy as np 
from sklearn.svm import SVC 

features = np.array([[0.25, 0.33, 0.46, 0.83, 0.14]]) 
labels = np.array([0, 0, 1, 1, 0]) 
clf = SVC() 
clf.fit(features, labels) 

# predicting the class of the following data 
test_data = np.array([[0.36, 0.22, 0.91, 0.81, 0.12]]) 
result = clf.predict(test_data) 
print(result)",Lainnya,2820,"import ___ as np 
from sklearn.svm import SVC 

features = np.array([[0.25, 0.33, 0.46, 0.83, 0.14]]) 
labels = np.array([0, 0, 1, 1, 0]) 
clf = SVC() 
clf.fit(features, labels) 

# predicting the class of the following data 
test_data = np.array([[0.36, 0.22, 0.91, 0.81, 0.12]]) 
result = clf.predict(test_data) 
print(result)",numpy
Optimize a Python script's performance by refactoring the code to use multiprocessing.,"def process_list_data(data):
 for record in data:
  # Process the data

list_data = [1,2,3,4,5]

process_list_data(list_data)","from multiprocessing import Pool

def process_data(record):
 # Process the data

def process_list_data(data):
 with Pool() as p:
 p.map(process_data, data)

list_data = [1,2,3,4,5]

process_list_data(list_data)",Lainnya,2828,"from multiprocessing import ___

def process_data(record):
 # Process the data

def process_list_data(data):
 with Pool() as p:
 p.map(process_data, data)

list_data = [1,2,3,4,5]

process_list_data(list_data)",Pool
Design a program that takes a date as input and calculates the day of the week that date falls on.,31-05-20,"#!/usr/bin/env python3

import datetime

def dayOfWeek(date):
   year,month,day = map(int,date.split('/'))
   dayNumber = datetime.date(year, month, day).weekday()
 
   return [""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"", ""Sunday""][dayNumber]",Lainnya,2844,"#!/usr/bin/env python3

import ___

def dayOfWeek(date):
   year,month,day = map(int,date.split('/'))
   dayNumber = datetime.date(year, month, day).weekday()
 
   return [""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"", ""Sunday""][dayNumber]",datetime
Write a Python program that can detect the language of a given piece of text.,"The text is: ""Bonjour tout le monde""","import detect_language

text = ""Bonjour tout le monde""
language = detect_language.detect(text)
print(language) # fr",Lainnya,2853,"import ___

text = ""Bonjour tout le monde""
language = detect_language.detect(text)
print(language) # fr",detect_language
Create a Python program that takes a sentence as an input and outputs all the words with their part of speech.,This is a sentence.,"import nltk

sentence = 'This is a sentence.'
words = nltk.word_tokenize(sentence)

for word in words:
 print(f'{word}: {nltk.pos_tag([word])[0][1]}')",Lainnya,2862,"import ___

sentence = 'This is a sentence.'
words = nltk.word_tokenize(sentence)

for word in words:
 print(f'{word}: {nltk.pos_tag([word])[0][1]}')",nltk
Modify the given Python program to optimize the memory allocation and improve the execution time of the program,"import pandas as pd
data = pd.read_csv('dataset.csv')","import pandas as pd

# Load the dataset with memory optimization
data = pd.read_csv('dataset.csv', low_memory=True)

# Optimize the data to reduce the size 
data = data.drop_duplicates(keep=False)

# Optimize the data to increase the performance 
data = data.apply(pd.to_numeric, errors='coerce')",Lainnya,2868,"import ___ as pd

# Load the dataset with memory optimization
data = pd.read_csv('dataset.csv', low_memory=True)

# Optimize the data to reduce the size 
data = data.drop_duplicates(keep=False)

# Optimize the data to increase the performance 
data = data.apply(pd.to_numeric, errors='coerce')",pandas
"Given a URL, write a Python script to fetch and decode the HTML web page using the `requests` library.","""https://example.org/""","import requests

url = ""https://example.org/""

response = requests.get(url)

if response.status_code == 200:
  html_page = response.content.decode('utf-8')",Lainnya,2880,"import ___

url = ""https://example.org/""

response = requests.get(url)

if response.status_code == 200:
  html_page = response.content.decode('utf-8')",requests
Create a Python program to visualize the performance of different stock prices over a period of time.,A list of stock prices for a given company over the past 10 years,"import matplotlib.pyplot as plt
 
# Read in data
data = []
with open('stock_prices.txt') as f:
    data = [float(x) for x in f.read().split()]

# Plot data
plt.plot(range(1, len(data)+1), data)
plt.title('Stock Price Over Time')
plt.xlabel('Time')
plt.ylabel('Price')
plt.show()",Lainnya,2895,"import ___.pyplot as plt
 
# Read in data
data = []
with open('stock_prices.txt') as f:
    data = [float(x) for x in f.read().split()]

# Plot data
plt.plot(range(1, len(data)+1), data)
plt.title('Stock Price Over Time')
plt.xlabel('Time')
plt.ylabel('Price')
plt.show()",matplotlib
Compare two strings using Python and output the similarity score between them.,"String 1: hello world 
String 2: hey world","import difflib

def compare_strings(str1, str2):
 score = difflib.SequenceMatcher(None, str1, str2).ratio() 
 print(""Similarity score is:"", score)

compare_strings(""hello world"", ""hey world"") # Output: Similarity score is: 0.909",Lainnya,2906,"import ___

def compare_strings(str1, str2):
 score = difflib.SequenceMatcher(None, str1, str2).ratio() 
 print(""Similarity score is:"", score)

compare_strings(""hello world"", ""hey world"") # Output: Similarity score is: 0.909",difflib
Modify a Python program to optimize its performance and handle errors gracefully.,A Python program to read a file and print its contents,"# Library import
import os

# Path of the file
file_name = ""myfile.txt""

# Open file
try:
  with open(file_name, 'r') as f:

    # Read file
    contents = f.read()

    # Print file
    print(contents)

except IOError:
  print('Error: file not found!')

finally:
  if f:
    f.close()",Lainnya,2909,"# Library import ___ os

# Path of the file
file_name = ""myfile.txt""

# Open file
try:
  with open(file_name, 'r') as f:

    # Read file
    contents = f.read()

    # Print file
    print(contents)

except IOError:
  print('Error: file not found!')

finally:
  if f:
    f.close()",import
Create a short Python program that prints out the current date and time in the specified format.,"Format - ""YYYY-MM-DD HH:MM:SS""","import time

time_now = time.strftime(""%Y-%m-%d %H:%M:%S"")
print(time_now)",Lainnya,2924,"import ___

time_now = time.strftime(""%Y-%m-%d %H:%M:%S"")
print(time_now)",time
Write a Python program to make a prediction using a Support Vector Machine (SVM),"X = [[0, 0], [1, 1]]
y = [0, 1]","import numpy as np
from sklearn import svm

X = np.array([[0, 0], [1, 1]])
y = np.array([0, 1])

clf = svm.SVC(kernel='linear')
clf.fit(X, y)

prediction = clf.predict([[2., 2.]])
print(prediction)",Lainnya,2948,"import ___ as np
from sklearn import svm

X = np.array([[0, 0], [1, 1]])
y = np.array([0, 1])

clf = svm.SVC(kernel='linear')
clf.fit(X, y)

prediction = clf.predict([[2., 2.]])
print(prediction)",numpy
Generate a python program that matches regular expression pattern.,"pattern = ""\d+""
text = ""I have 3 cats and 5 dogs""","import re

def regex_match(pattern, text):
    regex = re.compile(pattern)
    matches = regex.findall(text)
    return matches",Lainnya,2981,"import ___

def regex_match(pattern, text):
    regex = re.compile(pattern)
    matches = regex.findall(text)
    return matches",re
Compress a given folder using GZip in Python.,folder /files,"import gzip 
import shutil 

# Source files to compress 
source = '/files'
  
# Destination to store compressed files 
destination = '/files/compressed'
  
# set the compression level 
compression_level = 3

shutil.make_archive(destination, 'gz', source, compression_level)",Lainnya,2990,"import ___ 
import shutil 

# Source files to compress 
source = '/files'
  
# Destination to store compressed files 
destination = '/files/compressed'
  
# set the compression level 
compression_level = 3

shutil.make_archive(destination, 'gz', source, compression_level)",gzip
Create a web scrapper in Python to fetch data from a website. The scrapper should accept a URL and fetch the data and output it in a JSON format.,URL to example website: https://www.example.com,"import requests 
import json

url = ""https://www.example.com""

response = requests.get(url)
if response.status_code == 200:
    response_data = response.text
    parsed_data = json.loads(response_data)
    print(parsed_data)",Lainnya,3038,"import ___ 
import json

url = ""https://www.example.com""

response = requests.get(url)
if response.status_code == 200:
    response_data = response.text
    parsed_data = json.loads(response_data)
    print(parsed_data)",requests
Generate a Python script to download the source code of a given web page.,"url = ""https://www.example.com""","import urllib.request

def download_webpage_source(url):
    '''This function will download the source code of a given web page'''

    response = urllib.request.urlopen(url)
    data = response.read()
    text = data.decode('utf-8')

    return text",Lainnya,3043,"import ___.request

def download_webpage_source(url):
    '''This function will download the source code of a given web page'''

    response = urllib.request.urlopen(url)
    data = response.read()
    text = data.decode('utf-8')

    return text",urllib
Generate a python program to generate a json response based on following specification,"The response should contain the following keys:
- name
- email
- age","import json

data = {
    'name': 'John Doe',
    'email': 'john@example.com',
    'age': 32
}

json_data = json.dumps(data)
print(json_data)",Lainnya,3055,"import ___

data = {
    'name': 'John Doe',
    'email': 'john@example.com',
    'age': 32
}

json_data = json.dumps(data)
print(json_data)",json
Apply a filter in Python that removes any stop words from a text,"text: ""This is a test to see how the filter works""","from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 

def filter_stop_words(text):
    word_tokens = word_tokenize(text)
    filtered_text = [w for w in word_tokens if not w in stopwords.words('english')]
    return ' '.join(filtered_text)",Lainnya,3063,"from nltk.corpus import ___ 
from nltk.tokenize import word_tokenize 

def filter_stop_words(text):
    word_tokens = word_tokenize(text)
    filtered_text = [w for w in word_tokens if not w in stopwords.words('english')]
    return ' '.join(filtered_text)",stopwords
Construct a Python program to generate a random password using alphanumeric characters and special symbols.,Password Length = 8,"import random
import string

def generate_password(length):
    chars = string.ascii_letters + string.digits + string.punctuation
    return ''.join(random.choice(chars) for _ in range(length))

print(generate_password(8))",Lainnya,3070,"import ___
import string

def generate_password(length):
    chars = string.ascii_letters + string.digits + string.punctuation
    return ''.join(random.choice(chars) for _ in range(length))

print(generate_password(8))",random
Create a python program that outputs a given number of random numbers within a given range,"max_num = 100
num_of_nums = 10","import random

def get_n_random_numbers(max_num, num_of_nums):
    random_numbers = []
    for _ in range(num_of_nums):
        random_numbers.append(random.randrange(max_num))
    return random_numbers",Lainnya,3109,"import ___

def get_n_random_numbers(max_num, num_of_nums):
    random_numbers = []
    for _ in range(num_of_nums):
        random_numbers.append(random.randrange(max_num))
    return random_numbers",random
Write a python program to a calculate the area of a circle given its radius.,radius = 8,"import math

radius = 8
area = math.pi * radius * radius
print(area)",Lainnya,3111,"import ___

radius = 8
area = math.pi * radius * radius
print(area)",math
Write a Python program to call a given API with an input parameter and store the result in a variable.,"API URL: ""https://example.org/api?name=test""","import requests

url = 'https://example.org/api?name=test'
response = requests.get(url)
data = response.json()
result = data['result']",Lainnya,3128,"import ___

url = 'https://example.org/api?name=test'
response = requests.get(url)
data = response.json()
result = data['result']",requests
Create a PDF document from a Word document using Python.,word file,"import win32com.client

# word file to be converted
wordFile =  r'filename.docx'

# Open the word file
word = win32com.client.Dispatch(""Word.Application"")
doc = word.Documents.Open(wordFile)

# Set the pdf parameters
pdf_format_id = 17
file_name = r'filename.pdf'

# Save the file as pdf
doc.SaveAs(file_name, FileFormat=pdf_format_id)

# Close the word file
word.Quit()",Lainnya,3140,"import ___.client

# word file to be converted
wordFile =  r'filename.docx'

# Open the word file
word = win32com.client.Dispatch(""Word.Application"")
doc = word.Documents.Open(wordFile)

# Set the pdf parameters
pdf_format_id = 17
file_name = r'filename.pdf'

# Save the file as pdf
doc.SaveAs(file_name, FileFormat=pdf_format_id)

# Close the word file
word.Quit()",win32com
Edit a given Python program to use regex to extract the phone numbers from the text.,"import re

txt = ""My number is 666-111-1111 and my office number is 888-666-1234.""","import re

txt = ""My number is 666-111-1111 and my office number is 888-666-1234.""

phone_numbers = re.findall(r'\d{3}-\d{3}-\d{4}', txt)
print(phone_numbers) # output: ['666-111-1111', '888-666-1234']",Lainnya,3187,"import ___

txt = ""My number is 666-111-1111 and my office number is 888-666-1234.""

phone_numbers = re.findall(r'\d{3}-\d{3}-\d{4}', txt)
print(phone_numbers) # output: ['666-111-1111', '888-666-1234']",re
"Write a Python program to query all 10,000 rows in the provided SQL table.","Table ""Example"" with 10,000 rows","import sqlite3

# connect to SQL database
db = sqlite3.connect('example.db')

# create cursor
cur = db.cursor()

# execute query
cur.execute('SELECT * FROM ""example""')

# fetch all rows
rows = cur.fetchall()

# display all rows
for row in rows:
    print row",Lainnya,3208,"import ___

# connect to SQL database
db = sqlite3.connect('example.db')

# create cursor
cur = db.cursor()

# execute query
cur.execute('SELECT * FROM ""example""')

# fetch all rows
rows = cur.fetchall()

# display all rows
for row in rows:
    print row",sqlite3
Write a Python program that prints out all possible words from a collection of letters.,"letters = [""a"", ""b"", ""t""]","import itertools

letters = [""a"", ""b"", ""t""]
words = []

# we use itertool's permutations to generate all combinations of letters
Result = itertools.permutations(letters, 3)

# we iterate through the output of itertool's permutation
# and append it to result list of words
for ele in list(Result):
    words.append(''.join(ele))

# printing the result
print(words)",Lainnya,3238,"import ___

letters = [""a"", ""b"", ""t""]
words = []

# we use itertool's permutations to generate all combinations of letters
Result = itertools.permutations(letters, 3)

# we iterate through the output of itertool's permutation
# and append it to result list of words
for ele in list(Result):
    words.append(''.join(ele))

# printing the result
print(words)",itertools
Design a script in Python to scrape text data from a particular web page.,url = 'https://en.wikipedia.org/wiki/Movie',"from bs4 import BeautifulSoup
import requests

# Get the HTML of the page
html_content = requests.get(url).text

# Create the Soup object
soup = BeautifulSoup(html_content, 'lxml')

# Find the text data
data = soup.find_all('p')

# Print the text data
for element in data:
      print(element.text)",Lainnya,3267,"from bs4 import ___
import requests

# Get the HTML of the page
html_content = requests.get(url).text

# Create the Soup object
soup = BeautifulSoup(html_content, 'lxml')

# Find the text data
data = soup.find_all('p')

# Print the text data
for element in data:
      print(element.text)",BeautifulSoup
Create a Python program to convert raw JSON data into a Pandas DataFrame.,"{
    ""Name"": ""John Smith"",
    ""Age"": 25,
    ""Location"": ""New York, USA""
}","import json
import pandas as pd

data = {
 ""Name"": ""John Smith"",
 ""Age"": 25,
 ""Location"": ""New York, USA""
}

df = pd.DataFrame.from_dict(json.loads(json.dumps(data)))
print(df)

Output
   Name  Age      Location
0  John   25  New York, USA",Lainnya,3298,"import ___
import pandas as pd

data = {
 ""Name"": ""John Smith"",
 ""Age"": 25,
 ""Location"": ""New York, USA""
}

df = pd.DataFrame.from_dict(json.loads(json.dumps(data)))
print(df)

Output
   Name  Age      Location
0  John   25  New York, USA",json
Model a logistic regression algorithm using Python to predict a binary target: true or false.,"[[0,0], [0,1], [1,0], [1,1]], [1,1,0,1]","import numpy as np

X = np.array([[0,0], [0,1], [1,0], [1,1]])
y = np.array([1,1,0,1])

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=0).fit(X, y)

print(""Prediction:"", clf.predict([[2,2]]))",Lainnya,3301,"import ___ as np

X = np.array([[0,0], [0,1], [1,0], [1,1]])
y = np.array([1,1,0,1])

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=0).fit(X, y)

print(""Prediction:"", clf.predict([[2,2]]))",numpy
Develop a program to track the stock price using the Yahoo Finance API in Python,Yahoo API token: abc123,"import yfinance as yf

# Get the data of the stocks for the given ticker
ticker = ""AAPL""
data = yf.Ticker(ticker)

# The Yahoo API token
token = ""abc123""

# Get historical data for the ticker
data.history(period=""1mo"", token=token)

# Print the price
print(data.history(token=token)[""Close""].iloc[-1})",Lainnya,3338,"import ___ as yf

# Get the data of the stocks for the given ticker
ticker = ""AAPL""
data = yf.Ticker(ticker)

# The Yahoo API token
token = ""abc123""

# Get historical data for the ticker
data.history(period=""1mo"", token=token)

# Print the price
print(data.history(token=token)[""Close""].iloc[-1})",yfinance
Create a Python program to generate a random password of length n.,10,"import random

def generate_password(length):
  characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!@#$%^&*(){}[]?/'
  password = ''
  for c in range(length):
    password += random.choice(characters)
  return password

length = 10
password = generate_password(length)
print(password)",Lainnya,3350,"import ___

def generate_password(length):
  characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!@#$%^&*(){}[]?/'
  password = ''
  for c in range(length):
    password += random.choice(characters)
  return password

length = 10
password = generate_password(length)
print(password)",random
Create a Python script that generates a random password of length n with a minimum required characters.,n = 8,"import string
import random

def generate_password(length):
    password_characters = string.ascii_letters + string.digits + string.punctuation
    return ''.join(random.choice(password_characters) for i in range(length))

print(generate_password(8))",Lainnya,3351,"import ___
import random

def generate_password(length):
    password_characters = string.ascii_letters + string.digits + string.punctuation
    return ''.join(random.choice(password_characters) for i in range(length))

print(generate_password(8))",string
Develop a unit test in Python to verify correctness of an algorithm.,"def algorithm(arr):
	sum = 0
	for i in range(len(arr)):
		sum += arr[i]
	return sum","import unittest

class TestAlgorithm(unittest.TestCase):
    
    def test_algorithm(self):
        10 = algorithm([1, 2, 3, 4])
        self.assertEqual(10, 10)
        
        40 = algorithm([10, 10, 10, 10])
        self.assertEqual(40, 40)

if __name__ == '__main__':
    unittest.main()",Lainnya,3376,"import ___

class TestAlgorithm(unittest.TestCase):
    
    def test_algorithm(self):
        10 = algorithm([1, 2, 3, 4])
        self.assertEqual(10, 10)
        
        40 = algorithm([10, 10, 10, 10])
        self.assertEqual(40, 40)

if __name__ == '__main__':
    unittest.main()",unittest
Propose a Python program to tokenize the given sentences.,The quick brown fox jumps over the lazy dog,"import nltk

def tokenize_sentences(sentence):
    tokens = nltk.word_tokenize(sentence)
    return tokens",Lainnya,3422,"import ___

def tokenize_sentences(sentence):
    tokens = nltk.word_tokenize(sentence)
    return tokens",nltk
Generate a Dataframe in Python,"The table should have three columns - name, age, gender
Example data: 
John, 24, Male
Sarah, 32, Female","import pandas as pd

data = [('John', 24, 'Male'), 
        ('Sarah', 32, 'Female')] 
  
# Create the pandas DataFrame 
df = pd.DataFrame(data, columns = ['Name', 'Age', 'Gender']) 
  
print(df)",Lainnya,3432,"import ___ as pd

data = [('John', 24, 'Male'), 
        ('Sarah', 32, 'Female')] 
  
# Create the pandas DataFrame 
df = pd.DataFrame(data, columns = ['Name', 'Age', 'Gender']) 
  
print(df)",pandas
Take the following Python data structure and render it to JSON format.,"data = {
 'name': 'John',
 'age': 34,
 'hobbies': ['surfing', 'hiking', 'golf']
}","import json

data = {
 'name': 'John',
 'age': 34,
 'hobbies': ['surfing', 'hiking', 'golf']
}

json_data = json.dumps(data)

print(json_data)",Lainnya,3444,"import ___

data = {
 'name': 'John',
 'age': 34,
 'hobbies': ['surfing', 'hiking', 'golf']
}

json_data = json.dumps(data)

print(json_data)",json
Construct a python script to display the frequency of each words appearing in a document,"The text document contains the following content:

The quick brown fox jumps over the lazy dog.","from collections import Counter
 
with open('text.txt', 'r') as f:
    data = f.read().lower().split()
    
word_counter = Counter(data)
 
# Print the sorted most common 10 words
for word, count in word_counter.most_common(10):
    print('{}: {}'.format(word, count))",Lainnya,3478,"from collections import ___
 
with open('text.txt', 'r') as f:
    data = f.read().lower().split()
    
word_counter = Counter(data)
 
# Print the sorted most common 10 words
for word, count in word_counter.most_common(10):
    print('{}: {}'.format(word, count))",Counter
Generate a SQL query in Python to find the sum of numbers in a given dataset.,"Input data:
[[1, 2], [3, 4], [5, 6]]","import pandas as pd

df = pd.DataFrame([[1, 2], [3, 4], [5, 6]])

query = 'SELECT SUM(NUM1 + NUM2) AS SUM_NUM FROM df'

sum_num = pd.read_sql_query(query, con=df.to_sql('df'))
print(sum_num)",Lainnya,3499,"import ___ as pd

df = pd.DataFrame([[1, 2], [3, 4], [5, 6]])

query = 'SELECT SUM(NUM1 + NUM2) AS SUM_NUM FROM df'

sum_num = pd.read_sql_query(query, con=df.to_sql('df'))
print(sum_num)",pandas
Create a call to an external API in Python and process the response.,The API URL: 'https://www.example.com/api/data',"import requests

url = 'https://www.example.com/api/data'
response = requests.get(url)
data = response.json()

# Process response data
for item in data:
  # Do something with item...",Lainnya,3500,"import ___

url = 'https://www.example.com/api/data'
response = requests.get(url)
data = response.json()

# Process response data
for item in data:
  # Do something with item...",requests
Convert a SQL query to Python code.,SELECT * FROM orders WHERE status = 'shipped',"import sqlite3

conn = sqlite3.connect('database.db')
c = conn.cursor()
c.execute('SELECT * FROM orders WHERE status = \'shipped\'')

result = c.fetchall()

for row in result:
    print(row)

conn.close()",Lainnya,3506,"import ___

conn = sqlite3.connect('database.db')
c = conn.cursor()
c.execute('SELECT * FROM orders WHERE status = \'shipped\'')

result = c.fetchall()

for row in result:
    print(row)

conn.close()",sqlite3
Create an algorithm using Python to generate random passwords.,Number of characters: 10,"import random
 
def generate_password(length):
    # Generate a random password that is length characters long
    chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'
    password = ''
    for _ in range(length):
        password += random.choice(chars)
    return password
 
generated_password = generate_password(10)
print(generated_password)",Lainnya,3528,"import ___
 
def generate_password(length):
    # Generate a random password that is length characters long
    chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'
    password = ''
    for _ in range(length):
        password += random.choice(chars)
    return password
 
generated_password = generate_password(10)
print(generated_password)",random
Create a Python program that reads two dates and computes the number of days between them.,"date_1 = '2020-01-01'
date_2 = '2020-01-30'","from datetime import date

date_1 = date(2020, 1, 1)
date_2 = date(2020, 1, 30)

diff = date_2 - date_1
print('There are {} days between the two dates.'.format(diff.days))",Lainnya,3569,"from datetime import ___

date_1 = date(2020, 1, 1)
date_2 = date(2020, 1, 30)

diff = date_2 - date_1
print('There are {} days between the two dates.'.format(diff.days))",date
Load a dataset in CSV format into a Python pandas DataFrame.,"# dataset.csv
ColA, ColB, ColC
1, 2, 3
4, 5, 6
7, 8, 9","import pandas as pd

data = pd.read_csv('dataset.csv')",Lainnya,3576,"import ___ as pd

data = pd.read_csv('dataset.csv')",pandas
Write a Python code which randomly generates a hopscotch board of given size.,size = 7,"import random 

def generate_hopscotch_board(size):
    board = []
    for row in range(size):
        board.append([])
        for col in range(size):
            board[row].append(random.randint(1,6))
    return board

# Generate a hopscotch board
print(generate_hopscotch_board(size))",Lainnya,3599,"import ___ 

def generate_hopscotch_board(size):
    board = []
    for row in range(size):
        board.append([])
        for col in range(size):
            board[row].append(random.randint(1,6))
    return board

# Generate a hopscotch board
print(generate_hopscotch_board(size))",random
Write a Python program to format a given date from one format to another.,"start_date = ""3-5-2020""
end_date = ""5-5-2020""","from datetime import date

def format_date(date_str, start_format, end_format):
    date_obj = date.strptime(date_str, start_format)
    return date_obj.strftime(end_format)",Lainnya,3604,"from datetime import ___

def format_date(date_str, start_format, end_format):
    date_obj = date.strptime(date_str, start_format)
    return date_obj.strftime(end_format)",date
Design a program in Python to change the background color of a web page.,color = '#FF0000',"from selenium import webdriver
from selenium.webdriver.common.keys import Keys

driver = webdriver.Chrome()
driver.get(""http://example.com"")
html = driver.find_element_by_tag_name('html')
html.send_keys(Keys.CONTROL + Keys.SHIFT + Keys.BACKSPACE)
driver.execute_script(""document.body.style.backgroundColor='"" + color + ""'"")",Lainnya,3616,"from selenium import ___
from selenium.webdriver.common.keys import Keys

driver = webdriver.Chrome()
driver.get(""http://example.com"")
html = driver.find_element_by_tag_name('html')
html.send_keys(Keys.CONTROL + Keys.SHIFT + Keys.BACKSPACE)
driver.execute_script(""document.body.style.backgroundColor='"" + color + ""'"")",webdriver
Parse the following JSON into a Python dictionary.,"{
  ""name"": ""John"",
  ""age"": 28,
  ""hobbies"": [
    ""Programming"",
    ""Sports""
  ]
}","# import the json module
import json

# parse the json
json_dict = json.loads('{  ""name"": ""John"",  ""age"": 28,  ""hobbies"": [    ""Programming"",    ""Sports""  ]}')

# print the parsed json
print(json_dict)",Lainnya,3626,"# import ___ json module
import json

# parse the json
json_dict = json.loads('{  ""name"": ""John"",  ""age"": 28,  ""hobbies"": [    ""Programming"",    ""Sports""  ]}')

# print the parsed json
print(json_dict)",the
Generate a valid JSON from a given Python dictionary.,"data = {
    'name': 'John',
    'age': 25
}","import json
data = {
    'name': 'John',
    'age': 25
}

json_data = json.dumps(data)
# json_data = '{""name"":""John"",""age"":25}'",Lainnya,3653,"import ___
data = {
    'name': 'John',
    'age': 25
}

json_data = json.dumps(data)
# json_data = '{""name"":""John"",""age"":25}'",json
Edit a given python program,"Input: A program to round off a number to the nearest integer 

def round_off(a): 
    if (a - math.floor(a) >= 0.5): 
        a = math.ceil(a) 
    else: 
        a = math.floor(a) 
    return a","import math

def round_off(a): 
    if (a - math.floor(a) >= 0.5): 
        a = math.ceil(a) 
    else: 
        a = math.floor(a) 
    return int(a)",Lainnya,3671,"import ___

def round_off(a): 
    if (a - math.floor(a) >= 0.5): 
        a = math.ceil(a) 
    else: 
        a = math.floor(a) 
    return int(a)",math
Write a Python program to extract the text from an HTML document.,<h2>Hello World!</h2>,"from bs4 import BeautifulSoup

html = '<h2>Hello World!</h2>'
soup = BeautifulSoup(html, 'html.parser')
text = soup.find('h2').text

print(text) # Hello World!",Lainnya,3673,"from bs4 import ___

html = '<h2>Hello World!</h2>'
soup = BeautifulSoup(html, 'html.parser')
text = soup.find('h2').text

print(text) # Hello World!",BeautifulSoup
Write a python script that normalizes the given text.,The cat and rat chAsEd eAch other,"import re

def normalize_text(text):
    return re.sub(r'[^\w\s]','',text.lower())

text = ""The cat and rat chAsEd eAch other""
print(normalize_text(text))

# Output: the cat and rat chased each other",Lainnya,3714,"import ___

def normalize_text(text):
    return re.sub(r'[^\w\s]','',text.lower())

text = ""The cat and rat chAsEd eAch other""
print(normalize_text(text))

# Output: the cat and rat chased each other",re
Build a decision tree model in Python.,"X = [[0, 0], [1, 1]]
y = [0, 1]","# Import decision tree classifier from the sklearn library
from sklearn import tree
 
# Input data to the model
X = [[0, 0], [1, 1]]
y = [0, 1]
 
# Create a decision tree classifier object
clf = tree.DecisionTreeClassifier()
 
# Train the decision tree classifier
clf = clf.fit(X, y)",Lainnya,3733,"# Import decision tree classifier from the sklearn library
from sklearn import ___
 
# Input data to the model
X = [[0, 0], [1, 1]]
y = [0, 1]
 
# Create a decision tree classifier object
clf = tree.DecisionTreeClassifier()
 
# Train the decision tree classifier
clf = clf.fit(X, y)",tree
Classify the following items using a supervised machine learning algorithm in Python,"[3, 5, 7, 1, 0]","import numpy as np 
from sklearn import svm 

# Input data to classify
X = np.array([[3, 5, 7, 1, 0]])

# Label data, either 0 or 1
y = np.array([0])

# Create a SVC classifier
clf = svm.SVC(gamma=0.001, C=100.)

# Train the model, using the training sets
clf.fit(X, y)

print('Prediction:', clf.predict(X))

Output:
Prediction: [0]",Lainnya,3744,"import ___ as np 
from sklearn import svm 

# Input data to classify
X = np.array([[3, 5, 7, 1, 0]])

# Label data, either 0 or 1
y = np.array([0])

# Create a SVC classifier
clf = svm.SVC(gamma=0.001, C=100.)

# Train the model, using the training sets
clf.fit(X, y)

print('Prediction:', clf.predict(X))

Output:
Prediction: [0]",numpy
Compute the sum of two matrices in Python.,"matrix_1 = [[1, 2, 3], [4, 5, 6]]
matrix_2 = [[7, 8, 9], [10, 11, 12]]","import numpy as np

matrix_1 = np.array(matrix_1)
matrix_2 = np.array(matrix_2)

result = np.add(matrix_1, matrix_2)

## Output: [[ 8 10 12], [14 16 18]]",Lainnya,3755,"import ___ as np

matrix_1 = np.array(matrix_1)
matrix_2 = np.array(matrix_2)

result = np.add(matrix_1, matrix_2)

## Output: [[ 8 10 12], [14 16 18]]",numpy
Write a Python program that croscorrelates two given arrays.,"Array 1: [2, 3, 5, 7], Array 2: [1, 4, 6, 8]","import numpy as np
 
#input arrays
arr1 = np.array([2, 3, 5, 7])
arr2 = np.array([1, 4, 6, 8])

#calculating correlation
correlation = np.corrcoef(arr1, arr2)

#printing correlation
print(""Correlation: "", correlation[0][1])",Lainnya,3770,"import ___ as np
 
#input arrays
arr1 = np.array([2, 3, 5, 7])
arr2 = np.array([1, 4, 6, 8])

#calculating correlation
correlation = np.corrcoef(arr1, arr2)

#printing correlation
print(""Correlation: "", correlation[0][1])",numpy
Create a Python script to scrape content from a website.,Website URL: 'https://example.com',"import requests
from bs4 import BeautifulSoup 
 
url = 'https://example.com'
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
 
for content in soup.find_all('div', class_='content'):
 print(content.text)",Lainnya,3789,"import ___
from bs4 import BeautifulSoup 
 
url = 'https://example.com'
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
 
for content in soup.find_all('div', class_='content'):
 print(content.text)",requests
Automate the following task using Python,You are given a spreadsheat which contains a list of customer names and their respective purchase amounts. Calculate the total purchase made by each customer.,"import pandas as pd

# load spreadsheet
df = pd.read_csv('customer_purchase.csv')

# calculate total purchase for each customer
total_purchase = df.groupby('Customer Name')['Purchase Amount'].sum().reset_index()

# print total purchase for each customer
print(total_purchase)",Lainnya,3848,"import ___ as pd

# load spreadsheet
df = pd.read_csv('customer_purchase.csv')

# calculate total purchase for each customer
total_purchase = df.groupby('Customer Name')['Purchase Amount'].sum().reset_index()

# print total purchase for each customer
print(total_purchase)",pandas
Create a Python script that finds the most frequent words in a passage.,"passage = ""This is a passage about cats.""","from collections import Counter

def most_frequent_words(passage):
    word_list = passage.split() 
    word_freq = Counter(word_list) 
  
    most_freq_word = word_freq.most_common(1) 
    return most_freq_word",Lainnya,3868,"from collections import ___

def most_frequent_words(passage):
    word_list = passage.split() 
    word_freq = Counter(word_list) 
  
    most_freq_word = word_freq.most_common(1) 
    return most_freq_word",Counter
"Build a program in Python using the Pandas library to calculate the mean, median, and mode of a given series.","[1, 2, 2, 3, 3, 3, 4, 5]","import pandas as pd

# Create Series
data = [1, 2, 2, 3, 3, 3, 4, 5]
series = pd.Series(data)

# Calculate mean
mean = series.mean()

# Calculate median
median = series.median()

# Calculate mode
mode = series.mode()

# Print results
print(""Mean:"", mean)
print(""Median:"", median)
print(""Mode:"", mode)",Lainnya,3869,"import ___ as pd

# Create Series
data = [1, 2, 2, 3, 3, 3, 4, 5]
series = pd.Series(data)

# Calculate mean
mean = series.mean()

# Calculate median
median = series.median()

# Calculate mode
mode = series.mode()

# Print results
print(""Mean:"", mean)
print(""Median:"", median)
print(""Mode:"", mode)",pandas
"Using Python, edit the following dataset to discard outliers.","Dataset: [12, 34, 37, 10, 89, 67, 99, 101]","import numpy as np

dataset = [12, 34, 37, 10, 89, 67, 99, 101]
dataset_without_outliers = [x for x in dataset if abs(x-np.mean(dataset)) < 3*np.std(dataset)]

print(dataset_without_outliers) # prints [12, 34, 37, 10, 89, 67, 99]",Lainnya,3877,"import ___ as np

dataset = [12, 34, 37, 10, 89, 67, 99, 101]
dataset_without_outliers = [x for x in dataset if abs(x-np.mean(dataset)) < 3*np.std(dataset)]

print(dataset_without_outliers) # prints [12, 34, 37, 10, 89, 67, 99]",numpy
Use the BeautifulSoup library in Python to parse HTML from a website.,Example website: https://www.example.com,"import requests
from bs4 import BeautifulSoup

#make a GET request
response = requests.get('https://www.example.com')

#parse HTML
soup = BeautifulSoup(response.text, 'html.parser')",Lainnya,3906,"import ___
from bs4 import BeautifulSoup

#make a GET request
response = requests.get('https://www.example.com')

#parse HTML
soup = BeautifulSoup(response.text, 'html.parser')",requests
Write a script in Python to retrieve data from a web API.,The web API is available at http://api.example.com/v1/zipcodes and requires the parameter `zipcode` to execute.,"import requests

zipcode = '12345'
url = 'http://api.example.com/v1/zipcodes'

params = {'zipcode': zipcode}
response = requests.get(url, params=params)

if response.status_code == 200:
 data = response.json()
 print(data)
else:
 print('Error: ', response.status_code)",Lainnya,3907,"import ___

zipcode = '12345'
url = 'http://api.example.com/v1/zipcodes'

params = {'zipcode': zipcode}
response = requests.get(url, params=params)

if response.status_code == 200:
 data = response.json()
 print(data)
else:
 print('Error: ', response.status_code)",requests
Create a program in Python to perform web scraping using the BeautifulSoup module.,URL: https://en.wikipedia.org/wiki/Python_(programming_language),"import requests 
from bs4 import BeautifulSoup 

# Get the webpage
url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'
response = requests.get(url) 

# Create the soup
soup = BeautifulSoup(response.text, 'html.parser') 

# Extract the text
text = soup.get_text() 

# Output the text
print(text)",Lainnya,3929,"import ___ 
from bs4 import BeautifulSoup 

# Get the webpage
url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'
response = requests.get(url) 

# Create the soup
soup = BeautifulSoup(response.text, 'html.parser') 

# Extract the text
text = soup.get_text() 

# Output the text
print(text)",requests
Create a command line utility in Python that takes two arguments. The utility should compare the two arguments and output the result as either “equal” or “not equal”.,"Arg1: hello
Arg2: world","import sys

arg1 = sys.argv[1]
arg2 = sys.argv[2]

if arg1 == arg2:
 print('equal')
else:
 print('not equal')",Lainnya,3931,"import ___

arg1 = sys.argv[1]
arg2 = sys.argv[2]

if arg1 == arg2:
 print('equal')
else:
 print('not equal')",sys
Edit the following Python program so that it prints out the square root of a given number.,number = 8,"import math

number = 8

# compute the square root of the given number
square_root = math.sqrt(number)

# print the square root
print(f""The square root of {number} is {square_root}"")",Lainnya,3949,"import ___

number = 8

# compute the square root of the given number
square_root = math.sqrt(number)

# print the square root
print(f""The square root of {number} is {square_root}"")",math
Create a Python program that classifies articles based on sentiment.,This article is bad,"import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentences = [""This article is bad""]

sid = SentimentIntensityAnalyzer()
for sentence in sentences:
  print(sentence)
  ss = sid.polarity_scores(sentence)
  print(ss)
  if ss['compound'] >= 0.05:
    print(""Positive"")
  elif -0.05 < ss['compound'] < 0.05:
    print(""Neutral"")
  else:
    print(""Negative"")",Lainnya,3957,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentences = [""This article is bad""]

sid = SentimentIntensityAnalyzer()
for sentence in sentences:
  print(sentence)
  ss = sid.polarity_scores(sentence)
  print(ss)
  if ss['compound'] >= 0.05:
    print(""Positive"")
  elif -0.05 < ss['compound'] < 0.05:
    print(""Neutral"")
  else:
    print(""Negative"")",nltk
Write Python code to parse this JSON data.,"{
  ""title"": ""The Adventures of Tom Sawyer"",
  ""author"": ""Mark Twain"",
  ""year"": 1876
}","import json

data = {
  ""title"": ""The Adventures of Tom Sawyer"",
  ""author"": ""Mark Twain"",
  ""year"": 1876
}

parsed_data = json.loads(data)

title = parsed_data['title']
author = parsed_data['author']
year = parsed_data['year']",Lainnya,3960,"import ___

data = {
  ""title"": ""The Adventures of Tom Sawyer"",
  ""author"": ""Mark Twain"",
  ""year"": 1876
}

parsed_data = json.loads(data)

title = parsed_data['title']
author = parsed_data['author']
year = parsed_data['year']",json
Create a program that can find the top five most common words in the input.,Python is a powerful general-purpose programming language.,"import collections
import re

# clean and preprocess text
words = re.sub('\W+', ' ', input_text).split()

# find most common words
word_counter = collections.Counter(words)

# print top five most common words
print(word_counter.most_common(5))

# Output:
[('a', 1), ('Python', 1), ('is', 1), ('powerful', 1), ('general', 1)]",Lainnya,3998,"import ___
import re

# clean and preprocess text
words = re.sub('\W+', ' ', input_text).split()

# find most common words
word_counter = collections.Counter(words)

# print top five most common words
print(word_counter.most_common(5))

# Output:
[('a', 1), ('Python', 1), ('is', 1), ('powerful', 1), ('general', 1)]",collections
Develop a Python script to perform sentiment analysis on a given text.,"""I'm feeling really great today""","import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""I'm feeling really great today""

sid = SentimentIntensityAnalyzer()
ss = sid.polarity_scores(text)

print(ss['compound']) # Prints 0.6249, which is positive sentiment.",Lainnya,3999,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""I'm feeling really great today""

sid = SentimentIntensityAnalyzer()
ss = sid.polarity_scores(text)

print(ss['compound']) # Prints 0.6249, which is positive sentiment.",nltk
Create a data analysis solution using Python and Pandas.,"The CSV file has three columns:
Country, Population, and Area","import pandas as pd

# Read in the CSV file
df = pd.read_csv(""data.csv"")

# Calculate population density
df['Density'] = df['Population'] / df['Area']

# Print the density of the first 5 countries
print(df.head()['Density'])",Lainnya,4028,"import ___ as pd

# Read in the CSV file
df = pd.read_csv(""data.csv"")

# Calculate population density
df['Density'] = df['Population'] / df['Area']

# Print the density of the first 5 countries
print(df.head()['Density'])",pandas
Develop a RESTful web service in Python which returns the data provided in the given URL.,URL: https://example.com/dataset.json,"import flask
from flask import Flask
import requests

app = Flask(__name__)

@app.route('/data', methods=[""GET""])
def data():
    r = requests.get('https://example.com/dataset.json')
    return flask.jsonify(r.json())

if __name__ == '__main__':
    app.run()",Lainnya,4055,"import ___
from flask import Flask
import requests

app = Flask(__name__)

@app.route('/data', methods=[""GET""])
def data():
    r = requests.get('https://example.com/dataset.json')
    return flask.jsonify(r.json())

if __name__ == '__main__':
    app.run()",flask
Create a line chart representing the given data in Python.,"x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]","import matplotlib.pyplot as plt 

x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

plt.plot(x, y)
plt.title('Line Chart') 
plt.xlabel('X-Axis') 
plt.ylabel('Y-Axis') 
plt.show()",Lainnya,4070,"import ___.pyplot as plt 

x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

plt.plot(x, y)
plt.title('Line Chart') 
plt.xlabel('X-Axis') 
plt.ylabel('Y-Axis') 
plt.show()",matplotlib
Create a Python program to fetch data from an HTTPS resource.,"url = ""https://example.com/data""","import requests

url = ""https://example.com/data""

# Send a GET request to the URL
r =  requests.get(url)

# Check the status of the request
if r.status_code == 200:
 data = r.json()
 # Process the fetched data
else:
 print('Error: status code {}'.format(r.status_code))",Lainnya,4080,"import ___

url = ""https://example.com/data""

# Send a GET request to the URL
r =  requests.get(url)

# Check the status of the request
if r.status_code == 200:
 data = r.json()
 # Process the fetched data
else:
 print('Error: status code {}'.format(r.status_code))",requests
Write a Python program to generate a square matrix with random values from 0 to 9.,4 (Size of matrix),"import random

def matrix(size):
  matrix = [[0 for i in range(size)] for j in range(size)]
  for i in range(size):
    for j in range(size):
      matrix[i][j] = random.randint(0, 9)
  return matrix

result = matrix(4)
for row in result:
  print(row)",Lainnya,4086,"import ___

def matrix(size):
  matrix = [[0 for i in range(size)] for j in range(size)]
  for i in range(size):
    for j in range(size):
      matrix[i][j] = random.randint(0, 9)
  return matrix

result = matrix(4)
for row in result:
  print(row)",random
Implement an algorithm in Python to classify a given dataset into different target classes.,dataset.csv,"import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
 
# Load dataset
data = pd.read_csv('dataset.csv')
X = data.iloc[:, :-1]
y = data.iloc[:, -1]
 
# Create and fit classifier
classifier = KNeighborsClassifier(n_neighbors=5)
classifier.fit(X, y)
 
# Make predictions
predictions = classifier.predict(X)
print(np.mean(predictions == y))",Lainnya,4101,"import ___ as pd
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
 
# Load dataset
data = pd.read_csv('dataset.csv')
X = data.iloc[:, :-1]
y = data.iloc[:, -1]
 
# Create and fit classifier
classifier = KNeighborsClassifier(n_neighbors=5)
classifier.fit(X, y)
 
# Make predictions
predictions = classifier.predict(X)
print(np.mean(predictions == y))",pandas
Design an algorithm in Python to calculate the Euclidean distance between two points,"Input: ([2, 4], [4, 8])","import math 
    
def euclidean_distance(point1, point2):
    dist = math.sqrt( (point1[0]-point2[0])**2 + (point1[1]-point2[1])**2 )
    return dist 

print(euclidean_distance([2,4], [4,8]))",Lainnya,4105,"import ___ 
    
def euclidean_distance(point1, point2):
    dist = math.sqrt( (point1[0]-point2[0])**2 + (point1[1]-point2[1])**2 )
    return dist 

print(euclidean_distance([2,4], [4,8]))",math
Write a Python script to generate a random password of a given length.,length = 8,"import string
import random

def random_password_generator(length):
 chars = string.ascii_letters + string.digits + string.punctuation
 return ''.join((random.choice(chars) for i in range(length)))

print(random_password_generator(length))",Lainnya,4112,"import ___
import random

def random_password_generator(length):
 chars = string.ascii_letters + string.digits + string.punctuation
 return ''.join((random.choice(chars) for i in range(length)))

print(random_password_generator(length))",string
Create a Python script to generate a calendar representation of a given month.,Month : April; Year : 2020,"import calendar

year = 2020
month = 4

# create a calendar of the given month and year
cal = calendar.month(year, month)

# print it
print(cal)

# Output
     April 2020
Mo Tu We Th Fr Sa Su
       1  2  3  4  5
 6  7  8  9 10 11 12
13 14 15 16 17 18 19",Lainnya,4115,"import ___

year = 2020
month = 4

# create a calendar of the given month and year
cal = calendar.month(year, month)

# print it
print(cal)

# Output
     April 2020
Mo Tu We Th Fr Sa Su
       1  2  3  4  5
 6  7  8  9 10 11 12
13 14 15 16 17 18 19",calendar
Create a web scraper with Python and Beautiful Soup to scrape data from a single webpage.,URL: http://example.com/page,"import requests
from bs4 import BeautifulSoup

url = 'http://example.com/page'

response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')

results = soup.find_all('div', {'class': 'result'})

for result in results:
 title = result.find('h2').text
 description = result.find('p').text 
 print(title, description)",Lainnya,4150,"import ___
from bs4 import BeautifulSoup

url = 'http://example.com/page'

response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')

results = soup.find_all('div', {'class': 'result'})

for result in results:
 title = result.find('h2').text
 description = result.find('p').text 
 print(title, description)",requests
Construct a Python script that uses regular expressions to find phone numbers in a text.,"The following numbers belong to us: 888-555-0000, +1-217-543-1000.","import re

text = 'The following numbers belong to us: 888-555-0000, +1-217-543-1000.'

# Find all phone numbers
numbers = re.findall(r'\+?\d[\d -]{8,12}\d', text)

# Output
print(numbers)",Lainnya,4165,"import ___

text = 'The following numbers belong to us: 888-555-0000, +1-217-543-1000.'

# Find all phone numbers
numbers = re.findall(r'\+?\d[\d -]{8,12}\d', text)

# Output
print(numbers)",re
Write a Python script that normalizes given input strings.,"""Hello,  world    !  How are you?""","import re
s = ""Hello,  world    !  How are you?""
s = re.sub(' +', ' ', s)
print(s)

# Output
# 'Hello, world! How are you?'",Lainnya,4181,"import ___
s = ""Hello,  world    !  How are you?""
s = re.sub(' +', ' ', s)
print(s)

# Output
# 'Hello, world! How are you?'",re
Compose a python script to create a bar chart.,"[4,6,3,7,2]","import matplotlib.pyplot as plt
 
# x-axis values 
x = [4, 6, 3, 7, 2] 

# Y-axis values 
y = [0, 2, 3, 4, 5] 

# Function to plot the bar
plt.bar(x, y)

# Naming the x-axis 
plt.xlabel('x - axis')
# Naming the y-axis 
plt.ylabel('y - axis')
# Writing a title to the graph
plt.title('Bar Chart') 
# Show the plot
plt.show()",Lainnya,4185,"import ___.pyplot as plt
 
# x-axis values 
x = [4, 6, 3, 7, 2] 

# Y-axis values 
y = [0, 2, 3, 4, 5] 

# Function to plot the bar
plt.bar(x, y)

# Naming the x-axis 
plt.xlabel('x - axis')
# Naming the y-axis 
plt.ylabel('y - axis')
# Writing a title to the graph
plt.title('Bar Chart') 
# Show the plot
plt.show()",matplotlib
Write a Python program using NumPy to calculate the dot product of two vectors.,"x = [3, 4, 5]

y = [2, 6, 4]","import numpy as np

x = np.array([3, 4, 5])
y = np.array([2, 6, 4])

dot_product = np.dot(x, y)

print(dot_product) # 46",Lainnya,4188,"import ___ as np

x = np.array([3, 4, 5])
y = np.array([2, 6, 4])

dot_product = np.dot(x, y)

print(dot_product) # 46",numpy
Create a Python program to generate a random name from two given lists of names.,"first_names = [""Alice"", ""John"", ""Joe"", ""Michael""] 
last_names = [""Smith"", ""Williams"", ""Jackson"", ""Brown""]","import random

def get_random_name(first_names, last_names):
    first_name = random.choice(first_names)
    last_name = random.choice(last_names)
    random_name = first_name + ' ' + last_name
    return random_name",Lainnya,4200,"import ___

def get_random_name(first_names, last_names):
    first_name = random.choice(first_names)
    last_name = random.choice(last_names)
    random_name = first_name + ' ' + last_name
    return random_name",random
Write a Python program to visualize a given dataset in a 2D scatterplot.,"x_data = {1,2,3,4,5,6,7,8,9,10}
y_data = {3,4,7,8,10,12,14,16,18,19}","import matplotlib.pyplot as plt
def visualize_data(x_data, y_data):
 plt.scatter(x_data, y_data)
 plt.xlabel('x data')
 plt.ylabel('y data')
 plt.title('2D Scatterplot')
 plt.show()",Lainnya,4202,"import ___.pyplot as plt
def visualize_data(x_data, y_data):
 plt.scatter(x_data, y_data)
 plt.xlabel('x data')
 plt.ylabel('y data')
 plt.title('2D Scatterplot')
 plt.show()",matplotlib
Create a Python script to generate random numbers with using a certain range.,"Minimum = 5, Maximum = 15","import random

min_n = 5
max_n = 15

def random_number_generator(min_n, max_n):
  return random.randint(min_n, max_n)

for num in range(0, 10):
    print (random_number_generator(min_n, max_n))",Lainnya,4206,"import ___

min_n = 5
max_n = 15

def random_number_generator(min_n, max_n):
  return random.randint(min_n, max_n)

for num in range(0, 10):
    print (random_number_generator(min_n, max_n))",random
We are given the input and output schematic of a neural network. You are required to implement the network in Python code.,"Inputs=[2,1]
Hidden1=[2]
Outputs=[1]","import numpy as np
 
# Inputs
x = np.array([2, 1])
 
# Weights - Initilise to random values
w1 = np.random.rand(2, 2)
w2 = np.random.rand(2, 1)
 
# Hidden layer
h1 = np.matmul(x, w1)
 
# Output layer
y = np.matmul(h1, w2)",Lainnya,4210,"import ___ as np
 
# Inputs
x = np.array([2, 1])
 
# Weights - Initilise to random values
w1 = np.random.rand(2, 2)
w2 = np.random.rand(2, 1)
 
# Hidden layer
h1 = np.matmul(x, w1)
 
# Output layer
y = np.matmul(h1, w2)",numpy
Develop a valid Python script which computes the root of a given quadratic equation,"a = 1, b = -7, c =12","import math

def quadratic_equation_roots(a, b, c):
  d = b**2 - 4*a*c

  if d > 0:
    x1 = (-b + math.sqrt(d)) / (2*a)
    x2 = (-b - math.sqrt(d)) / (2*a)
    return x1, x2
  else:
    return ""This equation has no real roots!""",Lainnya,4223,"import ___

def quadratic_equation_roots(a, b, c):
  d = b**2 - 4*a*c

  if d > 0:
    x1 = (-b + math.sqrt(d)) / (2*a)
    x2 = (-b - math.sqrt(d)) / (2*a)
    return x1, x2
  else:
    return ""This equation has no real roots!""",math
Generate a python code to build a simple regression model?,"X = [[1, 2, 3], [4, 5, 6]]
Y = [[7], [8]]","import numpy as np

X = np.array(X)
Y = np.array(Y)

b = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)

#Print the parameters
print(""Parameters: "", b)

#Make predictions
x_new = [[1, 2, 3]]
y_pred = np.dot(x_new, b)
print(""Predicted output: "", y_pred)",Lainnya,4227,"import ___ as np

X = np.array(X)
Y = np.array(Y)

b = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)

#Print the parameters
print(""Parameters: "", b)

#Make predictions
x_new = [[1, 2, 3]]
y_pred = np.dot(x_new, b)
print(""Predicted output: "", y_pred)",numpy
Write code using Python to generate a random password of given length.,Length: 8,"import string
import random

def generate_password(length):
    chars=string.ascii_uppercase + string.ascii_lowercase + string.digits
    return ''.join(random.choice(chars) for i in range(length))

print(generate_password(8))",Lainnya,4236,"import ___
import random

def generate_password(length):
    chars=string.ascii_uppercase + string.ascii_lowercase + string.digits
    return ''.join(random.choice(chars) for i in range(length))

print(generate_password(8))",string
Write a Python program to create a dataframe from a given dictionary of lists.,"data = {
    'name': ['John', 'Mark', 'Tom'],
    'age': [21, 18, 20]
}","import pandas as pd

data_df = pd.DataFrame(data)

print(data_df)",Lainnya,4286,"import ___ as pd

data_df = pd.DataFrame(data)

print(data_df)",pandas
Create a Python program to generate random numbers between 1 and 10 of a specified length.,Length = 6,"import random
def generate_random_nums(length):
  lst = []
  for _ in range(length):
    lst.append(random.randint(1, 10))
  return lst",Lainnya,4301,"import ___
def generate_random_nums(length):
  lst = []
  for _ in range(length):
    lst.append(random.randint(1, 10))
  return lst",random
Generate a script to send an email using Python.,"email: test@example.com
subject: test
content: Hello World","import smtplib

sender = 'test@example.com'
receiver = 'test@example.com'
subject = 'test'
message = 'Hello World'

try:
 smtpObj = smtplib.SMTP('localhost')
 smtpObj.sendmail(sender, receiver,
  ""Subject: "" + subject + ""\n"" + message)
 print(""Successfully sent email"")
except Exception as e:
 print(""Error: unable to send email"")",Lainnya,4308,"import ___

sender = 'test@example.com'
receiver = 'test@example.com'
subject = 'test'
message = 'Hello World'

try:
 smtpObj = smtplib.SMTP('localhost')
 smtpObj.sendmail(sender, receiver,
  ""Subject: "" + subject + ""\n"" + message)
 print(""Successfully sent email"")
except Exception as e:
 print(""Error: unable to send email"")",smtplib
"Generate a random number between two given numbers, using Python.","min_range = 30
max_range = 100","""""""
Generate a random number between two given numbers, using Python
""""""

import random

def random_number(min_range, max_range):
    return random.randrange(min_range, max_range)

print(random_number(30, 100))",Lainnya,4335,"""""""
Generate a random number between two given numbers, using Python
""""""

import ___

def random_number(min_range, max_range):
    return random.randrange(min_range, max_range)

print(random_number(30, 100))",random
Create a Python script to analyze a text document. The script should locate all words with three or more characters in a row and count their frequency in the document.,The quick brown fox jumps over the lazy dog. The fox barked at the dog.,"from collections import defaultdict

text = 'The quick brown fox jumps over the lazy dog. The fox barked at the dog.'

words = defaultdict(int)

 for word in text.split():
  if len(word) >= 3:
   words[word] += 1

print(words)",Lainnya,4344,"from collections import ___

text = 'The quick brown fox jumps over the lazy dog. The fox barked at the dog.'

words = defaultdict(int)

 for word in text.split():
  if len(word) >= 3:
   words[word] += 1

print(words)",defaultdict
Construct a decision tree algorithm in Python to classify credit card transactions.,The dataset consists of 5 numerical features and one categorical target variable.,"from sklearn.tree import DecisionTreeClassifier
import numpy as np 

X = np.array([features])
y = np.array([target])

clf_dt = DecisionTreeClassifier()
clf_dt.fit(X,y)

# Predict class labels
preds = clf_dt.predict(X)",Lainnya,4365,"from sklearn.tree import ___
import numpy as np 

X = np.array([features])
y = np.array([target])

clf_dt = DecisionTreeClassifier()
clf_dt.fit(X,y)

# Predict class labels
preds = clf_dt.predict(X)",DecisionTreeClassifier
Create a python program to Reverse Engineer an API and find its endpoints.,http://example.com/api,"import requests

url = 'http://example.com/api'
response = requests.get(url)

if response.status_code == 200:
    # Find the API endpoints
    data = response.json()
    endpoints = data.get('endpoints')
    print(endpoints)",Lainnya,4370,"import ___

url = 'http://example.com/api'
response = requests.get(url)

if response.status_code == 200:
    # Find the API endpoints
    data = response.json()
    endpoints = data.get('endpoints')
    print(endpoints)",requests
Use a random forest model in Python to predict the sale price of a house.,"Example data: 
Size: 500, Rooms: 4","import pandas as pd
from sklearn.ensemble import RandomForestRegressor

# Create
data = {'Size': [500], 
'Rooms': [4]}

df = pd.DataFrame(data)

# Train
X = df[['Size','Rooms']] 
Y = df['Price'] 

regressor = RandomForestRegressor(n_estimators = 10, random_state = 0) 
regressor.fit(X, Y)

# Predict
regressor.predict([[500,4]]) # Predicted price: 1716.275",Lainnya,4378,"import ___ as pd
from sklearn.ensemble import RandomForestRegressor

# Create
data = {'Size': [500], 
'Rooms': [4]}

df = pd.DataFrame(data)

# Train
X = df[['Size','Rooms']] 
Y = df['Price'] 

regressor = RandomForestRegressor(n_estimators = 10, random_state = 0) 
regressor.fit(X, Y)

# Predict
regressor.predict([[500,4]]) # Predicted price: 1716.275",pandas
Create a code to parse a web page and check whether or not a particular keyword appears in the page.,"keyword = ""python""","import requests

def check_if_keyword_exists(url, keyword):
    response = requests.get(url)
    if keyword in response.text:
        return True
    return False

keyword = ""python""
print(check_if_keyword_exists(""https://en.wikipedia.org/wiki/Python_(programming_language)"", keyword)) # Output: True",Lainnya,4385,"import ___

def check_if_keyword_exists(url, keyword):
    response = requests.get(url)
    if keyword in response.text:
        return True
    return False

keyword = ""python""
print(check_if_keyword_exists(""https://en.wikipedia.org/wiki/Python_(programming_language)"", keyword)) # Output: True",requests
Write a Python program to predict the future stock price of a company.,Predict the stock price of Apple in 2021.,"import pandas as pd

# Read the data
data = pd.read_csv(""apple stock data.csv"")

# Extract the data points
X = data[['open', 'high', 'low', 'volume']]
y = data['close']

# Fit the model
model.fit(X, y)

# Predict the stock price of Apple in 2021 
predict = model.predict([[Apple_open, Apple_high, Apple_low, Apple_volume]])
print(predict)",Lainnya,4411,"import ___ as pd

# Read the data
data = pd.read_csv(""apple stock data.csv"")

# Extract the data points
X = data[['open', 'high', 'low', 'volume']]
y = data['close']

# Fit the model
model.fit(X, y)

# Predict the stock price of Apple in 2021 
predict = model.predict([[Apple_open, Apple_high, Apple_low, Apple_volume]])
print(predict)",pandas
"Given a JSON record of a customer, write a Python program to extract the customer's name.","{
    ""name"": ""John Smith"",
    ""age"": 35
}","import json

data = json.loads('{
    ""name"": ""John Smith"",
    ""age"": 35
}')

customer_name = data[""name""]
print(customer_name)",Lainnya,4418,"import ___

data = json.loads('{
    ""name"": ""John Smith"",
    ""age"": 35
}')

customer_name = data[""name""]
print(customer_name)",json
Compute the area of a given circle using its radius in Python.,radius = 5,"import math

def calculateCircleArea(radius):
    area = math.pi * radius * radius
    return area

radius = 5

print(""Area of a circle with radius 5 is: "", calculateCircleArea(radius))",Lainnya,4425,"import ___

def calculateCircleArea(radius):
    area = math.pi * radius * radius
    return area

radius = 5

print(""Area of a circle with radius 5 is: "", calculateCircleArea(radius))",math
Create a heap data structure in Python using the heapq library.,No input,"import heapq

def create_heap(items):
 heapq.heapify(items)

def add_item(items, item):
 heapq.heappush(items, item)

def pop_item(items):
 return heapq.heappop(items)

items = [4, 5, 2, 33, 1]
create_heap(items)
add_item(items, 6)
pop_item(items)",Lainnya,4436,"import ___

def create_heap(items):
 heapq.heapify(items)

def add_item(items, item):
 heapq.heappush(items, item)

def pop_item(items):
 return heapq.heappop(items)

items = [4, 5, 2, 33, 1]
create_heap(items)
add_item(items, 6)
pop_item(items)",heapq
Write a python script that does the following:,Download the content of a website,"import requests

url = ""https://example.com"" 
r = requests.get(url)
data = r.content

with open(""example_website.html"", ""wb"") as file:
    file.write(data)

print(""File downloaded successfully."")",Lainnya,4468,"import ___

url = ""https://example.com"" 
r = requests.get(url)
data = r.content

with open(""example_website.html"", ""wb"") as file:
    file.write(data)

print(""File downloaded successfully."")",requests
Write a python code to create a histogram,Input is an array of integers,"import matplotlib.pyplot as plt

def create_histogram(data):
    plt.hist(data, bins=20)
    plt.title('Histogram of Input Data')
    plt.show()

# Example data
data = [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1]

create_histogram(data)",Lainnya,4469,"import ___.pyplot as plt

def create_histogram(data):
    plt.hist(data, bins=20)
    plt.title('Histogram of Input Data')
    plt.show()

# Example data
data = [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1]

create_histogram(data)",matplotlib
Implement a Python program to generate randon uniform numbers. The program should have two input parameters a lower bound and an upper bound.,"Lower bound: 10, Upper bound: 20","import random

# generates a random number between lower and upper
def generateRandomNumber(lower, upper):
 r = random.uniform(lower, upper)
 return r

# driver program
if __name__ == ""__main__"":
 lower = 10
 upper = 20
 print(generateRandomNumber(lower, upper))",Lainnya,4471,"import ___

# generates a random number between lower and upper
def generateRandomNumber(lower, upper):
 r = random.uniform(lower, upper)
 return r

# driver program
if __name__ == ""__main__"":
 lower = 10
 upper = 20
 print(generateRandomNumber(lower, upper))",random
Optimize the following application in Python to reduce startup time.,"import time

def func():
    start=time.time()
    i=0
    while(i<100000000):
        i+=1
    end=time.time()
    print(end-start)

func()","import time

def func():
    start=time.time()
    # Optimized code using range instead of while loop
    lst = range(100000000)
    end=time.time()
    print(end-start)

func()",Lainnya,4478,"import ___

def func():
    start=time.time()
    # Optimized code using range instead of while loop
    lst = range(100000000)
    end=time.time()
    print(end-start)

func()",time
Write a python program to tokenize a given text,"Text='Python is an interpreted, high-level, general-purpose programming language.'","import nltk 
from nltk.tokenize import word_tokenize 
  
# input text  
text = 'Python is an interpreted, high-level, general-purpose programming language.'
  
# converting the text into tokens 
token = word_tokenize(text) 
  
print(token)",Lainnya,4479,"import ___ 
from nltk.tokenize import word_tokenize 
  
# input text  
text = 'Python is an interpreted, high-level, general-purpose programming language.'
  
# converting the text into tokens 
token = word_tokenize(text) 
  
print(token)",nltk
Create a Machine Learning model in Python to classify the following dataset.,The dataset contains 100 samples with 10 features each.,"from sklearn.neighbors import KNeighborsClassifier

# Create the KNN classifier
knn = KNeighborsClassifier(n_neighbors = 3)

# Fit the classifier to the data
knn.fit(X, y)

# Predict the labels for the test set
y_pred = knn.predict(X_test)",Lainnya,4484,"from sklearn.neighbors import ___

# Create the KNN classifier
knn = KNeighborsClassifier(n_neighbors = 3)

# Fit the classifier to the data
knn.fit(X, y)

# Predict the labels for the test set
y_pred = knn.predict(X_test)",KNeighborsClassifier
Write a web scraper in Python to collect web data from a website.,Website: https://example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://example.com""

try: 
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    # your web scraping code here

except Exception as e:
    print('Error:', e)",Lainnya,4495,"import ___
from bs4 import BeautifulSoup

url = ""https://example.com""

try: 
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    # your web scraping code here

except Exception as e:
    print('Error:', e)",requests
Create a Python program to find the number of days between two dates.,"date1 = ""2020-10-01""
date2 = ""2020-10-31""","from datetime import datetime

def get_days_diff(date1, date2):
 d1 = datetime.strptime(date1, ""%Y-%m-%d"")
 d2 = datetime.strptime(date2, ""%Y-%m-%d"")
 return abs((d2 - d1).days)",Lainnya,4539,"from datetime import ___

def get_days_diff(date1, date2):
 d1 = datetime.strptime(date1, ""%Y-%m-%d"")
 d2 = datetime.strptime(date2, ""%Y-%m-%d"")
 return abs((d2 - d1).days)",datetime
Write a Python program that can detect emails within a given text.,Hello! My name is John and my email is john@example.com.,"import re

text = 'Hello! My name is John and my email is john@example.com.'

# Find all occurrences of an email using regex
email_regex = r""[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,4}""
result = re.findall(email_regex, text)

# Print emails found
print(""Emails found: \n"")
for email in result:
 print(email)",Lainnya,4580,"import ___

text = 'Hello! My name is John and my email is john@example.com.'

# Find all occurrences of an email using regex
email_regex = r""[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,4}""
result = re.findall(email_regex, text)

# Print emails found
print(""Emails found: \n"")
for email in result:
 print(email)",re
Construct a algorithm in Python to find the solution of linear equation.,"2x + 3y = 5 
5x - 4y = 7","# import necessary modules 
import numpy as np 
  
# define coefficient and constants 
a = np.array([[2, 3], [5, -4]]) 
b = np.array([5, 7]) 
  
# solve linear equations 
ans = np.linalg.solve(a, b) 
  
# print the solutions 
print(ans[0], ans[1])",Lainnya,4581,"# import ___ modules 
import numpy as np 
  
# define coefficient and constants 
a = np.array([[2, 3], [5, -4]]) 
b = np.array([5, 7]) 
  
# solve linear equations 
ans = np.linalg.solve(a, b) 
  
# print the solutions 
print(ans[0], ans[1])",necessary
Create a Python program to download a website from the Internet and save it locally.,"Website to download: ""https://www.example.com""","import urllib.request

url = 'https://www.example.com'

try:
 response = urllib.request.urlopen(url)
 content = response.read()
 filename = url.split('/')[-1]
 with open(filename, 'w') as file:
 file.write(content)
except Exception as e:
 print(e)",Lainnya,4604,"import ___.request

url = 'https://www.example.com'

try:
 response = urllib.request.urlopen(url)
 content = response.read()
 filename = url.split('/')[-1]
 with open(filename, 'w') as file:
 file.write(content)
except Exception as e:
 print(e)",urllib
Generate a code snippet in Python to handle HTTP requests from a given URL.,URL = 'https://example.com/test',"import requests

url = 'https://example.com/test'
 
# Make the request
response = requests.get(url)
 
# Check the response
if response.status_code == 200:
  # Success
  content = response.text
else:
  # Failure
  print(f'Request failed with status code: {response.status_code}')",Lainnya,4605,"import ___

url = 'https://example.com/test'
 
# Make the request
response = requests.get(url)
 
# Check the response
if response.status_code == 200:
  # Success
  content = response.text
else:
  # Failure
  print(f'Request failed with status code: {response.status_code}')",requests
Generate a classifier in Python using the Random Forest algorithm.,"Features: Weight, Size
Label: Type","from sklearn.ensemble import RandomForestClassifier

X = [[Weight, Size]]
y = [Type]

model = RandomForestClassifier(random_state=0)
model.fit(X, y)",Lainnya,4610,"from sklearn.ensemble import ___

X = [[Weight, Size]]
y = [Type]

model = RandomForestClassifier(random_state=0)
model.fit(X, y)",RandomForestClassifier
Write a Python script to generate a random username using letter and numbers.,[No input],"import string
from random import *

def generate_username():
    letters = string.ascii_letters
    numbers = string.digits
    username = """"
    for _ in range(10):
        username += choice(letters) + choice(numbers)
    return username

print(generate_username())",Lainnya,4616,"import ___
from random import *

def generate_username():
    letters = string.ascii_letters
    numbers = string.digits
    username = """"
    for _ in range(10):
        username += choice(letters) + choice(numbers)
    return username

print(generate_username())",string
Can you create a program Python to find the top ten most frequent words in a text?,"text=""Python is a great language to learn. It is very powerful and easy to learn.""","import collections

#Splitting the text into words
words=text.split()

#Creating a frequency table
word_freq = collections.Counter(words)

#Printing the top 10 most frequent words
for word, frequency in word_freq.most_common(10):
    print(word, frequency)",Lainnya,4625,"import ___

#Splitting the text into words
words=text.split()

#Creating a frequency table
word_freq = collections.Counter(words)

#Printing the top 10 most frequent words
for word, frequency in word_freq.most_common(10):
    print(word, frequency)",collections
Generate Python code to connect to a SQL database.,"hostname: test.com,
username: admin,
password: pwd123","import mysql.connector

connection = mysql.connector.connect(  
    host = ""test.com"",
    user = ""admin"",
    password = ""pwd123"",
    database = ""testdb""
)",Lainnya,4627,"import ___.connector

connection = mysql.connector.connect(  
    host = ""test.com"",
    user = ""admin"",
    password = ""pwd123"",
    database = ""testdb""
)",mysql
Propose a solution that optimizes the following python program.,"for i in range(1000):
    for j in range(1000):
        arr[i][j] += 5","import numpy as np

arr = np.array(arr)  # Convert to a numpy array

arr += 5  # add 5 to the array",Lainnya,4628,"import ___ as np

arr = np.array(arr)  # Convert to a numpy array

arr += 5  # add 5 to the array",numpy
Write a python program to extract the title of a given website,https://www.wikipedia.org,"import requests
from bs4 import BeautifulSoup

url = 'https://www.wikipedia.org' 
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
title = soup.find('title').text
print(title)
# Output: Wikipedia",Lainnya,4651,"import ___
from bs4 import BeautifulSoup

url = 'https://www.wikipedia.org' 
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
title = soup.find('title').text
print(title)
# Output: Wikipedia",requests
Generate a python program to scramble a sequence of characters.,'Hello World!',"import random 

# Initialize the string  
string = 'Hello World!'

# Convert the string to a list
char_list = list(string) 

# Shuffle the list
random.shuffle(char_list) 

# Convert back the list to a string
random_string = ''.join(char_list)

# Print the scrambled string
print(random_string)",Lainnya,4654,"import ___ 

# Initialize the string  
string = 'Hello World!'

# Convert the string to a list
char_list = list(string) 

# Shuffle the list
random.shuffle(char_list) 

# Convert back the list to a string
random_string = ''.join(char_list)

# Print the scrambled string
print(random_string)",random
Generate a Python program to visualize multiple dimensions of data with matplotlib.,.,"import matplotlib.pyplot as plt

x = [0, 1, 2, 3, 4, 5, 6, 7]
y = [0, 1, 4, 9, 16, 25, 36, 49]

plt.plot(x, y)
plt.xlabel('X Axis')
plt.ylabel('Y Axis')
plt.title('Plot of X and Y')
plt.show()",Lainnya,4657,"import ___.pyplot as plt

x = [0, 1, 2, 3, 4, 5, 6, 7]
y = [0, 1, 4, 9, 16, 25, 36, 49]

plt.plot(x, y)
plt.xlabel('X Axis')
plt.ylabel('Y Axis')
plt.title('Plot of X and Y')
plt.show()",matplotlib
Create a Python script to generate a given number of random numbers within a particular range,A range of 0 to 100 and 5 numbers,"# Import library
import random

# Generate random numbers
random_nums = []

for i in range(5):
    random_nums.append(random.randint(0,100))

# Print random numbers
print(random_nums)",Lainnya,4667,"# Import library
import ___

# Generate random numbers
random_nums = []

for i in range(5):
    random_nums.append(random.randint(0,100))

# Print random numbers
print(random_nums)",random
Analyze the following data and build a linear regression model in Python.,"x = [1, 2, 3, 4, 5, 6, 7] 
y = [2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]","import numpy as np

x = np.array([1,2,3,4,5,6,7])
y = np.array([2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5])

m = ((np.mean(x)*np.mean(y)) - np.mean(x*y))/((np.mean(x)**2) - np.mean(x**2))
c = np.mean(y) - (m*np.mean(x))

print(""slope ="", m)
print(""intercept ="", c)",Lainnya,4682,"import ___ as np

x = np.array([1,2,3,4,5,6,7])
y = np.array([2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5])

m = ((np.mean(x)*np.mean(y)) - np.mean(x*y))/((np.mean(x)**2) - np.mean(x**2))
c = np.mean(y) - (m*np.mean(x))

print(""slope ="", m)
print(""intercept ="", c)",numpy
Create a web scraper using Python that collects the title and content from the homepage of a given website.,https://www.example.com as the target website.,"import requests
import bs4

url = 'https://www.example.com'
r = requests.get(url)
html = bs4.BeautifulSoup(r.text,""html.parser"")

# Find title
title = html.find('title')
print(title.text)

# Find content
content = html.find('div', {'class': 'content'})
print(content.text)",Lainnya,4687,"import ___
import bs4

url = 'https://www.example.com'
r = requests.get(url)
html = bs4.BeautifulSoup(r.text,""html.parser"")

# Find title
title = html.find('title')
print(title.text)

# Find content
content = html.find('div', {'class': 'content'})
print(content.text)",requests
Transform the following data frame in Python.,"df = [
    {'name': 'Bob', 'age': 25},
    {'name': 'Mary', 'age': 18},
    {'name': 'John', 'age': 32},
]","import pandas as pd

df = pd.DataFrame(df)

#Transform the dataframe
df['age_group'] = [ ""under 20"" if a < 20
   else ""20-35"" if a < 35
   else ""over 35""
   for a in df['age']]",Lainnya,4708,"import ___ as pd

df = pd.DataFrame(df)

#Transform the dataframe
df['age_group'] = [ ""under 20"" if a < 20
   else ""20-35"" if a < 35
   else ""over 35""
   for a in df['age']]",pandas
Build a REST API endpoint in Python that takes a user's name and returns a personalized greeting message.,"name = ""John""","from flask import Flask

app = Flask(__name__)

@app.route('/greeting', methods=['GET'])
def get_greeting(name):
 return 'Hello, ' + name + '!'

if __name__ == '__main__':
 app.run()",Lainnya,4715,"from flask import ___

app = Flask(__name__)

@app.route('/greeting', methods=['GET'])
def get_greeting(name):
 return 'Hello, ' + name + '!'

if __name__ == '__main__':
 app.run()",Flask
Design a Python program that prints a sentence every 10 seconds.,"""Hello World""","import time

sentence = ""Hello World""

while True:
    print(sentence)
    time.sleep(10)",Lainnya,4718,"import ___

sentence = ""Hello World""

while True:
    print(sentence)
    time.sleep(10)",time
Create a Python program to capture the data from a web page.,https://www.example.com/,"import requests
import lxml.html as lh

url = 'https://www.example.com/'
page = requests.get(url)
doc = lh.fromstring(page.content)

# parse and extract data from webpage
data = doc.xpath('//p/text()')",Lainnya,4723,"import ___
import lxml.html as lh

url = 'https://www.example.com/'
page = requests.get(url)
doc = lh.fromstring(page.content)

# parse and extract data from webpage
data = doc.xpath('//p/text()')",requests
Develop a python program to remove punctuations from an input text,This is a great world - let's start coding!,"import string 
  
# Remove punctuations from string 
def remove_punctuations(s): 
    s = ''.join([i for i in s if i not in frozenset(string.punctuation)]) 
    return s 
  
# Driver Code 
if __name__ == ""__main__"" : 
  
    text = ""This is a great world - let's start coding!""
    print(remove_punctuations(text))",Lainnya,4773,"import ___ 
  
# Remove punctuations from string 
def remove_punctuations(s): 
    s = ''.join([i for i in s if i not in frozenset(string.punctuation)]) 
    return s 
  
# Driver Code 
if __name__ == ""__main__"" : 
  
    text = ""This is a great world - let's start coding!""
    print(remove_punctuations(text))",string
Create a web scraper in Python to extract all data from a page with the URL: http://example.com,http://example.com,"import requests 
from bs4 import BeautifulSoup

r = requests.get(""http://example.com"") 
data = r.text 
soup = BeautifulSoup(data, 'html.parser') 

for item in soup.find_all(""div""): 
 print(item.text)",Lainnya,4778,"import ___ 
from bs4 import BeautifulSoup

r = requests.get(""http://example.com"") 
data = r.text 
soup = BeautifulSoup(data, 'html.parser') 

for item in soup.find_all(""div""): 
 print(item.text)",requests
Calculate the number of days between two dates in Python.,"date1 = '2020-08-18'
date2 = '2020-09-01'","from datetime import date 
  
# Function to calculate number of days between two dates 
def getNumberOfDays(date1, date2): 
    return (date2 - date1).days 
  
# Driver program 
date1 = date(2020, 8, 18) 
date2 = date(2020, 9, 1) 
print(getNumberOfDays(date1, date2))",Lainnya,4817,"from datetime import ___ 
  
# Function to calculate number of days between two dates 
def getNumberOfDays(date1, date2): 
    return (date2 - date1).days 
  
# Driver program 
date1 = date(2020, 8, 18) 
date2 = date(2020, 9, 1) 
print(getNumberOfDays(date1, date2))",date
Write a Python program to process a dataset of words and count how many times each unique word appears.,"words = ['apple', 'apple', 'banana', 'apple', 'orange', 'banana', 'pear', 'orange', 'orange']","from collections import Counter

words = ['apple', 'apple', 'banana', 'apple', 'orange', 'banana', 'pear', 'orange', 'orange']

word_counts = Counter(words)

for word, count in word_counts.items():
    print(f'{word}: {count}')",Lainnya,4834,"from collections import ___

words = ['apple', 'apple', 'banana', 'apple', 'orange', 'banana', 'pear', 'orange', 'orange']

word_counts = Counter(words)

for word, count in word_counts.items():
    print(f'{word}: {count}')",Counter
Create a Python script to convert JSON data to CSV format.,"{
    “name”: “John”,
    “age”: 30,
    “city”: “New York”
}","import csv
import json

data = {
    “name”: “John”,
    “age”: 30,
    “city”: “New York”
}

with open('data.csv', 'w') as csvfile:
 writer = csv.writer(csvfile)
 writer.writerow([""Name"", ""Age"", ""City""])
 writer.writerow([data[""name""], data[""age""], data[""city""]])",Lainnya,4843,"import ___
import json

data = {
    “name”: “John”,
    “age”: 30,
    “city”: “New York”
}

with open('data.csv', 'w') as csvfile:
 writer = csv.writer(csvfile)
 writer.writerow([""Name"", ""Age"", ""City""])
 writer.writerow([data[""name""], data[""age""], data[""city""]])",csv
Write a Python program that extracts the domain name from a given URL.,https://www.google.com,"def get_domain(url):
  from urllib.parse import urlparse
  parsed_uri = urlparse(url)
  domain = '{uri.netloc}'.format(uri=parsed_uri)
  return domain

domain = get_domain(""https://www.google.com"")
print(domain)",Lainnya,4846,"def get_domain(url):
  from urllib.parse import ___
  parsed_uri = urlparse(url)
  domain = '{uri.netloc}'.format(uri=parsed_uri)
  return domain

domain = get_domain(""https://www.google.com"")
print(domain)",urlparse
Create a web service in Python which accepts a URL as input and prints the HTML of the page.,"url = ""www.example.com""","import requests

def get_html(url):
    response = requests.get(url)   
    if response.status_code == 200:
        return response.text
    else:
        return None

html = get_html(""www.example.com"")
if html:
    print(html)",Lainnya,4849,"import ___

def get_html(url):
    response = requests.get(url)   
    if response.status_code == 200:
        return response.text
    else:
        return None

html = get_html(""www.example.com"")
if html:
    print(html)",requests
Create a Python program to generate N random numbers between 0 and 1,N = 5,"import random

def gen_random_numbers(n):
    rand_nums = []    
    for i in range(n):
        rand_nums.append(random.uniform(0.0, 1.0))
    return rand_nums

rand_nums = gen_random_numbers(N)
print(rand_nums)",Lainnya,4852,"import ___

def gen_random_numbers(n):
    rand_nums = []    
    for i in range(n):
        rand_nums.append(random.uniform(0.0, 1.0))
    return rand_nums

rand_nums = gen_random_numbers(N)
print(rand_nums)",random
Create a Python program to open the user's default web browser with the given URL as an argument.,www.example.com,"import webbrowser

url = 'www.example.com'
webbrowser.open_new(url)",Lainnya,4855,"import ___

url = 'www.example.com'
webbrowser.open_new(url)",webbrowser
Generate a Python note to query a database and display 5 records.,"Database table name: ""users""","import sqlite3

conn = sqlite3.connect('database.db')
c = conn.cursor()

# query the database
c.execute('SELECT * FROM users LIMIT 5')

# fetch all records
records = c.fetchall()

# print all records
for record in records:
  print(record)

# close the connection
conn.close()",Lainnya,4859,"import ___

conn = sqlite3.connect('database.db')
c = conn.cursor()

# query the database
c.execute('SELECT * FROM users LIMIT 5')

# fetch all records
records = c.fetchall()

# print all records
for record in records:
  print(record)

# close the connection
conn.close()",sqlite3
Create a distance calculator program in Python that takes in two coordinates and returns the distance between them.,"coordinates1 = (5, 3)
coordinates2 = (2, 7)","import math

def distance_calc(coord1, coord2):
    """"""Returns the distance between two coordinates.""""""
    x1, y1 = coord1
    x2, y2 = coord2
    dist = math.sqrt((x2-x1)**2 + (y2-y1)**2)
    return dist

print(distance_calc(coordinates1, coordinates2))",Lainnya,4869,"import ___

def distance_calc(coord1, coord2):
    """"""Returns the distance between two coordinates.""""""
    x1, y1 = coord1
    x2, y2 = coord2
    dist = math.sqrt((x2-x1)**2 + (y2-y1)**2)
    return dist

print(distance_calc(coordinates1, coordinates2))",math
Write a Python script to calculate the distance between two points.,"Point1 = (x1, y1)
Point2 = (x2, y2)","import math

def calculate_distance(x1, y1, x2, y2):
  x_diff = x2 - x1
  y_diff = y2 - y1
  distance = math.sqrt(x_diff**2 + y_diff**2)
  return distance

result = calculate_distance(x1, y1, x2, y2)
print(result)",Lainnya,4885,"import ___

def calculate_distance(x1, y1, x2, y2):
  x_diff = x2 - x1
  y_diff = y2 - y1
  distance = math.sqrt(x_diff**2 + y_diff**2)
  return distance

result = calculate_distance(x1, y1, x2, y2)
print(result)",math
Create a python module to edit a dataframe,"The DataFrame is composed of two columns, 'id' and 'value'.","import pandas as pd

def edit_dataframe(df):

    # Adding the column 'new_value'
    df['new_value'] = df['value'] + 1

    # Replacing values in the 'id' column
    df['new_id'] = df['id'].map(lambda x: 'id_' + str(x))

    # Updating the value in the 'value' column
    df.value = df.value * 2

    return df",Lainnya,4893,"import ___ as pd

def edit_dataframe(df):

    # Adding the column 'new_value'
    df['new_value'] = df['value'] + 1

    # Replacing values in the 'id' column
    df['new_id'] = df['id'].map(lambda x: 'id_' + str(x))

    # Updating the value in the 'value' column
    df.value = df.value * 2

    return df",pandas
Create a Python script which uses the BeautifulSoup library to parse the data of a given webpage.,Webpage link = http://www.example.com,"import requests
from bs4 import BeautifulSoup

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')",Lainnya,4911,"import ___
from bs4 import BeautifulSoup

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')",requests
Create a Python program to sort a dictionary by value in descending order.,"Dictionary: {""a"": 3, ""b"": 1, ""c"": 5, ""d"": 4, ""e"": 2}","# Sort the given dictionary by value 
import operator
 
d = {'a':3, 'b':1, 'c':5, 'd':4, 'e':2}
sorted_d = sorted(d.items(), key=operator.itemgetter(1),reverse=True)
 
print(sorted_d)

// Output: [('c', 5), ('d', 4), ('a', 3), ('e', 2), ('b', 1)]",Lainnya,4920,"# Sort the given dictionary by value 
import ___
 
d = {'a':3, 'b':1, 'c':5, 'd':4, 'e':2}
sorted_d = sorted(d.items(), key=operator.itemgetter(1),reverse=True)
 
print(sorted_d)

// Output: [('c', 5), ('d', 4), ('a', 3), ('e', 2), ('b', 1)]",operator
Implement a web scraper in Python that downloads the contents of a given URL.,url = 'https://en.wikipedia.org/wiki/Web_scraping',"import requests
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/Web_scraping'

r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')

html = str(soup)

with open(""output.html"", ""w"") as file:
    file.write(html)",Lainnya,4948,"import ___
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/Web_scraping'

r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')

html = str(soup)

with open(""output.html"", ""w"") as file:
    file.write(html)",requests
Generate a Python program that uses the requests library to make a GET request to an API endpoint.,https://jsonplaceholder.typicode.com/users,"import requests

# Make a get request to get the latest users
response = requests.get('https://jsonplaceholder.typicode.com/users')

# Get the response data as a JSON
data = response.json()

# Print the data
print(data)",Lainnya,4961,"import ___

# Make a get request to get the latest users
response = requests.get('https://jsonplaceholder.typicode.com/users')

# Get the response data as a JSON
data = response.json()

# Print the data
print(data)",requests
"Using regular expression in Python, write a program to extract any birthday dates from a text.",This is a text where I am talking about my birthday 4th October 2020,"import re

text = 'This is a text where I am talking about my birthday 4th October 2020'

pattern = r'\d{1,2}\s[A-Z][a-z]{2,8}\s\d{4}'

match = re.search(pattern, text)
if match:
    print(match.group())",Lainnya,4990,"import ___

text = 'This is a text where I am talking about my birthday 4th October 2020'

pattern = r'\d{1,2}\s[A-Z][a-z]{2,8}\s\d{4}'

match = re.search(pattern, text)
if match:
    print(match.group())",re
Create a Python program that extrapolates the most frequent word from a given text.,"Text = ""This is an example of a text with some words""","from collections import Counter

def most_frequent_word(string):
    split_string = string.split("" "")
    counter = Counter(split_string)
    return counter.most_common(1)[0][0]

print(most_frequent_word(""This is an example of a text with some words""))",Lainnya,4997,"from collections import ___

def most_frequent_word(string):
    split_string = string.split("" "")
    counter = Counter(split_string)
    return counter.most_common(1)[0][0]

print(most_frequent_word(""This is an example of a text with some words""))",Counter
Implement a hash algorithm according to these specifications in Python.,"Length of Hashed String: 6
Hash Algorithm: SHA1","import hashlib

def generate_hash(string):
    hashed_string = hashlib.sha1(string.encode())
    return hashed_string.hexdigest()[:6]

hashed_string = generate_hash(""Code Generation Task Instructions"")
print(hashed_string)",Lainnya,5003,"import ___

def generate_hash(string):
    hashed_string = hashlib.sha1(string.encode())
    return hashed_string.hexdigest()[:6]

hashed_string = generate_hash(""Code Generation Task Instructions"")
print(hashed_string)",hashlib
Create a Python Flask application that takes a user input and generates a new text from the input.,Alice was once a a little girl living,"from flask import Flask

app = Flask(__name__)

@app.route('/', methods=['POST'])
def generate_newtext():
 input_text = request.form.get('input_text')
 
 new_text = input_text + "" She had wonderful adventures exploring the world around her and filled her days with joy.""
 
 return new_text
 
if __name__ == '__main__':
 app.run()",Lainnya,5016,"from flask import ___

app = Flask(__name__)

@app.route('/', methods=['POST'])
def generate_newtext():
 input_text = request.form.get('input_text')
 
 new_text = input_text + "" She had wonderful adventures exploring the world around her and filled her days with joy.""
 
 return new_text
 
if __name__ == '__main__':
 app.run()",Flask
"Write a Python program to generate a random password consisting of lowercase alphabets, numerical digits and special characters.",password length: 10,"import string
import random

def generate_password(length):
 password_characters = string.ascii_lowercase + string.digits + string.punctuation
 password = ''.join(random.choice(password_characters) for i in range(length))
 return password",Lainnya,5054,"import ___
import random

def generate_password(length):
 password_characters = string.ascii_lowercase + string.digits + string.punctuation
 password = ''.join(random.choice(password_characters) for i in range(length))
 return password",string
"Use regex in a Python program to find all instances of the word ""the"".",The quick brown fox jumps over the lazy dog,"import re

string = 'The quick brown fox jumps over the lazy dog'

# Prints matches
matches = re.findall('the', string, re.IGNORECASE)
print(matches)",Lainnya,5062,"import ___

string = 'The quick brown fox jumps over the lazy dog'

# Prints matches
matches = re.findall('the', string, re.IGNORECASE)
print(matches)",re
Create a web API in Python to get records from a database table.,Name of the database table: employee,"from flask import Flask, request, jsonify
import sqlite3

app = Flask(name)

@app.route('/api/v1/employees', methods=['GET'])
def get_employees():
 conn = sqlite3.connect('employees.db')
 cur = conn.cursor()
 data = cur.execute('SELECT * from employee').fetchall()
 conn.close()
 return jsonify(data)

if name == 'main':
 app.run(debug=True)",Lainnya,5110,"from flask import ___, request, jsonify
import sqlite3

app = Flask(name)

@app.route('/api/v1/employees', methods=['GET'])
def get_employees():
 conn = sqlite3.connect('employees.db')
 cur = conn.cursor()
 data = cur.execute('SELECT * from employee').fetchall()
 conn.close()
 return jsonify(data)

if name == 'main':
 app.run(debug=True)",Flask
"Given a sentence, tokenize it in Python, separating each of the words using the NLTK library.",The cat sat on the mat.,"import nltk

tokenized = nltk.word_tokenize(""The cat sat on the mat."")
print(tokenized)
# Output: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']",Lainnya,5142,"import ___

tokenized = nltk.word_tokenize(""The cat sat on the mat."")
print(tokenized)
# Output: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']",nltk
Use the following data to create a graphical representation in Python.,"x = [1,2,3,4,5]
y = [2,4,6,8,10]","import matplotlib.pyplot as plt

x = [1,2,3,4,5]
y = [2,4,6,8,10]

plt.plot(x,y)
plt.title('Graph title')
plt.xlabel('X-axis Label')
plt.ylabel('Y-axis Label')

plt.show()",Lainnya,5144,"import ___.pyplot as plt

x = [1,2,3,4,5]
y = [2,4,6,8,10]

plt.plot(x,y)
plt.title('Graph title')
plt.xlabel('X-axis Label')
plt.ylabel('Y-axis Label')

plt.show()",matplotlib
Create a Python script to download a zip archive from a URL and extract it in the current directory.,https://example.com/myzip.zip,"import requests
import shutil
import zipfile

url = 'https://example.com/myzip.zip'

response = requests.get(url, stream=True)

with open('myzip.zip', 'wb') as f:
 shutil.copyfileobj(response.raw, f)

with zipfile.ZipFile('myzip.zip', 'r') as f:
 f.extractall()",Lainnya,5148,"import ___
import shutil
import zipfile

url = 'https://example.com/myzip.zip'

response = requests.get(url, stream=True)

with open('myzip.zip', 'wb') as f:
 shutil.copyfileobj(response.raw, f)

with zipfile.ZipFile('myzip.zip', 'r') as f:
 f.extractall()",requests
Create a Python script to look up the IMDB rating of a movie by its title.,Title: The Prestige,"import imdb

ia = imdb.IMDb()
movie = ia.search_movie('The Prestige')[0]
ia.update(movie)

print(movie['rating'])
// Output: 8.5",Lainnya,5171,"import ___

ia = imdb.IMDb()
movie = ia.search_movie('The Prestige')[0]
ia.update(movie)

print(movie['rating'])
// Output: 8.5",imdb
Write a procedure in Python to rectify misspelled words in a paragraph.,"""My favarite flowers are rose and tulples""","import re

def fix_spelling(paragraph):
    words = paragraph.split()
    corrected_words = []
    for word in words:
        corrected_words.append(re.sub(r'[aeiou]',r'[aeiou]', word))
 
    return "" "".join(corrected_words)

print(fix_spelling(""My favarite flowers are rose and tulples""))",Lainnya,5196,"import ___

def fix_spelling(paragraph):
    words = paragraph.split()
    corrected_words = []
    for word in words:
        corrected_words.append(re.sub(r'[aeiou]',r'[aeiou]', word))
 
    return "" "".join(corrected_words)

print(fix_spelling(""My favarite flowers are rose and tulples""))",re
Make a POST request using Python to the specified URL.,URL: http://example.com/,"import requests

url = 'http://example.com/'
response = requests.post(url)",Lainnya,5225,"import ___

url = 'http://example.com/'
response = requests.post(url)",requests
Generate a bar chart using the given data in Python.,"data = [10, 5, 20, 25, 15]","import matplotlib.pyplot as plt

data = [10, 5, 20, 25, 15]

plt.bar(range(len(data)), data, color='blue')
plt.show()",Lainnya,5234,"import ___.pyplot as plt

data = [10, 5, 20, 25, 15]

plt.bar(range(len(data)), data, color='blue')
plt.show()",matplotlib
Categorize the following text into distinct classes using natural language processing techniques in Python.,Apple banana cherry,"from sklearn.feature_extraction.text import CountVectorizer 
  
# create the transform 
vectorizer = CountVectorizer(token_pattern=r""(?u)\b\w+\b"") 
  
# tokenize and build vocab 
vectorizer.fit([text]) 
  
# summarize 
print(vectorizer.vocabulary_) 

# output {'apple': 0, 'banana': 1, 'cherry': 2}",Lainnya,5244,"from sklearn.feature_extraction.text import ___ 
  
# create the transform 
vectorizer = CountVectorizer(token_pattern=r""(?u)\b\w+\b"") 
  
# tokenize and build vocab 
vectorizer.fit([text]) 
  
# summarize 
print(vectorizer.vocabulary_) 

# output {'apple': 0, 'banana': 1, 'cherry': 2}",CountVectorizer
Compile this Python code into an executable.,"def greeting():
  print(""Hello, World!"")

greeting()","import py_compile

py_compile.compile('sample.py', cfile='sample.pyc')",Lainnya,5294,"import ___

py_compile.compile('sample.py', cfile='sample.pyc')",py_compile
Build a web scraping script in Python that stores the HTML content of a website in a variable.,URL: https://www.example.com,"import urllib.request

url = 'https://www.example.com'

html_content = urllib.request.urlopen(url).read()",Lainnya,5313,"import ___.request

url = 'https://www.example.com'

html_content = urllib.request.urlopen(url).read()",urllib
"Given the following JSON input, write a Python program to calculate the average age of all the users.","[
  {
  ""name"": ""Alice"",
  ""age"": 25
  },
  {
  ""name"": ""Bob"",
  ""age"": 30
  },
  {
  ""name"": ""John"",
  ""age"": 20
  }
]","import json

users = json.loads(input)
total_age = 0
for user in users:
 total_age += user[""age""]

average_age = total_age / len(users)

print(f""Average age of users is {average_age}"")",Lainnya,5334,"import ___

users = json.loads(input)
total_age = 0
for user in users:
 total_age += user[""age""]

average_age = total_age / len(users)

print(f""Average age of users is {average_age}"")",json
Write a Python 3 script that reads input from stdin line by line and prints the number of occurrences of each word.,The quick brown fox jumps over the lazy dog,"import sys

dictionary={}

for line in sys.stdin:
 words_in_line = line.split()
 for word in words_in_line:
 word=word.lower()
 if word in dictionary:
 dictionary[word]+=1
 else:
 dictionary[word]=1

for word in dictionary:
 print(word +"":""+ str(dictionary[word]))",Lainnya,5340,"import ___

dictionary={}

for line in sys.stdin:
 words_in_line = line.split()
 for word in words_in_line:
 word=word.lower()
 if word in dictionary:
 dictionary[word]+=1
 else:
 dictionary[word]=1

for word in dictionary:
 print(word +"":""+ str(dictionary[word]))",sys
Write a Python script to fetch the current stock price of a given company,name = ABC,"from yahoo_fin import stock_info as si

def get_stock_price(name):
    data = si.get_live_price(name)
    return data

if __name__ == '__main__':
    name = 'ABC'
    print(get_stock_price(name))",Lainnya,5344,"from yahoo_fin import ___ as si

def get_stock_price(name):
    data = si.get_live_price(name)
    return data

if __name__ == '__main__':
    name = 'ABC'
    print(get_stock_price(name))",stock_info
Perform classification on the given dataset using Support Vector Machines in Python.,"X = [[0,0],[1,1],[1,2],[2,2],[2,3]]
y = [0,0,0,1,1]","from sklearn.svm import SVC

model = SVC(kernel = 'linear', probability=True) 
model.fit(X, y)",Lainnya,5345,"from sklearn.svm import ___

model = SVC(kernel = 'linear', probability=True) 
model.fit(X, y)",SVC
"Generate a Python script that takes two arguements, a filename and a number, and prints out all the lines from the filename whose length is less than the number.","file_name = 'sample.txt'
number = 10","import sys

file_name = sys.argv[1]
number = int(sys.argv[2])

with open(file_name, 'r') as f:
 for line in f:
 if len(line) < number:
 print(line, end='')",Lainnya,5351,"import ___

file_name = sys.argv[1]
number = int(sys.argv[2])

with open(file_name, 'r') as f:
 for line in f:
 if len(line) < number:
 print(line, end='')",sys
"Create a Python program that reads in a CSV, parse the data, and generates a JSON report.","Name, Age, Profession
John, 25, Engineer
Jane, 30, Developer","import csv
import json
 
csv_file = open('data.csv', 'r')
json_file = open('data.json', 'w')
 
fieldnames = (""Name"",""Age"",""Profession"")
reader = csv.DictReader(csv_file, fieldnames)
out = json.dumps([r for r in reader])
json_file.write(out)",Lainnya,5373,"import ___
import json
 
csv_file = open('data.csv', 'r')
json_file = open('data.json', 'w')
 
fieldnames = (""Name"",""Age"",""Profession"")
reader = csv.DictReader(csv_file, fieldnames)
out = json.dumps([r for r in reader])
json_file.write(out)",csv
Compute the median of a sequence of numbers in Python.,"Sequence: [3, -2, 4, 7, 10, 12, 11, -4, 8]","import statistics 
sequence = [3, -2, 4, 7, 10, 12, 11, -4, 8]
median = statistics.median(sequence) 
print(median) # Output: 7",Lainnya,5398,"import ___ 
sequence = [3, -2, 4, 7, 10, 12, 11, -4, 8]
median = statistics.median(sequence) 
print(median) # Output: 7",statistics
Create a Python program that takes a varchar input and encodes it using the Base 64 algorithm.,"""Hello World!""","import base64

string = ""Hello World!""

data_bytes = string.encode('ascii')
encoded_string = base64.b64encode(data_bytes)

print(encoded_string)",Lainnya,5414,"import ___

string = ""Hello World!""

data_bytes = string.encode('ascii')
encoded_string = base64.b64encode(data_bytes)

print(encoded_string)",base64
Generate a Python program to scrape the headlines from a given news article.,https://www.bbc.com/news/uk-england-london-53741405,"import requests
from bs4 import BeautifulSoup

url = ""https://www.bbc.com/news/uk-england-london-53741405""

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')

headlines = soup.find_all('h1', class_='story-body__h1')
for headline in headlines:
 print(headline.text)",Lainnya,5437,"import ___
from bs4 import BeautifulSoup

url = ""https://www.bbc.com/news/uk-england-london-53741405""

page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')

headlines = soup.find_all('h1', class_='story-body__h1')
for headline in headlines:
 print(headline.text)",requests
Create a web scraper using Python and the requests library to scrape data from a specific website.,Example website URL: https://www.example.com,"import requests

# Specify your website URL
url = 'https://www.example.com'

# Send a request to the website
response = requests.get(url)

# Check the status of the response
if response.status_code == 200:
 # Parse the HTML of the response
 response_html = response.content

 # Do something with the HTML
 print(response_html)",Lainnya,5501,"import ___

# Specify your website URL
url = 'https://www.example.com'

# Send a request to the website
response = requests.get(url)

# Check the status of the response
if response.status_code == 200:
 # Parse the HTML of the response
 response_html = response.content

 # Do something with the HTML
 print(response_html)",requests
Convert the following Matlab code into Python.,"a = 0:10:100;
b = zeros(101,1);
for i=1:101
b(i) = 5*i
end","import numpy as np
a = np.arange(0, 101, 10)
b = np.zeros(101)
for i in range(1, 101):
    b[i] = 5 * i",Lainnya,5536,"import ___ as np
a = np.arange(0, 101, 10)
b = np.zeros(101)
for i in range(1, 101):
    b[i] = 5 * i",numpy
Write a Python program to clean a given text from unwanted words and punctuations.,A raw string,"import string

def clean_text(text):
 # remove punctuation 
 translator = str.maketrans('', '', string.punctuation)
 text = text.translate(translator)
 
 # remove unwanted words
 unwanted_words = {'the', 'and', 'a'}
 words = text.split(' ')
 words = [word for word in words if word not in unwanted_words]
 
 return ' '.join(words)",Lainnya,5540,"import ___

def clean_text(text):
 # remove punctuation 
 translator = str.maketrans('', '', string.punctuation)
 text = text.translate(translator)
 
 # remove unwanted words
 unwanted_words = {'the', 'and', 'a'}
 words = text.split(' ')
 words = [word for word in words if word not in unwanted_words]
 
 return ' '.join(words)",string
Create an AI program in Python that determines whether a given sentence is a statement or a question.,The weather is cold today,"import re

def is_question(sentence):
 sentence = sentence.strip()
 if sentence.endswith('?'):
 return True
 else:
 return False

sentence = ""The weather is cold today""
print(is_question(sentence)) # False

sentence = ""Is it raining outside?""
print(is_question(sentence)) # True",Lainnya,5544,"import ___

def is_question(sentence):
 sentence = sentence.strip()
 if sentence.endswith('?'):
 return True
 else:
 return False

sentence = ""The weather is cold today""
print(is_question(sentence)) # False

sentence = ""Is it raining outside?""
print(is_question(sentence)) # True",re
Create a program in Python to compute the cosine similarity between two given vectors.,"[2, 5], [1, 3]","import numpy

def cos_sim(vec1, vec2):
    sim = numpy.dot(vec1, vec2)/(numpy.linalg.norm(vec1)* numpy.linalg.norm(vec2)) 
    return sim

vec1 = [2, 5]
vec2 = [1, 3]
print(""Cosine Similarity:"", cos_sim(vec1, vec2))",Lainnya,5546,"import ___

def cos_sim(vec1, vec2):
    sim = numpy.dot(vec1, vec2)/(numpy.linalg.norm(vec1)* numpy.linalg.norm(vec2)) 
    return sim

vec1 = [2, 5]
vec2 = [1, 3]
print(""Cosine Similarity:"", cos_sim(vec1, vec2))",numpy
Classify the given words using a Python classification program.,"Words: horse, dog, cat","import nltk
from nltk.tokenize import word_tokenize

words = ['horse', 'dog', 'cat']

tokens = [word_tokenize(word) for word in words]

for token in tokens:
    print(nltk.pos_tag([token])[0][1])

# prints NN, NN, NN",Lainnya,5569,"import ___
from nltk.tokenize import word_tokenize

words = ['horse', 'dog', 'cat']

tokens = [word_tokenize(word) for word in words]

for token in tokens:
    print(nltk.pos_tag([token])[0][1])

# prints NN, NN, NN",nltk
Create a simple webscraper using Python and Beautiful Soup.,URL of website to scrape: https://example.com,"import requests
from bs4 import BeautifulSoup
 
url = 'https://example.com'
content = requests.get(url).content
soup = BeautifulSoup(content, 'html.parser')
 
for element in soup.find_all('h2'):
    print(element.text)",Lainnya,5590,"import ___
from bs4 import BeautifulSoup
 
url = 'https://example.com'
content = requests.get(url).content
soup = BeautifulSoup(content, 'html.parser')
 
for element in soup.find_all('h2'):
    print(element.text)",requests
Generate a correct python program to fetch the price of a given stock ticker symbol.,Apple Inc. (AAPL),"import requests

def get_stock_price(symbol):
 url = ""https://finance.yahoo.com/quote/"" + symbol
 req = requests.get(url)
 data = req.json()
 return data['regularMarketPrice']",Lainnya,5591,"import ___

def get_stock_price(symbol):
 url = ""https://finance.yahoo.com/quote/"" + symbol
 req = requests.get(url)
 data = req.json()
 return data['regularMarketPrice']",requests
Design a classification model in Python that can predict the probability of a customer churning.,"data = [[1, 20, 0], [1, 24, 0], [0, 30, 1], [1, 35, 0], [1, 32, 0]]","import numpy as np
from sklearn.linear_model import LogisticRegression 

X = np.array([[1, 20, 0], [1, 24, 0], [0, 30, 1], [1, 35, 0], [1, 32, 0]])
y = np.array([0, 0, 1, 0, 0])

model = LogisticRegression()
model.fit(X, y)

prediction = model.predict_proba([[1, 33, 0]])",Lainnya,5623,"import ___ as np
from sklearn.linear_model import LogisticRegression 

X = np.array([[1, 20, 0], [1, 24, 0], [0, 30, 1], [1, 35, 0], [1, 32, 0]])
y = np.array([0, 0, 1, 0, 0])

model = LogisticRegression()
model.fit(X, y)

prediction = model.predict_proba([[1, 33, 0]])",numpy
"Using an HTTP library in Python (e.g. Requests), make a POST request and send a JSON payload to a web service.","const url = 'https://example.com/api/submit';
const data = {
 message: 'Hello!',
 name: 'John'
};","import requests

url = 'https://example.com/api/submit'
data = {'message': 'Hello!', 'name': 'John' }

r = requests.post(url, json=data)
print(r.text)",Lainnya,5638,"import ___

url = 'https://example.com/api/submit'
data = {'message': 'Hello!', 'name': 'John' }

r = requests.post(url, json=data)
print(r.text)",requests
Create a program in Python to predict the sentiment of a phrase using a provided pretrained model.,"model_path = ""mymodel.model""
phrase = ""This is a great day""","import numpy as np
from keras.models import load_model

# Load the model
model = load_model(model_path)

# Encode the phrase
phrase_encoded = np.array([phrase])

# Make the prediction
prediction = model.predict(phrase_encoded)

# Print the result
print(""The sentiment of the phrase is: {}"".format(prediction))",Lainnya,5653,"import ___ as np
from keras.models import load_model

# Load the model
model = load_model(model_path)

# Encode the phrase
phrase_encoded = np.array([phrase])

# Make the prediction
prediction = model.predict(phrase_encoded)

# Print the result
print(""The sentiment of the phrase is: {}"".format(prediction))",numpy
Write a Python program to select all the Sundays of a specified year.,year = 2020,"import datetime

def select_all_sundays(year):
    sunday_list = []
    for n in range(1,13):
        sundays = [d for d in [datetime.date(year, n, d) for d in range(1, 32)]
                if d.weekday() == 6]
        sunday_list.extend(sundays)
    return sunday_list

if __name__ == '__main__':
    year = 2020
    sunday_list = select_all_sundays(year)
    print(sunday_list)",Lainnya,5656,"import ___

def select_all_sundays(year):
    sunday_list = []
    for n in range(1,13):
        sundays = [d for d in [datetime.date(year, n, d) for d in range(1, 32)]
                if d.weekday() == 6]
        sunday_list.extend(sundays)
    return sunday_list

if __name__ == '__main__':
    year = 2020
    sunday_list = select_all_sundays(year)
    print(sunday_list)",datetime
Create a Python program to select high temperature days based on a given dataset.,Link to Dataset: http://web.engr.oregonstate.edu/~mjb/weather_data/index.html,"import pandas as pd

# Load data
df = pd.read_csv('Oregon_OregonState_97_02.csv', sep=',', index_col=0)

# Select days with high temperature
high_temp_days = df.query('T_MAX > 25')

# Display results
print(high_temp_days)",Lainnya,5675,"import ___ as pd

# Load data
df = pd.read_csv('Oregon_OregonState_97_02.csv', sep=',', index_col=0)

# Select days with high temperature
high_temp_days = df.query('T_MAX > 25')

# Display results
print(high_temp_days)",pandas
Develop a Python script to extract some text from a website.,Website URL: http://example.com,"import requests
from bs4 import BeautifulSoup
 
response = requests.get(""http://example.com"")
 
soup = BeautifulSoup(response.content, ""html.parser"")
 
text = soup.get_text()
print(text)",Lainnya,5680,"import ___
from bs4 import BeautifulSoup
 
response = requests.get(""http://example.com"")
 
soup = BeautifulSoup(response.content, ""html.parser"")
 
text = soup.get_text()
print(text)",requests
Develop a web scraper in Python to get all emails from a web page.,URL of the page: http://example.com,"import requests 
from bs4 import BeautifulSoup

# Get request to the URL
page = requests.get(""http://example.com"")

# Create a BeautifulSoup object from the response
soup = BeautifulSoup(page.content, 'html.parser') 

# Get all emails from the page
emails = soup.find_all('a', {'href': 'mailto'})

for email in emails:
    print(email.get('href').replace(""mailto:"", """"))",Lainnya,5717,"import ___ 
from bs4 import BeautifulSoup

# Get request to the URL
page = requests.get(""http://example.com"")

# Create a BeautifulSoup object from the response
soup = BeautifulSoup(page.content, 'html.parser') 

# Get all emails from the page
emails = soup.find_all('a', {'href': 'mailto'})

for email in emails:
    print(email.get('href').replace(""mailto:"", """"))",requests
Create a machine learning model in Python to classify a given dataset into 5 different classes.,"X (feature matrix), y (label vector)","from sklearn.neighbors import KNeighborsClassifier

# Initialize KNN model
knn_model = KNeighborsClassifier(n_neighbors=5)

# Fit the model
knn_model.fit(X, y)

# Predict the classes
y_pred = knn_model.predict(X)",Lainnya,5723,"from sklearn.neighbors import ___

# Initialize KNN model
knn_model = KNeighborsClassifier(n_neighbors=5)

# Fit the model
knn_model.fit(X, y)

# Predict the classes
y_pred = knn_model.predict(X)",KNeighborsClassifier
Create an API route in Python that allows users to retrieve the top 5 most recent posts from a blog.,Blog post data,"import datetime

@app.route('/posts')
def get_posts():
 posts = Post.query \
 .order_by(Post.created_at.desc()) \
 .limit(5)
 return jsonify([{
 'title': post.title,
 'date': post.created_at.strftime('%Y-%m-%d'),
 'body': post.body
 } for post in posts])",Lainnya,5737,"import ___

@app.route('/posts')
def get_posts():
 posts = Post.query \
 .order_by(Post.created_at.desc()) \
 .limit(5)
 return jsonify([{
 'title': post.title,
 'date': post.created_at.strftime('%Y-%m-%d'),
 'body': post.body
 } for post in posts])",datetime
Create a web scraping application in Python that downloads the source code of a website given its URL.,https://www.example.com/,"import urllib.request

url = ""https://www.example.com/""

response = urllib.request.urlopen(url) 
webContent = response.read()

f = open(""example.html"", ""w"")
f.write(webContent.decode('utf-8'))
f.close()",Lainnya,5748,"import ___.request

url = ""https://www.example.com/""

response = urllib.request.urlopen(url) 
webContent = response.read()

f = open(""example.html"", ""w"")
f.write(webContent.decode('utf-8'))
f.close()",urllib
Write a Python script to predict the sentiment of a given sentence using the TextBlob library.,"""Life is full of surprises.""","import textblob

sentence = ""Life is full of surprises.""
sentiment = textblob.TextBlob(sentence).sentiment.polarity

if sentiment == 0:
 # neutral sentiment
 print(""Neutral Sentiment"")
elif sentiment > 0:
 # positive sentiment
 print(""Positive Sentiment"")
else:
 # negative sentiment
 print(""Negative Sentiment"")",Lainnya,5783,"import ___

sentence = ""Life is full of surprises.""
sentiment = textblob.TextBlob(sentence).sentiment.polarity

if sentiment == 0:
 # neutral sentiment
 print(""Neutral Sentiment"")
elif sentiment > 0:
 # positive sentiment
 print(""Positive Sentiment"")
else:
 # negative sentiment
 print(""Negative Sentiment"")",textblob
Create a sentiment classifier using a linear regression algorithm in Python.,"Sentences:
1. I love this movie 
2. I hate this movie","import numpy as np

X = np.array([[1, 0], [0, 1]])
y = np.array([1, 0])

from sklearn.linear_model import LinearRegression 

model = LinearRegression().fit(X, y) 
  
predictions = model.predict(X) 
  
print(""Sentiment:"", predictions)",Lainnya,5786,"import ___ as np

X = np.array([[1, 0], [0, 1]])
y = np.array([1, 0])

from sklearn.linear_model import LinearRegression 

model = LinearRegression().fit(X, y) 
  
predictions = model.predict(X) 
  
print(""Sentiment:"", predictions)",numpy
Generate a Python script that extracts text from a given PDF and converts it to CSV.,A PDF file,"import os
import pdfplumber
import csv

# Open the pdf
with pdfplumber.open(file_path) as pdf:
 # Extract text
 text = pdf.extract_text()
 
 # Convert to list
 lines = text.splitlines()
 
 # Save as csv
 with open('file.csv', 'w') as csvfile:
 wr = csv.writer(csvfile)
 for line in lines:
 wr.writerow(line.split())",Lainnya,5789,"import ___
import pdfplumber
import csv

# Open the pdf
with pdfplumber.open(file_path) as pdf:
 # Extract text
 text = pdf.extract_text()
 
 # Convert to list
 lines = text.splitlines()
 
 # Save as csv
 with open('file.csv', 'w') as csvfile:
 wr = csv.writer(csvfile)
 for line in lines:
 wr.writerow(line.split())",os
"Write a Python program to predict the grade of a student, based on the past exam results.","Mia's last 3 exam results:
Math: 84
English: 89
Biology: 82","import numpy as np

# Input data
math = 84
english = 89
biology = 82

# Define weights
math_weight = 0.3
english_weight = 0.4
biology_weight = 0.3

# Compute weighted sum
grade = math * math_weight + english * english_weight + biology * biology_weight

# Print the grade
print('Mia\'s grade is: {:.2f}'.format(grade))",Lainnya,5793,"import ___ as np

# Input data
math = 84
english = 89
biology = 82

# Define weights
math_weight = 0.3
english_weight = 0.4
biology_weight = 0.3

# Compute weighted sum
grade = math * math_weight + english * english_weight + biology * biology_weight

# Print the grade
print('Mia\'s grade is: {:.2f}'.format(grade))",numpy
Write a Python program to generate random numbers in a specified range.,Range: 0 to 1000,"import random 
  
# Generates a random integer between 0 and 1000 
x = random.randint(0,1000) 
  
print(x)",Lainnya,5805,"import ___ 
  
# Generates a random integer between 0 and 1000 
x = random.randint(0,1000) 
  
print(x)",random
"In Python, parse the following XML document and extract the book title and author.","<book>
  <title>Title1</title>
  <author>Author1</author>
</book>","# import the necessary libraries
import xml.etree.ElementTree as ET

# Parse the XML document
root = ET.fromstring(xml_doc)

for book in root:
    if book.tag == 'title':
        title = book.text
    elif book.tag == 'author':
        author = book.text

print(f""Book Title: {title}, Author: {author}"")",Lainnya,5811,"# import ___ necessary libraries
import xml.etree.ElementTree as ET

# Parse the XML document
root = ET.fromstring(xml_doc)

for book in root:
    if book.tag == 'title':
        title = book.text
    elif book.tag == 'author':
        author = book.text

print(f""Book Title: {title}, Author: {author}"")",the
Generate a program in Python to calculate the area of a circle given its radius.,5.5,"import math

def calculate_area_of_circle(radius):
    area = math.pi * radius ** 2
    return area

result = calculate_area_of_circle(5.5)
print('The area of the circle is: ', result)",Lainnya,5832,"import ___

def calculate_area_of_circle(radius):
    area = math.pi * radius ** 2
    return area

result = calculate_area_of_circle(5.5)
print('The area of the circle is: ', result)",math
Write a Python script to make an HTTP request using the Requests library.,url = 'https://example.org',"import requests

resp = requests.get(url)

if resp.status_code == 200:
 print('Success!')
 print(resp.text)
 else:
 print('An error occurred.')",Lainnya,5835,"import ___

resp = requests.get(url)

if resp.status_code == 200:
 print('Success!')
 print(resp.text)
 else:
 print('An error occurred.')",requests
Create a program in Python that visualizes the data given.,"DataSet = [
    [1,2,3,4,5],
    [6,7,8,9,10],
    [11,12,13,14,15]
]","import matplotlib.pyplot as plt

data_set = [
    [1,2,3,4,5],
    [6,7,8,9,10],
    [11,12,13,14,15]
]

fig, ax = plt.subplots()
ax.plot(data_set)
ax.legend([""Group 1"", ""Group 2"", ""Group 3""])
plt.show()",Lainnya,5852,"import ___.pyplot as plt

data_set = [
    [1,2,3,4,5],
    [6,7,8,9,10],
    [11,12,13,14,15]
]

fig, ax = plt.subplots()
ax.plot(data_set)
ax.legend([""Group 1"", ""Group 2"", ""Group 3""])
plt.show()",matplotlib
Convert the following SQL query to Python.,"SELECT * 
FROM `employee_table`
WHERE `salary` < 10000","import sqlite3

db = sqlite3.connect(""employee_table.db"") # Assumes the table is in a file named employee_table.db
cur = db.cursor()

# Execute the SQL command
cur.execute(""SELECT * FROM employee_table WHERE salary < 10000"")

# Commit your changes
db.commit()

# Get the results
results = cur.fetchall()

# Print the results
for row in results:
    print(row)",Lainnya,5855,"import ___

db = sqlite3.connect(""employee_table.db"") # Assumes the table is in a file named employee_table.db
cur = db.cursor()

# Execute the SQL command
cur.execute(""SELECT * FROM employee_table WHERE salary < 10000"")

# Commit your changes
db.commit()

# Get the results
results = cur.fetchall()

# Print the results
for row in results:
    print(row)",sqlite3
Create a Python script to find the area of a circle when given its radius.,radius = 5,"import math
 
def area_circle(radius):
 return math.pi * (radius ** 2)
 
print(area_circle(radius))",Lainnya,5867,"import ___
 
def area_circle(radius):
 return math.pi * (radius ** 2)
 
print(area_circle(radius))",math
Write a Python script to retrieve a title from a given URL.,https://www.nytimes.com/2020/11/19/us/denver-police-protest.html,"import requests

url = 'https://www.nytimes.com/2020/11/19/us/denver-police-protest.html'
response = requests.get(url)

if response.status_code == 200:
 title = response.text.split(""<title>"")[1].split(""</title>"")[0]
 print(title)",Lainnya,5868,"import ___

url = 'https://www.nytimes.com/2020/11/19/us/denver-police-protest.html'
response = requests.get(url)

if response.status_code == 200:
 title = response.text.split(""<title>"")[1].split(""</title>"")[0]
 print(title)",requests
Create a Python program that uses natural language processing and machine learning to analyze sentiment in a given sentence.,The food was absolutely delicious.,"import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentences = [""The food was absolutely delicious.""]
sid = SentimentIntensityAnalyzer()

for sentence in sentences:
 print(sentence)
 ss = sid.polarity_scores(sentence)
 for k in ss:
 print('{0}: {1}'.format(k, ss[k]), end='\n')",Lainnya,5871,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sentences = [""The food was absolutely delicious.""]
sid = SentimentIntensityAnalyzer()

for sentence in sentences:
 print(sentence)
 ss = sid.polarity_scores(sentence)
 for k in ss:
 print('{0}: {1}'.format(k, ss[k]), end='\n')",nltk
Transform this JSON into a Python Dictionary.,"{""name"": ""John"", ""age"": 28, ""location"": ""New York""}","import json

# Load the JSON data into a Python Dictionary
data = json.loads('{""name"": ""John"", ""age"": 28, ""location"": ""New York""}')",Lainnya,5875,"import ___

# Load the JSON data into a Python Dictionary
data = json.loads('{""name"": ""John"", ""age"": 28, ""location"": ""New York""}')",json
Create a web scraper in Python using Selenium to extract the contents of a webpage.,URL: https://en.wikipedia.org/wiki/Python,"from selenium import webdriver

url = 'https://en.wikipedia.org/wiki/Python'

driver = webdriver.Chrome()
driver.get(url)

page_content = driver.page_source
 
driver.close()

# Process page_content",Lainnya,5907,"from selenium import ___

url = 'https://en.wikipedia.org/wiki/Python'

driver = webdriver.Chrome()
driver.get(url)

page_content = driver.page_source
 
driver.close()

# Process page_content",webdriver
Develop an API call in Python to fech data from a website.,Link to website: www.example.com,"import requests 

URL = ""www.example.com"" 
  
# defining a params dict for the parameters to be sent to the API 
PARAMS = { } 
  
# sending get request and saving the response as response object 
r = requests.get(url = URL, params = PARAMS) 
  
# extracting data in json format 
data = r.json() 
print(data)",Lainnya,5917,"import ___ 

URL = ""www.example.com"" 
  
# defining a params dict for the parameters to be sent to the API 
PARAMS = { } 
  
# sending get request and saving the response as response object 
r = requests.get(url = URL, params = PARAMS) 
  
# extracting data in json format 
data = r.json() 
print(data)",requests
Create a Python script to download a web page from a URL.,https://example.com,"import requests

# Get the webpage
url = 'https://example.com'
r = requests.get(url)

# Save the webpage to a file 
with open('webpage.html', 'wb') as f:
 f.write(r.content)",Lainnya,5920,"import ___

# Get the webpage
url = 'https://example.com'
r = requests.get(url)

# Save the webpage to a file 
with open('webpage.html', 'wb') as f:
 f.write(r.content)",requests
Generate a Python script that plots the relationship between two variables.,"x = [1, 2, 3, 4, 5]
    y = [2, 4, 6, 8, 10]","import matplotlib.pyplot as plt

x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

plt.plot(x, y)
plt.xlabel(""x"")
plt.ylabel(""y"")
plt.title(""Relationship between x and y"")
plt.show()",Lainnya,5926,"import ___.pyplot as plt

x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

plt.plot(x, y)
plt.xlabel(""x"")
plt.ylabel(""y"")
plt.title(""Relationship between x and y"")
plt.show()",matplotlib
Create a machine learning model in Python to predict the age of a person from their height and weight.,"Sample input: 
Height: 59
Weight: 140","import numpy as np
from sklearn.linear_model import LinearRegression

# Creating the X and Y datasets 
x = []
y = []

# Adding the data
x.append([59, 140])
y.append(30)

x = np.array(x)
y = np.array(y)

# Creating and fitting the model 
model = LinearRegression().fit(x, y)",Lainnya,5949,"import ___ as np
from sklearn.linear_model import LinearRegression

# Creating the X and Y datasets 
x = []
y = []

# Adding the data
x.append([59, 140])
y.append(30)

x = np.array(x)
y = np.array(y)

# Creating and fitting the model 
model = LinearRegression().fit(x, y)",numpy
"Create a command line tool in Python that takes input from the user and prints a message. The message should be ""You entered <input>.""",hello,"import sys

def main():
 args = sys.argv[1:]

 if args and len(args) == 1:
 print('You entered {}.'.format(args[0]))
 else:
 print('Please provide a single argument.')

if __name__ == ""__main__"":
 main()",Lainnya,5959,"import ___

def main():
 args = sys.argv[1:]

 if args and len(args) == 1:
 print('You entered {}.'.format(args[0]))
 else:
 print('Please provide a single argument.')

if __name__ == ""__main__"":
 main()",sys
Construct a Python program to calculate the age in years of a person given their birthdate.,06-11-96,"import datetime

def calculate_age(birthdate):

    today = datetime.date.today()
    current_year = today.year

    age = current_year - birthdate.year

    if ((birthdate.month, birthdate.day) > (today.month, today.day)):
        age -= 1
    
    return age

birthdate = datetime.date(1996, 6, 11)
age = calculate_age(birthdate)
print(age) # 24",Lainnya,5971,"import ___

def calculate_age(birthdate):

    today = datetime.date.today()
    current_year = today.year

    age = current_year - birthdate.year

    if ((birthdate.month, birthdate.day) > (today.month, today.day)):
        age -= 1
    
    return age

birthdate = datetime.date(1996, 6, 11)
age = calculate_age(birthdate)
print(age) # 24",datetime
Write a Python program that prints the time in a given timezone.,"timezone: ""UTC+11:00""","from datetime import datetime
import pytz

def print_time(tz):
  timezone = pytz.timezone(tz)
  print(datetime.now(timezone).strftime(""%H:%M:%S""))

print_time(""UTC+11:00"")",Lainnya,5972,"from datetime import ___
import pytz

def print_time(tz):
  timezone = pytz.timezone(tz)
  print(datetime.now(timezone).strftime(""%H:%M:%S""))

print_time(""UTC+11:00"")",datetime
Write a Python program to generate a random password with length x.,x = 8,"import string
import random

def generate_password(length):
    characters = string.ascii_letters + string.digits
    password = """"
    for i in range(length):
        password += random.choice(characters)
    return password

result = generate_password(8)
print(result)",Lainnya,5975,"import ___
import random

def generate_password(length):
    characters = string.ascii_letters + string.digits
    password = """"
    for i in range(length):
        password += random.choice(characters)
    return password

result = generate_password(8)
print(result)",string
Convert the following code from python 2.x to python 3.x.,"import csv
csvReader = csv.reader(open(""filename.csv"", ""rb""))","import csv

with open(""filename.csv"", 'r', newline='') as f:
    csvReader = csv.reader(f)",Lainnya,5986,"import ___

with open(""filename.csv"", 'r', newline='') as f:
    csvReader = csv.reader(f)",csv
Create a Pie Chart in Python with the following data,"Item	Frequency
Pen	4
Pencil	9
Eraser	3","import matplotlib.pyplot as plt

items = ['Pen', 'Pencil', 'Eraser']
frequencies = [4, 9, 3]

plt.pie(frequencies, labels=items, autopct='%1.1f%%', shadow=True, startangle=90)
plt.axis('equal')
plt.show()",Lainnya,6029,"import ___.pyplot as plt

items = ['Pen', 'Pencil', 'Eraser']
frequencies = [4, 9, 3]

plt.pie(frequencies, labels=items, autopct='%1.1f%%', shadow=True, startangle=90)
plt.axis('equal')
plt.show()",matplotlib
Write a Python program to find all the words with a length equal to 5 in a sentence and replace them with a placeholder.,"The sentence is ""The quick brown fox jumped over the lazy dog""","sentence = 'The quick brown fox jumped over the lazy dog'
words = sentence.split()

for i in range(len(words)):
 if len(words[i]) == 5:
 words[i] = '_____'

modified_sentence = ' '.join(words)
print(modified_sentence)
# Output: The _____ brown _____ jumped over the _____ _____",Lainnya,6056,"sentence = 'The quick brown fox jumped over the lazy dog'
words = sentence.split()

for i in range(len(words)):
 if len(words[i]) == 5:
 words[i] = '_____'

modified_sentence = ' '.join(words)
print(modified_sentence)
# Output: The _____ brown _____ jumped over the _____ _____",
Create a web scraper program in Python that can scrape a given website.,"The website to be scraped is ""https://www.example.com/"".","import requests
from bs4 import BeautifulSoup

url = 'https://www.example.com/'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# scrape the website using soup",Lainnya,6067,"import ___
from bs4 import BeautifulSoup

url = 'https://www.example.com/'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# scrape the website using soup",requests
Create a Python program to visualize Pandas DataFrame.,"df = pandas.DataFrame({
    'Name': ['Alice', 'Bob', 'Carol', 'Dave'],
    'Age': [18, 25, 35, 45]
})","import matplotlib.pyplot as plt
import pandas as pd

df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Carol', 'Dave'],
    'Age': [18, 25, 35, 45]
})

ax = df.plot.bar(x='Name', y='Age', rot=0)

plt.show()",Lainnya,6070,"import ___.pyplot as plt
import pandas as pd

df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Carol', 'Dave'],
    'Age': [18, 25, 35, 45]
})

ax = df.plot.bar(x='Name', y='Age', rot=0)

plt.show()",matplotlib
"Using the provided data, generate a decision tree classifier in Python.","X = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])
Y = np.array([0, 0, 1, 1])","from sklearn.tree import DecisionTreeClassifier

# Create and train a Decision Tree classifier
clf = DecisionTreeClassifier().fit(X, y)

# Make predictions
predictions = clf.predict(X)

# Print the predictions
print(predictions)",Lainnya,6072,"from sklearn.tree import ___

# Create and train a Decision Tree classifier
clf = DecisionTreeClassifier().fit(X, y)

# Make predictions
predictions = clf.predict(X)

# Print the predictions
print(predictions)",DecisionTreeClassifier
Create a python script that filters out all negative numbers from the given matrix,"[[-1, 2, -3], [-4, 5, 6], [-7, 8, 9]]","import numpy as np

def filter_out_negative(matrix):
  # Convert matrix to numpy array
  matrix = np.array(matrix)
  # Find all negative numbers and set them to 0
  matrix[matrix < 0] = 0
  return matrix

result = filter_out_negative([[-1, 2, -3], [-4, 5, 6], [-7, 8, 9]])
print(result)",Lainnya,6075,"import ___ as np

def filter_out_negative(matrix):
  # Convert matrix to numpy array
  matrix = np.array(matrix)
  # Find all negative numbers and set them to 0
  matrix[matrix < 0] = 0
  return matrix

result = filter_out_negative([[-1, 2, -3], [-4, 5, 6], [-7, 8, 9]])
print(result)",numpy
Write a Python program using the SciPy library to solve the given equation.,3x - 2y + z = 5,"from scipy.optimize import fsolve

#define the equation
def equation(p):
    x, y, z = p
    return (3*x - 2*y + z - 5)

#solve the equation
result =  fsolve(equation, (1, 1, 1)) 

#Print the result 
print(result)",Lainnya,6097,"from scipy.optimize import ___

#define the equation
def equation(p):
    x, y, z = p
    return (3*x - 2*y + z - 5)

#solve the equation
result =  fsolve(equation, (1, 1, 1)) 

#Print the result 
print(result)",fsolve
Convert this SQL query to Python.,"SELECT *
FROM customers
WHERE customer_name LIKE '%John%'","import pydb

def query_customer_name(name):
    query = """"""
    SELECT *
    FROM customers
    WHERE customer_name LIKE %s""""""
    name_wildcard = '%' + name + '%'
    query_result = pydb.query(query, name_wildcard)
    return query_result
    
if __name__ == '__main__':
    query_customer_name('John')",Lainnya,6112,"import ___

def query_customer_name(name):
    query = """"""
    SELECT *
    FROM customers
    WHERE customer_name LIKE %s""""""
    name_wildcard = '%' + name + '%'
    query_result = pydb.query(query, name_wildcard)
    return query_result
    
if __name__ == '__main__':
    query_customer_name('John')",pydb
Create a network application in Python that sends a GET request to an API and parses the JSON response.,URL of API endpoint: https://api.mydomain.com/getdata,"import requests

url = 'https://api.mydomain.com/getdata'
response = requests.get(url)

data = response.json()
print(data)",Lainnya,6128,"import ___

url = 'https://api.mydomain.com/getdata'
response = requests.get(url)

data = response.json()
print(data)",requests
"Create a Python script that replaces all words containing 3 or more consecutive vowels with ""*"".","""entertainment""","import re

def replaceConsecutiveVowels(word): 
    regex = re.compile(r'[aeiou]{3,}', re.IGNORECASE) 
    return regex.sub(""*"", word)

word = ""entertainment""

print(replaceConsecutiveVowels(word)) # Output: *",Lainnya,6134,"import ___

def replaceConsecutiveVowels(word): 
    regex = re.compile(r'[aeiou]{3,}', re.IGNORECASE) 
    return regex.sub(""*"", word)

word = ""entertainment""

print(replaceConsecutiveVowels(word)) # Output: *",re
Create a Python program to download and save a web page using the Requests library.,https://www.example.com,"import requests

url = 'https://www.example.com'

response = requests.get(url)

with open('example.html', 'wb') as file:
 file.write(response.content)",Lainnya,6153,"import ___

url = 'https://www.example.com'

response = requests.get(url)

with open('example.html', 'wb') as file:
 file.write(response.content)",requests
Create an AIX application using Python that takes in user text and returns an appropriate response.,"User input text: ""I'm feeling sad.""","import gpt_2_simple as gpt2

# Load the GPT-2 model
sess = gpt2.start_tf_sess()
gpt2.load_gpt2(sess, run_name='run1')

# Generate a response text
generated_text = gpt2.generate(sess,
 temperature=0.7,
 prefix=""I'm feeling sad."",
 length=30,
 return_as_list=True
)[0]

# Print the response
print(generated_text)",Lainnya,6160,"import ___ as gpt2

# Load the GPT-2 model
sess = gpt2.start_tf_sess()
gpt2.load_gpt2(sess, run_name='run1')

# Generate a response text
generated_text = gpt2.generate(sess,
 temperature=0.7,
 prefix=""I'm feeling sad."",
 length=30,
 return_as_list=True
)[0]

# Print the response
print(generated_text)",gpt_2_simple
Calculate the area of a circle using a Python program,radius = 7,"import math

def areaOfCircle(radius):
    area = round(math.pi * (radius ** 2), 2)
    return area

area = areaOfCircle(7)
print(area)",Lainnya,6166,"import ___

def areaOfCircle(radius):
    area = round(math.pi * (radius ** 2), 2)
    return area

area = areaOfCircle(7)
print(area)",math
Develop a Python program that takes in an URL and extracts all the text content from the page.,'https://www.example.com/',"import requests
from bs4 import BeautifulSoup

url = 'https://www.example.com/'

page = requests.get(url)
html = BeautifulSoup(page.content, 'html.parser')

texts = []
for txt in  html.find_all('p'):
    texts.append(txt.text)

print(texts)",Lainnya,6179,"import ___
from bs4 import BeautifulSoup

url = 'https://www.example.com/'

page = requests.get(url)
html = BeautifulSoup(page.content, 'html.parser')

texts = []
for txt in  html.find_all('p'):
    texts.append(txt.text)

print(texts)",requests
Create a script in Python to apply Principal Component Analysis (PCA) on a given dataset.,"dataset = [[1,2,3],[4,5,6],[7,8,9]]","from sklearn.decomposition import PCA

# define a 3x3 matrix 
matrix_data = dataset 
pca = PCA(n_components=2) 

# transform 3x3 matrix into 2x2 matrix 
transformed_data = pca.fit_transform(matrix_data) 

print(transformed_data)",Lainnya,6196,"from sklearn.decomposition import ___

# define a 3x3 matrix 
matrix_data = dataset 
pca = PCA(n_components=2) 

# transform 3x3 matrix into 2x2 matrix 
transformed_data = pca.fit_transform(matrix_data) 

print(transformed_data)",PCA
Take a given Python dictionary and transform it to a standardized format using JSON.,"my_dict = {
 'name': 'John Doe',
 'age': 42,
 'occupation': 'Programmer'
}","import json

my_dict = {
 'name': 'John Doe',
 'age': 42,
 'occupation': 'Programmer'
}

# Transform to JSON
my_json = json.dumps(my_dict)

print(my_json) # Output: {""name"":""John Doe"",""age"":42,""occupation"":""Programmer""}",Lainnya,6231,"import ___

my_dict = {
 'name': 'John Doe',
 'age': 42,
 'occupation': 'Programmer'
}

# Transform to JSON
my_json = json.dumps(my_dict)

print(my_json) # Output: {""name"":""John Doe"",""age"":42,""occupation"":""Programmer""}",json
Create a Python script to read a given PDF document.,file = ‘document.pdf’,"import PyPDF2

# open and read the pdf file
file = open('document.pdf', 'rb')
reader = PyPDF2.PdfFileReader(file)

# read complete document
for page in range(reader.numPages):
    print(reader.getPage(page).extractText())

file.close()",Lainnya,6234,"import ___

# open and read the pdf file
file = open('document.pdf', 'rb')
reader = PyPDF2.PdfFileReader(file)

# read complete document
for page in range(reader.numPages):
    print(reader.getPage(page).extractText())

file.close()",PyPDF2
Write a Python code snippet to create a user account with the given name and password.,"Name: John
Password: J0hnP455w0rd","import bcrypt

name = ""John""
password = ""J0hnP455w0rd""
password_hash = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())

# Create user account in the database
# with the given name and hashed password
# ----------
# Code to store username and 
# hashed password in the database 
# ----------",Lainnya,6235,"import ___

name = ""John""
password = ""J0hnP455w0rd""
password_hash = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())

# Create user account in the database
# with the given name and hashed password
# ----------
# Code to store username and 
# hashed password in the database 
# ----------",bcrypt
Construct a regular expression in Python to find all consecutive digits in a sentence.,"There are 3 sets of consecutive numbers in this sentence: 12, 22 and 33.","import re 

str = ""There are 3 sets of consecutive numbers in this sentence: 12, 22 and 33.""

num_list = re.findall(r'\d+', str)
print(num_list)
# Output: ['3', '12', '22', '33']",Lainnya,6248,"import ___ 

str = ""There are 3 sets of consecutive numbers in this sentence: 12, 22 and 33.""

num_list = re.findall(r'\d+', str)
print(num_list)
# Output: ['3', '12', '22', '33']",re
Write a Python program to validate a given email address. The program should ensure that the given email follows valid email syntax.,example@example.com,"import re

def is_valid_email(email):
 email_regex = re.compile(r""^[\w\.\+\-]+\@[\w]+\.[a-z]{2,3}$"")
 return email_regex.match(email)

email = ""example@example.com""
if is_valid_email(email):
 print(""Valid email address"")
else:
 print(""Invalid email address"")",Lainnya,6274,"import ___

def is_valid_email(email):
 email_regex = re.compile(r""^[\w\.\+\-]+\@[\w]+\.[a-z]{2,3}$"")
 return email_regex.match(email)

email = ""example@example.com""
if is_valid_email(email):
 print(""Valid email address"")
else:
 print(""Invalid email address"")",re
Write a python code to complete the following.,Sequentially fill a numpy array of size 4 with numbers from 0 to 3,"import numpy as np
arr = np.zeros(4, dtype=int)
 
for i in range(len(arr)):
    arr[i] = i",Lainnya,6289,"import ___ as np
arr = np.zeros(4, dtype=int)
 
for i in range(len(arr)):
    arr[i] = i",numpy
Produce a chart of linear equations in Python.,"Equations:
y = 5x + 2
y = -3x + 6","import matplotlib.pyplot as plt

x = [i for i in range(-10, 10)]
y1 = [5*i + 2 for i in x]
y2 = [-3*i + 6 for i in x]

plt.plot(x, y1, label='y = 5x + 2')
plt.plot(x, y2, label='y = -3x + 6')
plt.legend()
plt.show()",Lainnya,6322,"import ___.pyplot as plt

x = [i for i in range(-10, 10)]
y1 = [5*i + 2 for i in x]
y2 = [-3*i + 6 for i in x]

plt.plot(x, y1, label='y = 5x + 2')
plt.plot(x, y2, label='y = -3x + 6')
plt.legend()
plt.show()",matplotlib
Create a web scraper in Python to crawl a website and collect data about a particular topic.,The URL of the website to be crawled.,"import requests
import bs4

web_url = '<input URL>' # Insert URL here

def scrape(url):
    response = requests.get(url)
    soup = bs4.BeautifulSoup(response.text, 'lxml')

    output = []

    # Scrape the web page to get the required data
    ...

    return output

if __name__ == '__main__':
    print(scrape(web_url))",Lainnya,6329,"import ___
import bs4

web_url = '<input URL>' # Insert URL here

def scrape(url):
    response = requests.get(url)
    soup = bs4.BeautifulSoup(response.text, 'lxml')

    output = []

    # Scrape the web page to get the required data
    ...

    return output

if __name__ == '__main__':
    print(scrape(web_url))",requests
Create a Python program to generate a report of a user's sales data.,A list of dictionaries containing sales data.,"import csv

# A list of dictionaries containing sales data
sales_data = [
 { 'name': 'John', 'quantity': 2, 'price': 10.0 },
 { 'name': 'Jane', 'quantity': 3, 'price': 15.0 },
 { 'name': 'Mike', 'quantity': 4, 'price':",Lainnya,6336,"import ___

# A list of dictionaries containing sales data
sales_data = [
 { 'name': 'John', 'quantity': 2, 'price': 10.0 },
 { 'name': 'Jane', 'quantity': 3, 'price': 15.0 },
 { 'name': 'Mike', 'quantity': 4, 'price':",csv
Develop a machine learning algorithm in Python to identify apples from bananas.,No Input,"import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC

# Load data
X = np.array([[1,2,3], [-1,2,5], [-1,2,7], [5,5,5], [3,3,3], [5,5,7]])
y = np.array([0, 0, 0, 1, 0, 1])

# Initialize classifier
clf = SVC(kernel='linear')

# Fit data
clf.fit(X, y)

# Test classifier
x_test = np.array([[2,2,2], [4,4,4]])

prediction = clf.predict(x_test)
print(prediction)",Lainnya,6347,"import ___ as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC

# Load data
X = np.array([[1,2,3], [-1,2,5], [-1,2,7], [5,5,5], [3,3,3], [5,5,7]])
y = np.array([0, 0, 0, 1, 0, 1])

# Initialize classifier
clf = SVC(kernel='linear')

# Fit data
clf.fit(X, y)

# Test classifier
x_test = np.array([[2,2,2], [4,4,4]])

prediction = clf.predict(x_test)
print(prediction)",numpy
Edit an existing Python program to calculate the area of a circle.,"import math
def area(radius):
    return math.pi * radius ** 2","import math
def area(radius):
    area = math.pi * radius ** 2
    return area",Lainnya,6352,"import ___
def area(radius):
    area = math.pi * radius ** 2
    return area",math
Build a decision tree classifier in Python that classfies the given data points.,"[[2,1,1], [2,2,0], [2,0,1], [1,1,1], [1,0,1], [1,2,0], [0,2,0], [0,1,1], [0,0,1]]","import numpy as np
from sklearn.tree import DecisionTreeClassifier

X = np.matrix('2 1 1; 2 2 0; 2 0 1; 1 1 1; 1 0 1; 1 2 0; 0 2 0; 0 1 1; 0 0 1')
Y = np.array([1, 0, 1, 1, 1, 0, 0, 1, 1])

model = DecisionTreeClassifier().fit(X,Y)",Lainnya,6360,"import ___ as np
from sklearn.tree import DecisionTreeClassifier

X = np.matrix('2 1 1; 2 2 0; 2 0 1; 1 1 1; 1 0 1; 1 2 0; 0 2 0; 0 1 1; 0 0 1')
Y = np.array([1, 0, 1, 1, 1, 0, 0, 1, 1])

model = DecisionTreeClassifier().fit(X,Y)",numpy
Design a Python script to access a REST API.,`https://example.com/api/v1/data`,"import requests

url = 'https://example.com/api/v1/data'

response = requests.get(url)
data = response.json()

# process the data here
# ...",Lainnya,6373,"import ___

url = 'https://example.com/api/v1/data'

response = requests.get(url)
data = response.json()

# process the data here
# ...",requests
Develop an algorithm to generate a random integer between 0 and n in Python.,n = 6,"import random

def random_number(n):
  return random.randint(0, n)

random_num = random_number(6)
print(random_num)",Lainnya,6374,"import ___

def random_number(n):
  return random.randint(0, n)

random_num = random_number(6)
print(random_num)",random
Write a Python script to compress a directory using the gzip library.,source directory: example_dir,"import gzip
import os

# Walk through the source directory
for root, dirs, files in os.walk('example_dir'):
    # Gzip each file
    for file in files:
        with open(os.path.join(root, file), 'rb') as f_in:
            with gzip.open(os.path.join(root, file + '.gz'), 'wb') as f_out:
                f_out.writelines(f_in)",Lainnya,6378,"import ___
import os

# Walk through the source directory
for root, dirs, files in os.walk('example_dir'):
    # Gzip each file
    for file in files:
        with open(os.path.join(root, file), 'rb') as f_in:
            with gzip.open(os.path.join(root, file + '.gz'), 'wb') as f_out:
                f_out.writelines(f_in)",gzip
Create a python program to detect the languages of the given text,"A text sample such as ""Hello, my name is John Smith""","def detect_language(txt):
    '''This function will detect the language of the given text.'''
    import langdetect
    lang = langdetect.detect(txt)
    return lang

if __name__ == ""__main__"":
    txt = ""Hello, my name is John Smith""
    print(detect_language(txt))",Lainnya,6382,"def detect_language(txt):
    '''This function will detect the language of the given text.'''
    import ___
    lang = langdetect.detect(txt)
    return lang

if __name__ == ""__main__"":
    txt = ""Hello, my name is John Smith""
    print(detect_language(txt))",langdetect
Generate a Python program to find the nearest prime number greater than an inputted number,26,"#import libraries
import sympy

# define the input
num = 26

# set the flag to True
flag = True

# check for prime numbers
while flag:
    num += 1
    if sympy.isprime(num):
        flag = False

# print the output
print(num)",Lainnya,6397,"#import ___
import sympy

# define the input
num = 26

# set the flag to True
flag = True

# check for prime numbers
while flag:
    num += 1
    if sympy.isprime(num):
        flag = False

# print the output
print(num)",libraries
"Using Python, write a script to detect any outliers in the given dataset.","Data points: [3, 5, 7, 8, 9, 2, 10, 11, 12, 60]","import numpy as np 
def detect_outliers(data): 
    outliers = [] 
    data = np.array(data) 
    mean = np.mean(data) 
    std = np.std(data) 
    for i in data: 
        z_score = (i - mean) / std
        if np.abs(z_score) > 3:
            outliers.append(i) 
    return outliers",Lainnya,6423,"import ___ as np 
def detect_outliers(data): 
    outliers = [] 
    data = np.array(data) 
    mean = np.mean(data) 
    std = np.std(data) 
    for i in data: 
        z_score = (i - mean) / std
        if np.abs(z_score) > 3:
            outliers.append(i) 
    return outliers",numpy
Create a Python program to remove punctuations from the given sentence,"He loves to eat Italian; pizza, pasta, and gelato","import string

def remove_punctuations(sentence):
    translator = str.maketrans('', '', string.punctuation)
    return sentence.translate(translator)

print(remove_punctuations(""He loves to eat Italian; pizza, pasta, and gelato""))",Lainnya,6425,"import ___

def remove_punctuations(sentence):
    translator = str.maketrans('', '', string.punctuation)
    return sentence.translate(translator)

print(remove_punctuations(""He loves to eat Italian; pizza, pasta, and gelato""))",string
Create a visualization in Python using Matplotlib that displays the top 5 most popular programming languages.,"x_values = [""Python"", ""Java"", ""C++"", ""Javascript"", ""C#""]
y_values = [45, 25, 15, 10, 5]","import matplotlib.pyplot as plt

x_values = [""Python"", ""Java"", ""C++"", ""Javascript"", ""C#""]
y_values = [45, 25, 15, 10, 5]

plt.bar(x_values, y_values)

plt.title(""Popular Programming Languages"")
plt.ylabel(""Percentage of Use"")
plt.xlabel(""Languages"")

plt.show()",Lainnya,6450,"import ___.pyplot as plt

x_values = [""Python"", ""Java"", ""C++"", ""Javascript"", ""C#""]
y_values = [45, 25, 15, 10, 5]

plt.bar(x_values, y_values)

plt.title(""Popular Programming Languages"")
plt.ylabel(""Percentage of Use"")
plt.xlabel(""Languages"")

plt.show()",matplotlib
Create a web scraper using Python and BeautifulSoup to extract the prices of a product from an online store,https://example.com/product/123,"import requests
from bs4 import BeautifulSoup

url = 'https://example.com/product/123'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

price_block = soup.find('div', class_='price')
prices = [float(price.text) for price in price_block.find_all('span')]

print(f""Prices for {url} are {prices}"")",Lainnya,6457,"import ___
from bs4 import BeautifulSoup

url = 'https://example.com/product/123'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

price_block = soup.find('div', class_='price')
prices = [float(price.text) for price in price_block.find_all('span')]

print(f""Prices for {url} are {prices}"")",requests
Analyze the sentiment of a given text using Python,I love writing code!,"from nltk.sentiment.vader import SentimentIntensityAnalyzer

#init sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

#analyze sentiment
sentiment_scores = analyzer.polarity_scores(""I love writing code!"")

if sentiment_scores['pos'] > sentiment_scores['neg']:
    print (""The sentiment of the text is positive"")
else:
    print (""The sentiment of the text is negative"")",Lainnya,6479,"from nltk.sentiment.vader import ___

#init sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

#analyze sentiment
sentiment_scores = analyzer.polarity_scores(""I love writing code!"")

if sentiment_scores['pos'] > sentiment_scores['neg']:
    print (""The sentiment of the text is positive"")
else:
    print (""The sentiment of the text is negative"")",SentimentIntensityAnalyzer
Create a script in Python that prints a matrix of size n x m containing random numbers.,"n=3, m=2","import random

def random_matrix(n, m):
    matrix = []
    for i in range(n):
        row = []
        for j in range(m):
            row.append(random.randint(1,100))
        matrix.append(row)
    return matrix

res = random_matrix(3, 2)
print(res)",Lainnya,6497,"import ___

def random_matrix(n, m):
    matrix = []
    for i in range(n):
        row = []
        for j in range(m):
            row.append(random.randint(1,100))
        matrix.append(row)
    return matrix

res = random_matrix(3, 2)
print(res)",random
Create a way to encrypt a message using a key in Python.,"message = ""Hello world!""
key = ""secret""","import hashlib

def encrypt(message, key):
    encrypted_msg = """"
    for char in message:
        encrypted_msg += chr(ord(char) + ord(key[0]))
    return encrypted_msg

encrypted_msg = encrypt(message, key)
print(encrypted_msg)",Lainnya,6498,"import ___

def encrypt(message, key):
    encrypted_msg = """"
    for char in message:
        encrypted_msg += chr(ord(char) + ord(key[0]))
    return encrypted_msg

encrypted_msg = encrypt(message, key)
print(encrypted_msg)",hashlib
Create a Python script which automates the process of making API requests to a given URL.,https://example.com,"import requests

url = 'https://example.com'

# Make get request
r = requests.get(url)

# Check the response status
if r.status_code == 200:
 print('success')

# Make post request
r = requests.post(url, data = {'key':'value'})

# Check the response status
if r.status_code == 200:
 print('success')",Lainnya,6510,"import ___

url = 'https://example.com'

# Make get request
r = requests.get(url)

# Check the response status
if r.status_code == 200:
 print('success')

# Make post request
r = requests.post(url, data = {'key':'value'})

# Check the response status
if r.status_code == 200:
 print('success')",requests
"Given a sentence and a word, extract the POS tag of the word using nltk library in Python.","Sentence: He is enjoying the warm weather
Word: enjoying","import nltk

sentence = ""He is enjoying the warm weather""
word = ""enjoying""

tokens = nltk.word_tokenize(sentence)
tagged = nltk.pos_tag(tokens)

for (token, tag) in tagged:
   if token == word:
     print(""POS Tag of the word:"", tag)",Lainnya,6532,"import ___

sentence = ""He is enjoying the warm weather""
word = ""enjoying""

tokens = nltk.word_tokenize(sentence)
tagged = nltk.pos_tag(tokens)

for (token, tag) in tagged:
   if token == word:
     print(""POS Tag of the word:"", tag)",nltk
Construct a program in Python to stack and scale input data,A list of 10 data points consisting of a mix of integers and floats,"import numpy as np

def preprocess(data):
    # Stack the data
    data = np.stack(data)

    # Scale the data
    data = (data - np.min(data)) / (np.max(data) - np.min(data))
    return data",Lainnya,6533,"import ___ as np

def preprocess(data):
    # Stack the data
    data = np.stack(data)

    # Scale the data
    data = (data - np.min(data)) / (np.max(data) - np.min(data))
    return data",numpy
Could you please craft a Python solution to find the total number of days between two dates?,"date1 = ""29 June 1999""
date2 = ""29 July 1999""","import datetime

def diff_in_days(date1, date2):
    d1 = datetime.datetime.strptime(date1, ""%d %B %Y"")
    d2 = datetime.datetime.strptime(date2, ""%d %B %Y"")
    delta = d2 - d1
    return delta.days

date1 = ""29 June 1999""
date2 = ""29 July 1999""

difference = diff_in_days(date1, date2)
print(""Difference is"", difference, ""days"")",Lainnya,6540,"import ___

def diff_in_days(date1, date2):
    d1 = datetime.datetime.strptime(date1, ""%d %B %Y"")
    d2 = datetime.datetime.strptime(date2, ""%d %B %Y"")
    delta = d2 - d1
    return delta.days

date1 = ""29 June 1999""
date2 = ""29 July 1999""

difference = diff_in_days(date1, date2)
print(""Difference is"", difference, ""days"")",datetime
Create a Python script to display a table of values given a range of x and y coordinates.,"x range: 0 to 50
y range: 0 to 10","import pandas as pd
import numpy as np

x = np.arange(0, 50, 1)
y = np.arange(0, 10, 1)

xytable = []

for xi in x:
    for yi in y:
        xytable.append([xi, yi, xi*yi])

table = pd.DataFrame(xytable, columns=['X', 'Y', 'Product'])

print(table)",Lainnya,6552,"import ___ as pd
import numpy as np

x = np.arange(0, 50, 1)
y = np.arange(0, 10, 1)

xytable = []

for xi in x:
    for yi in y:
        xytable.append([xi, yi, xi*yi])

table = pd.DataFrame(xytable, columns=['X', 'Y', 'Product'])

print(table)",pandas
"Create a program in Python that takes a website URL as input, scrapes all the links on the page, and prints out the URLs of the links on the page.",Sample URL: https://www.example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://www.example.com""   
resp = requests.get(url) 
soup = BeautifulSoup(resp.text, 'html.parser') 
links = soup.find_all('a', href=True) 

for link in links:
 print(link['href'])",Lainnya,6587,"import ___
from bs4 import BeautifulSoup

url = ""https://www.example.com""   
resp = requests.get(url) 
soup = BeautifulSoup(resp.text, 'html.parser') 
links = soup.find_all('a', href=True) 

for link in links:
 print(link['href'])",requests
Write a Python program to scrape the HTML content of a website and extract all links.,Website URL: http://example.com,"import requests
from bs4 import BeautifulSoup

url = 'http://example.com'

r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')

links = [link.get('href') for link in soup.find_all('a')]
print(links)",Lainnya,6643,"import ___
from bs4 import BeautifulSoup

url = 'http://example.com'

r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')

links = [link.get('href') for link in soup.find_all('a')]
print(links)",requests
Create a Python program to retrieve data from a given URL.,"url = ""https://example.com/index.html""","# Import the built-in ""requests"" package
import requests

# Set the URL
url = ""https://example.com/index.html""

# Retrieve the data
data = requests.get(url)

# Output the retrieved data
print(data.text)",Lainnya,6658,"# Import the built-in ""requests"" package
import ___

# Set the URL
url = ""https://example.com/index.html""

# Retrieve the data
data = requests.get(url)

# Output the retrieved data
print(data.text)",requests
Create a Python script that extracts the text from a webpage,URL: https://www.example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://www.example.com""

page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')

text = soup.find_all(text=True)

for t in text:
    print(t.strip())",Lainnya,6659,"import ___
from bs4 import BeautifulSoup

url = ""https://www.example.com""

page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')

text = soup.find_all(text=True)

for t in text:
    print(t.strip())",requests
Create a Python script to generate a histogram from an input dataset.,"[1, 2, 3, 4, 5, 6, 7, 8, 9]","import numpy as np
import matplotlib.pyplot as plt

data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])

# histogram the data
plt.hist(data)

# labels
plt.xlabel('Value')
plt.ylabel('Frequency')

plt.show()",Lainnya,6689,"import ___ as np
import matplotlib.pyplot as plt

data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])

# histogram the data
plt.hist(data)

# labels
plt.xlabel('Value')
plt.ylabel('Frequency')

plt.show()",numpy
Create a web scraper in Python to access the data in a given url,https://www.example.com/,"import requests
from bs4 import BeautifulSoup

url = 'https://www.example.com/'
resp = requests.get(url)
soup = BeautifulSoup(resp.content, 'html.parser')

# Scraping code goes here",Lainnya,6695,"import ___
from bs4 import BeautifulSoup

url = 'https://www.example.com/'
resp = requests.get(url)
soup = BeautifulSoup(resp.content, 'html.parser')

# Scraping code goes here",requests
Build a web scraper with Python to extract the text of a website.,Link to a website.,"import requests
from bs4 import BeautifulSoup

# Copy the link to the website
url = 'https://www.example.com/'

# Make a request for the page
r = requests.get(url)

# Parse the response using BeautifulSoup
soup = BeautifulSoup(r.text, 'html.parser')

# Extract the text from the page
text = soup.find_all(text=True)

# Output the text
for t in text:
 print(t.strip())",Lainnya,6706,"import ___
from bs4 import BeautifulSoup

# Copy the link to the website
url = 'https://www.example.com/'

# Make a request for the page
r = requests.get(url)

# Parse the response using BeautifulSoup
soup = BeautifulSoup(r.text, 'html.parser')

# Extract the text from the page
text = soup.find_all(text=True)

# Output the text
for t in text:
 print(t.strip())",requests
Create a web scrapper in Python that extracts the number of subscribers from a YouTube Channel.,https://www.youtube.com/user/mahalo,"import requests
from bs4 import BeautifulSoup

url = 'https://www.youtube.com/user/mahalo'
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
subs = soup.find(id='subscriber-count').text

subscribers = int(subs.replace(',', '').split(' ')[0])
print('Number of subscribers: ', subscribers)",Lainnya,6749,"import ___
from bs4 import BeautifulSoup

url = 'https://www.youtube.com/user/mahalo'
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
subs = soup.find(id='subscriber-count').text

subscribers = int(subs.replace(',', '').split(' ')[0])
print('Number of subscribers: ', subscribers)",requests
"Write a Python program that takes in an email address, checks it is valid and then prints the domain.","email = ""test@example.com""","import re 
  
def validate_email(email): 
  
    regex = '^[a-z0-9]+[\._]?[a-z0-9]+[@]\w+[.]\w{2,3}$'
  
    if(re.search(regex,email)):  
        domain = email.split('@')[1] 
        print(""Domain name:"", domain)      
    else:  
        print(""Invalid Email"")  
  
  
email = ""test@example.com""
validate_email(email)",Lainnya,6756,"import ___ 
  
def validate_email(email): 
  
    regex = '^[a-z0-9]+[\._]?[a-z0-9]+[@]\w+[.]\w{2,3}$'
  
    if(re.search(regex,email)):  
        domain = email.split('@')[1] 
        print(""Domain name:"", domain)      
    else:  
        print(""Invalid Email"")  
  
  
email = ""test@example.com""
validate_email(email)",re
Write a code to perform Principal Component Analysis (PCA) in Python.,Data set: <noinput>,"from sklearn.decomposition import PCA

# create PCA object
pca = PCA(n_components=None)

# fit the object with the data
pca.fit(data)

# transform the data into lower dimension
pca_data = pca.transform(data)

# variance of each PC
pca.explained_variance_ratio_",Lainnya,6771,"from sklearn.decomposition import ___

# create PCA object
pca = PCA(n_components=None)

# fit the object with the data
pca.fit(data)

# transform the data into lower dimension
pca_data = pca.transform(data)

# variance of each PC
pca.explained_variance_ratio_",PCA
Build a Python script to optimize a given linear equation by minimizing the cost.,x + 2y = 4,"import numpy as np
from scipy.optimize import minimize

def cost_function(X): 
    x = X[0]
    y = X[1]
    return x + 2*y - 4

X = minimize(cost_function, [0, 0])

x_opt = X.x[0]
y_opt = X.x[1]

# the optimal solution is x = 2, y = 1",Lainnya,6781,"import ___ as np
from scipy.optimize import minimize

def cost_function(X): 
    x = X[0]
    y = X[1]
    return x + 2*y - 4

X = minimize(cost_function, [0, 0])

x_opt = X.x[0]
y_opt = X.x[1]

# the optimal solution is x = 2, y = 1",numpy
Analyse the sentiment of the given sentence using python.,Sentence: I am so excited that I was chosen for the job.,"from textblob import TextBlob

# Get the sentiment of the sentence
sentence = 'I am so excited that I was chosen for the job.'
blob = TextBlob(sentence)
sentiment = blob.sentiment
print('Polarity:', sentiment.polarity)  # Output: Polarity: 0.8",Lainnya,6799,"from textblob import ___

# Get the sentiment of the sentence
sentence = 'I am so excited that I was chosen for the job.'
blob = TextBlob(sentence)
sentiment = blob.sentiment
print('Polarity:', sentiment.polarity)  # Output: Polarity: 0.8",TextBlob
Create a Python program to randomly generate a mixture of two Gaussian distributions.,"mean1 = 0, mean2 = 5, stddev1 = 0.5, stddev2 = 1  
N = 10","import random 
import math

def random_mixture(mean1, mean2, stddev1, stddev2, N):
    data = []
    for _ in range(N):
        if random.random() < 0.5:
            data.append(random.normalvariate(mean1, stddev1))
        else:
            data.append(random.normalvariate(mean2, stddev2))
    return data",Lainnya,6819,"import ___ 
import math

def random_mixture(mean1, mean2, stddev1, stddev2, N):
    data = []
    for _ in range(N):
        if random.random() < 0.5:
            data.append(random.normalvariate(mean1, stddev1))
        else:
            data.append(random.normalvariate(mean2, stddev2))
    return data",random
Automate an online registration process with Python.,"A sample registration form that asks for first name, last name, email address, and phone number.","import requests

# input
form_data = {
 'firstname': 'Jane', 
 'lastname': 'Doe', 
 'email': 'janedoe@example.com', 
 'phone': '123-456-7890'
}

# process
url = 'https://example.com/register'
response = requests.post(url, data=form_data)

# output
if response.status_code == 200:
 print('Registration was successful!')",Lainnya,6820,"import ___

# input
form_data = {
 'firstname': 'Jane', 
 'lastname': 'Doe', 
 'email': 'janedoe@example.com', 
 'phone': '123-456-7890'
}

# process
url = 'https://example.com/register'
response = requests.post(url, data=form_data)

# output
if response.status_code == 200:
 print('Registration was successful!')",requests
Convert a given text into speech using Python,Text: Hello world!,"import pyttsx3

engine = pyttsx3.init()
engine.say(""Hello world!"")
engine.runAndWait()",Lainnya,6881,"import ___

engine = pyttsx3.init()
engine.say(""Hello world!"")
engine.runAndWait()",pyttsx3
Optimize a Python code snippet to make it run faster.,"import random

def generate_numbers(n):
 numbers = []
 for _ in range(n):
 numbers.append(random.randint(1, 1000))

 return numbers","import random

def generate_numbers(n):
 numbers = [random.randint(1, 1000) for _ in range(n)]

 return numbers",Lainnya,6883,"import ___

def generate_numbers(n):
 numbers = [random.randint(1, 1000) for _ in range(n)]

 return numbers",random
Create a Python script that takes a URL as an input and outputs the website title and description.,https://www.example.com,"import requests
from bs4 import BeautifulSoup 

url = 'https://www.example.com'

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')

title = soup.title.string
description = soup.find('meta', attrs={'name': 'description'})['content']

print('Title:', title)
print('Description:', description)",Lainnya,6892,"import ___
from bs4 import BeautifulSoup 

url = 'https://www.example.com'

r = requests.get(url)
soup = BeautifulSoup(r.content, 'html.parser')

title = soup.title.string
description = soup.find('meta', attrs={'name': 'description'})['content']

print('Title:', title)
print('Description:', description)",requests
Write a Python program to generate a random password of length 8 with the following requirements:,"The password must include the following – at least one lowercase letter, one uppercase letter, one numeric digit, one special character","import string
import random

def generate_password(length):
    chars = string.ascii_uppercase + string.ascii_lowercase + string.digits + string.punctuation
    password = ''.join(random.choice(chars) for _ in range(length))
    return password",Lainnya,6901,"import ___
import random

def generate_password(length):
    chars = string.ascii_uppercase + string.ascii_lowercase + string.digits + string.punctuation
    password = ''.join(random.choice(chars) for _ in range(length))
    return password",string
Create a program in Python that extracts titles of all YouTube videos from a URL.,https://www.youtube.com/user/Thexvid/videos,"import requests
import re

url = ""https://www.youtube.com/user/Thexvid/videos""

r = requests.get(url)
titles = re.findall('<a href=""/watch\?v=([^""]+)"">(.+?)<\/a>',r.content.decode('utf-8'))

for title in titles:
 print(title[1])",Lainnya,6902,"import ___
import re

url = ""https://www.youtube.com/user/Thexvid/videos""

r = requests.get(url)
titles = re.findall('<a href=""/watch\?v=([^""]+)"">(.+?)<\/a>',r.content.decode('utf-8'))

for title in titles:
 print(title[1])",requests
"Using the input as a guide, modify the following Python code to add a new feature of sorting the dictionary by value.","names_and_points = {
  ""Dave"": 20,
  ""John"": 40,
  ""Rachel"": 55
}","from operator import itemgetter

names_and_points = {
  ""Dave"": 20,
  ""John"": 40,
  ""Rachel"": 55
}

sorted_dict = sorted(names_and_points.items(), key=itemgetter(1))

print(sorted_dict)",Lainnya,6912,"from operator import ___

names_and_points = {
  ""Dave"": 20,
  ""John"": 40,
  ""Rachel"": 55
}

sorted_dict = sorted(names_and_points.items(), key=itemgetter(1))

print(sorted_dict)",itemgetter
Can you provide a Python program to remove all punctuation from a given sentence?,"""This is a sentence; with, punctuation.""","import string

def remove_punctuation(sentence):
    translator = str.maketrans('', '', string.punctuation)
    return sentence.translate(translator)

#Test
print(remove_punctuation(""This is a sentence; with, punctuation.""))",Lainnya,6918,"import ___

def remove_punctuation(sentence):
    translator = str.maketrans('', '', string.punctuation)
    return sentence.translate(translator)

#Test
print(remove_punctuation(""This is a sentence; with, punctuation.""))",string
Create a web crawler in Python to get all web page URLs from a given website.,https://en.wikipedia.org/wiki/Web_crawler,"import requests
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/Web_crawler'
request = requests.get(url)
soup = BeautifulSoup(request.content, 'html.parser')
for link in soup.find_all('a', href=True):
  print(link['href'])",Lainnya,6932,"import ___
from bs4 import BeautifulSoup

url = 'https://en.wikipedia.org/wiki/Web_crawler'
request = requests.get(url)
soup = BeautifulSoup(request.content, 'html.parser')
for link in soup.find_all('a', href=True):
  print(link['href'])",requests
Generate Python code to visualize this data using a bar chart.,"Data: {
    'Boys': [50, 80, 100, 90],
    'Girls': [60, 70, 90, 95]
}","import matplotlib.pyplot as plt 

# Create data
labels = ['Boys', 'Girls']  
values =[50, 80, 100, 90, 60, 70, 90, 95]
  
# naming the x-axis 
plt.xlabel('Category') 
# naming the y-axis 
plt.ylabel('Score') 
# plot title 
plt.title('Bar Plot') 
  
# plot the generated values  
plt.bar(labels, values) 
# function to show the plot 
plt.show()",Lainnya,6947,"import ___.pyplot as plt 

# Create data
labels = ['Boys', 'Girls']  
values =[50, 80, 100, 90, 60, 70, 90, 95]
  
# naming the x-axis 
plt.xlabel('Category') 
# naming the y-axis 
plt.ylabel('Score') 
# plot title 
plt.title('Bar Plot') 
  
# plot the generated values  
plt.bar(labels, values) 
# function to show the plot 
plt.show()",matplotlib
Write a Python program to query Twitter to get the most recent tweets from a user.,username: @elonmusk,"import tweepy

# Authenticate to Twitter
auth = tweepy.OAuthHandler(""CONSUMER_KEY"", ""CONSUMER_SECRET"")
auth.set_access_token(""ACCESS_TOKEN"", ""ACCESS_TOKEN_SECRET"")
# Create API object
api = tweepy.API(auth)

# Get the most recent tweets from the given user
tweets = api.user_timeline(screen_name=""@elonmusk"")

for tweet in tweets:
 print(tweet.text)",Lainnya,6949,"import ___

# Authenticate to Twitter
auth = tweepy.OAuthHandler(""CONSUMER_KEY"", ""CONSUMER_SECRET"")
auth.set_access_token(""ACCESS_TOKEN"", ""ACCESS_TOKEN_SECRET"")
# Create API object
api = tweepy.API(auth)

# Get the most recent tweets from the given user
tweets = api.user_timeline(screen_name=""@elonmusk"")

for tweet in tweets:
 print(tweet.text)",tweepy
Create a program in Python that takes a text and tokenizes it into words.,"text = ""This is an example of tokenization""","import re 

#Replace special characters with space 
text = re.sub(r'[^\w\s]',' ',text)
#Split text 
tokens = text.split() 

print(tokens)
#Output: ['This', 'is', 'an', 'example', 'of', 'tokenization']",Lainnya,6967,"import ___ 

#Replace special characters with space 
text = re.sub(r'[^\w\s]',' ',text)
#Split text 
tokens = text.split() 

print(tokens)
#Output: ['This', 'is', 'an', 'example', 'of', 'tokenization']",re
Generate code that optimizes a Python program so it runs faster.,"n = 30

result = 0
for i in range(n):
    for j in range(n):
        result += i * j","import numpy as np

n = 30

# Optimized code using numpy
result = np.sum(np.multiply(np.arange(n), np.arange(n)))",Lainnya,7064,"import ___ as np

n = 30

# Optimized code using numpy
result = np.sum(np.multiply(np.arange(n), np.arange(n)))",numpy
Write a Python program to calculate the total number of days between two given dates.,"First date: 20 Dec 2020 
Second date: 10 Jan 2021","from datetime import date 

def daysDifference(date1, date2): 
    return (date2-date1).days 

date1 = date(2020, 12, 20) 
date2 = date(2021, 1, 10) 
print(daysDifference(date1, date2))",Lainnya,7070,"from datetime import ___ 

def daysDifference(date1, date2): 
    return (date2-date1).days 

date1 = date(2020, 12, 20) 
date2 = date(2021, 1, 10) 
print(daysDifference(date1, date2))",date
Create a Python script that fills in the missing data with median values.,"[1, None, 4, 5, None, 10]","import numpy as np

def fillWithMedian(data):
    data = np.array(data)
    median_val = np.nanmedian(data)
    data[np.isnan(data)] = median_val 
    return data

data = [1, None, 4, 5, None, 10]
print(fillWithMedian(data))",Lainnya,7076,"import ___ as np

def fillWithMedian(data):
    data = np.array(data)
    median_val = np.nanmedian(data)
    data[np.isnan(data)] = median_val 
    return data

data = [1, None, 4, 5, None, 10]
print(fillWithMedian(data))",numpy
Create a REST API call in Python that sends a GET request and displays the response.,https://reqres.in/api/users,"import requests

# Send GET request
r = requests.get('https://reqres.in/api/users')

# Get response
if r.status_code == 200:
 print(r.text)",Lainnya,7085,"import ___

# Send GET request
r = requests.get('https://reqres.in/api/users')

# Get response
if r.status_code == 200:
 print(r.text)",requests
Find the most common words in a document using Python.,The quick brown fox jumps over the lazy dog.,"from collections import Counter

text = ""The quick brown fox jumps over the lazy dog.""
words = text.split()

word_count = Counter(words)

# print the most common words
print(word_count.most_common(3))

# Output: [('the', 2), ('quick', 1), ('brown', 1)]",Lainnya,7132,"from collections import ___

text = ""The quick brown fox jumps over the lazy dog.""
words = text.split()

word_count = Counter(words)

# print the most common words
print(word_count.most_common(3))

# Output: [('the', 2), ('quick', 1), ('brown', 1)]",Counter
Optimize the existing Python script to improve the performance.,"import timeit

def find_value(l):
    for v in l:
        if v >= 0:
            return v
    return -1

print(timeit.timeit('find_value([-5, 0, 4, -1, 3])', number=10000))","import timeit

def find_value(l):
    for v in l:
        if v >= 0:
            # Early exit once value is found
            return v
    return -1

print(timeit.timeit('find_value([-5, 0, 4, -1, 3])', number=10000))",Lainnya,7146,"import ___

def find_value(l):
    for v in l:
        if v >= 0:
            # Early exit once value is found
            return v
    return -1

print(timeit.timeit('find_value([-5, 0, 4, -1, 3])', number=10000))",timeit
Create a program in Python that takes a website URL as input and returns the number of HTML tags in the page.,URL: https://www.example.com,"import requests
from bs4 import BeautifulSoup

def count_tags(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'html.parser')
    count = len(soup.find_all())
    return count",Lainnya,7147,"import ___
from bs4 import BeautifulSoup

def count_tags(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'html.parser')
    count = len(soup.find_all())
    return count",requests
Optimize a Python program to run faster and use less memory.,"import math
 
# Slow loop implementation
def slow_loop(num):
    for i in range(int(num)):
        result = math.sqrt(i*i + 1)
    return result","import math
 
# Faster loop implementation
def fast_loop(num):
    result = 1
    for i in range(int(num)):
        result += math.sqrt(i*i + 1)
    return result",Lainnya,7157,"import ___
 
# Faster loop implementation
def fast_loop(num):
    result = 1
    for i in range(int(num)):
        result += math.sqrt(i*i + 1)
    return result",math
Create a web crawler in Python which takes an URL as input and extract all the links from the page.,https://www.example.com,"import requests
from bs4 import BeautifulSoup

def extract_links(url):
 r = requests.get(url)
 soup = BeautifulSoup(r.content, 'html.parser')
 links = []
 for link in soup.find_all('a'):
  links.append(link.get('href'))
 return links

url = ""https://www.example.com""
print(extract_links(url))",Lainnya,7200,"import ___
from bs4 import BeautifulSoup

def extract_links(url):
 r = requests.get(url)
 soup = BeautifulSoup(r.content, 'html.parser')
 links = []
 for link in soup.find_all('a'):
  links.append(link.get('href'))
 return links

url = ""https://www.example.com""
print(extract_links(url))",requests
Write a code in Python to show a histogram distribution of data.,"[2, 3, 5, 6, 7, 8, 9, 10]","import matplotlib.pyplot as plt

# example data
data = [2, 3, 5, 6, 7, 8, 9, 10]

# create histogram
plt.hist(data)

# show plot
plt.show()",Lainnya,7233,"import ___.pyplot as plt

# example data
data = [2, 3, 5, 6, 7, 8, 9, 10]

# create histogram
plt.hist(data)

# show plot
plt.show()",matplotlib
"Create a Python program to read numbers from stdin and produce a histogram, showing the frequency of the numbers in each 10 buckets.","15
-7
-3
29
4","import sys

# Define buckets
buckets = [0]*10

# Read line-by-line
for line in sys.stdin:
 # Read as integer
 value = int(line)

 # Find the bucket
 bucket = max(int(value/10), 0)
 buckets[bucket] += 1

# Output result
for i, count in enumerate(buckets):
 print('{}-{}: {}'.format(i*10, i*10+9, count))",Lainnya,7242,"import ___

# Define buckets
buckets = [0]*10

# Read line-by-line
for line in sys.stdin:
 # Read as integer
 value = int(line)

 # Find the bucket
 bucket = max(int(value/10), 0)
 buckets[bucket] += 1

# Output result
for i, count in enumerate(buckets):
 print('{}-{}: {}'.format(i*10, i*10+9, count))",sys
Create a post request in python with the given parameters.,"API: https://api.endpoint.com
Headers: {'Authorization': 'Bearer abcdefg', 'Content-Type': 'application/json'}
Parameters: {'name': 'John', 'age': 25}","import requests

url = 'https://api.endpoint.com'
headers = {'Authorization': 'Bearer abcdefg', 'Content-Type': 'application/json'}
parameters = {'name': 'John', 'age': 25}

response = requests.post(url, headers=headers, json=parameters)",Lainnya,7243,"import ___

url = 'https://api.endpoint.com'
headers = {'Authorization': 'Bearer abcdefg', 'Content-Type': 'application/json'}
parameters = {'name': 'John', 'age': 25}

response = requests.post(url, headers=headers, json=parameters)",requests
Create a python module that reads the sentiment of a given text.,Nothing,"import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

def sentiment_score(text): 
    sentiment_scores = SentimentIntensityAnalyzer().polarity_scores(text) 
    return sentiment_scores[""compound""]",Lainnya,7249,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

def sentiment_score(text): 
    sentiment_scores = SentimentIntensityAnalyzer().polarity_scores(text) 
    return sentiment_scores[""compound""]",nltk
Perform a sentiment analysis on a body of text using Python.,"text = ""This is a very positive sentiment!""","import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""This is a very positive sentiment!""
sentiment_analyzer = SentimentIntensityAnalyzer()
scores = sentiment_analyzer.polarity_scores(text)

if scores['compound'] > 0.05:
 print(""Positive sentiment!"")
else:
 print(""Negative sentiment!"")",Lainnya,7286,"import ___
from nltk.sentiment.vader import SentimentIntensityAnalyzer

text = ""This is a very positive sentiment!""
sentiment_analyzer = SentimentIntensityAnalyzer()
scores = sentiment_analyzer.polarity_scores(text)

if scores['compound'] > 0.05:
 print(""Positive sentiment!"")
else:
 print(""Negative sentiment!"")",nltk
Generate a Python program to fill missing values in the given table.,"Table: student_data

| id  | name  | age |
|-----|-------|-----|
| 1   | John  |    |
| 2   | Jane  |    |
| 3   | Jack  | 28 |","import pandas as pd

# Read the student data
data = pd.read_csv('student_data.csv')

# Fill the missing values
data['age'] = data['age'].fillna(data['age'].mean())

# Print the result
print(data)",Lainnya,7293,"import ___ as pd

# Read the student data
data = pd.read_csv('student_data.csv')

# Fill the missing values
data['age'] = data['age'].fillna(data['age'].mean())

# Print the result
print(data)",pandas
Can you develop a Python script that takes in a URL and prints out the source code?,url = 'http://www.example.org/',"import urllib.request
 
url = 'http://www.example.org/'

response = urllib.request.urlopen(url)

print(response.read())",Lainnya,7295,"import ___.request
 
url = 'http://www.example.org/'

response = urllib.request.urlopen(url)

print(response.read())",urllib
Write Python code to implement a decision tree classifier.,No Input,"from sklearn import tree

#features 
features = [[104,0], [100,0], [120,1], [80,0], [105,1]]
#labels
labels = [0,0,1,0,1]

clf = tree.DecisionTreeClassifier()
clf = clf.fit(features, labels)

print(""Predicted Label:"", clf.predict([[120,1]]))",Lainnya,7301,"from sklearn import ___

#features 
features = [[104,0], [100,0], [120,1], [80,0], [105,1]]
#labels
labels = [0,0,1,0,1]

clf = tree.DecisionTreeClassifier()
clf = clf.fit(features, labels)

print(""Predicted Label:"", clf.predict([[120,1]]))",tree
Create a Python program to read and parse XML data from a URL.,https://example.com/data.xml,"import requests
import xml.etree.ElementTree as ET

url = 'https://example.com/data.xml'
r = requests.get(url)
xml_data = r.text

root = ET.fromstring(xml_data)

for child in root:
 print(child.tag, child.attrib)",Lainnya,7333,"import ___
import xml.etree.ElementTree as ET

url = 'https://example.com/data.xml'
r = requests.get(url)
xml_data = r.text

root = ET.fromstring(xml_data)

for child in root:
 print(child.tag, child.attrib)",requests
Use matplotlib in Python to create a pie chart depicting a survey result.,"topic = ""Favorite fruits""
responses = { 'banana': 5, 'apple': 7, 'strawberry': 10, 'mango': 6 }","import matplotlib.pyplot as plt
 
labels = list(responses.keys())
values = list(responses.values())
colors = ['#F08080', '#F8A458', '#9BC808', '#000080']
 
plt.pie(values, labels = labels, colors = colors, autopct='%1.2f%%')
plt.title('Favorite Fruits')
plt.axis('equal')
plt.show()",Lainnya,7351,"import ___.pyplot as plt
 
labels = list(responses.keys())
values = list(responses.values())
colors = ['#F08080', '#F8A458', '#9BC808', '#000080']
 
plt.pie(values, labels = labels, colors = colors, autopct='%1.2f%%')
plt.title('Favorite Fruits')
plt.axis('equal')
plt.show()",matplotlib
Create an API request using Python to get the status of your favorite website.,Website URL: example.com,"import requests

url = 'http://example.com'

r = requests.get(url)

if r.status_code == 200:
  print('Website is up and running.')
else:
  print('Website is not responding.')",Lainnya,7367,"import ___

url = 'http://example.com'

r = requests.get(url)

if r.status_code == 200:
  print('Website is up and running.')
else:
  print('Website is not responding.')",requests
Create an AI assistant in Python to detect whether a sentence is a question or not.,Is this a question?,"import nltk

sentence = ""Is this a question?""
words = nltk.word_tokenize(sentence)

# Check if the sentence ends with a question mark
if words[-1] == '?':
 print(""This is a question."")
else:
 print(""This is not a question."")",Lainnya,7435,"import ___

sentence = ""Is this a question?""
words = nltk.word_tokenize(sentence)

# Check if the sentence ends with a question mark
if words[-1] == '?':
 print(""This is a question."")
else:
 print(""This is not a question."")",nltk
"Create a web scraper in Python that retrieves the titles of all posts of a given web page, and prints them on the screen.",https://example.com/blog,"import requests
from bs4 import BeautifulSoup

url = ""https://example.com/blog""

r = requests.get(url)
html = r.text

soup = BeautifulSoup(html, 'html.parser')
titles = soup.find_all('h2')

for title in titles:
 print(title.text)",Lainnya,7439,"import ___
from bs4 import BeautifulSoup

url = ""https://example.com/blog""

r = requests.get(url)
html = r.text

soup = BeautifulSoup(html, 'html.parser')
titles = soup.find_all('h2')

for title in titles:
 print(title.text)",requests
Generate a Python program to calculate the number of days between two given dates.,"Start date: 5th June 2020
End date: 17th June 2020","from datetime import date

start_date = date(2020, 6, 5)
end_date = date(2020, 6, 17)
delta = end_date - start_date
print(delta.days)",Lainnya,7459,"from datetime import ___

start_date = date(2020, 6, 5)
end_date = date(2020, 6, 17)
delta = end_date - start_date
print(delta.days)",date
Rewrite the given SQL query to fetch the same results using Python.,"SELECT CustomerID, FirstName, LastName FROM Customers WHERE Country = 'Germany';","import sqlite3

conn = sqlite3.connect('database.db')
cursor = conn.cursor()

cursor.execute(""SELECT CustomerID, FirstName, LastName FROM Customers WHERE Country = 'Germany'"") 
rows = cursor.fetchall()

conn.close()

# Output rows
for row in rows:
    print(row[0], row[1], row[2])",Lainnya,7496,"import ___

conn = sqlite3.connect('database.db')
cursor = conn.cursor()

cursor.execute(""SELECT CustomerID, FirstName, LastName FROM Customers WHERE Country = 'Germany'"") 
rows = cursor.fetchall()

conn.close()

# Output rows
for row in rows:
    print(row[0], row[1], row[2])",sqlite3
Create a Python program to scrape data from a website. The program should accept the website's URL as input.,https://example.com,"import requests
from bs4 import BeautifulSoup

url = ""https://example.com""
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# Scrape data from the website
# ...
# ...",Lainnya,7519,"import ___
from bs4 import BeautifulSoup

url = ""https://example.com""
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# Scrape data from the website
# ...
# ...",requests
Create a Python script to interpolate missing data points from a Pandas dataframe.,"import pandas as pd

df = pd.DataFrame({
 'x': [0,1,3,4,5],
 'y': [1,2,4,8,16]
})","import pandas as pd
import numpy as np

df = pd.DataFrame({
 'x': [0,1,3,4,5],
 'y': [1,2,4,8,16]
})

# interpolate the missing data
new_x = np.linspace(0, 5, 6)
df = df.set_index('x').reindex(new_x).interpolate().reset_index()
print(df)",Lainnya,7520,"import ___ as pd
import numpy as np

df = pd.DataFrame({
 'x': [0,1,3,4,5],
 'y': [1,2,4,8,16]
})

# interpolate the missing data
new_x = np.linspace(0, 5, 6)
df = df.set_index('x').reindex(new_x).interpolate().reset_index()
print(df)",pandas
Create a script in Python to download the content of a webpage with a given URL.,URL: https://github.com,"import requests
 
url = ""https://github.com""
 
response = requests.get(url)
 
with open('webpage.txt', 'w') as file:
    file.write(response.text)",Lainnya,7526,"import ___
 
url = ""https://github.com""
 
response = requests.get(url)
 
with open('webpage.txt', 'w') as file:
    file.write(response.text)",requests
Create a utility in Python to generate a PDF of a webpage. The utility should accept a URL as input and generate a PDF of the webpage in the same directory.,https://www.example.com,"import pdfkit

def generate_pdf(url):
 filename = url.rsplit('/', 1)[-1] + '.pdf'
 pdfkit.from_url(url, filename)

if __name__ == '__main__':
 url = input('Enter a URL: ')
 generate_pdf(url)",Lainnya,7542,"import ___

def generate_pdf(url):
 filename = url.rsplit('/', 1)[-1] + '.pdf'
 pdfkit.from_url(url, filename)

if __name__ == '__main__':
 url = input('Enter a URL: ')
 generate_pdf(url)",pdfkit
Create a webhook in Python to handle incoming HTTP POST requests. This webhook should process the JSON payload in the POST request and log the output to console.,"{
  ""name"": ""John Doe"",
  ""email"": ""john@example.com""
}","import json
from flask import Flask, request

app = Flask(name)

@app.route('/webhook', methods=['POST'])
def webhook():
 payload = json.loads(request.data)
 print(payload)
 return ""OK""

if name == 'main':
 app.run(debug=True)",Lainnya,7559,"import ___
from flask import Flask, request

app = Flask(name)

@app.route('/webhook', methods=['POST'])
def webhook():
 payload = json.loads(request.data)
 print(payload)
 return ""OK""

if name == 'main':
 app.run(debug=True)",json
